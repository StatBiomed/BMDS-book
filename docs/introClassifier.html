<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Introduction to Classification | Biomedical Data Science - introduction with case studies</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.35 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Introduction to Classification | Biomedical Data Science - introduction with case studies" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Introduction to Classification | Biomedical Data Science - introduction with case studies" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="BIOF1001 teaching team" />


<meta name="date" content="2025-09-28" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introLinearReg.html"/>
<link rel="next" href="image-digital.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./index.html">Biomedical Data Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#introduction-for-readers"><i class="fa fa-check"></i>Introduction for readers</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#what-you-will-learn-from-this-coursebook"><i class="fa fa-check"></i>What you will learn from this course/book</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#what-we-recommend-you-do-while-reading-this-book"><i class="fa fa-check"></i>What we recommend you do while reading this book</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#other-reference-books"><i class="fa fa-check"></i>Other reference books</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="part"><span><b>I Data Science Foundations</b></span></li>
<li class="chapter" data-level="1" data-path="introR.html"><a href="introR.html"><i class="fa fa-check"></i><b>1</b> Introduction to R</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introR.html"><a href="introR.html#introR-w1"><i class="fa fa-check"></i><b>1.1</b> Intro to R programming (Session 1)</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="introR.html"><a href="introR.html#r-as-a-basic-calculator"><i class="fa fa-check"></i><b>1.1.1</b> R as a basic calculator</a></li>
<li class="chapter" data-level="1.1.2" data-path="introR.html"><a href="introR.html#variables"><i class="fa fa-check"></i><b>1.1.2</b> Variables</a></li>
<li class="chapter" data-level="1.1.3" data-path="introR.html"><a href="introR.html#data-types"><i class="fa fa-check"></i><b>1.1.3</b> Data types</a></li>
<li class="chapter" data-level="1.1.4" data-path="introR.html"><a href="introR.html#functions"><i class="fa fa-check"></i><b>1.1.4</b> Functions</a></li>
<li class="chapter" data-level="1.1.5" data-path="introR.html"><a href="introR.html#r-scripts"><i class="fa fa-check"></i><b>1.1.5</b> R scripts</a></li>
<li class="chapter" data-level="1.1.6" data-path="introR.html"><a href="introR.html#resource-links"><i class="fa fa-check"></i><b>1.1.6</b> Resource links</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="introR.html"><a href="introR.html#introR-w2"><i class="fa fa-check"></i><b>1.2</b> Intro to R programming (Session 2)</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="introR.html"><a href="introR.html#data-structures"><i class="fa fa-check"></i><b>1.2.1</b> Data structures</a></li>
<li class="chapter" data-level="1.2.2" data-path="introR.html"><a href="introR.html#vector"><i class="fa fa-check"></i><b>1.2.2</b> Vector</a></li>
<li class="chapter" data-level="1.2.3" data-path="introR.html"><a href="introR.html#matrix"><i class="fa fa-check"></i><b>1.2.3</b> Matrix</a></li>
<li class="chapter" data-level="1.2.4" data-path="introR.html"><a href="introR.html#list"><i class="fa fa-check"></i><b>1.2.4</b> List</a></li>
<li class="chapter" data-level="1.2.5" data-path="introR.html"><a href="introR.html#data-frame"><i class="fa fa-check"></i><b>1.2.5</b> Data Frame</a></li>
<li class="chapter" data-level="1.2.6" data-path="introR.html"><a href="introR.html#readingwriting-data-fromto-r"><i class="fa fa-check"></i><b>1.2.6</b> Reading/writing data from/to R</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="introR.html"><a href="introR.html#introR-w3"><i class="fa fa-check"></i><b>1.3</b> Intro to R programming (Session 4)</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="introR.html"><a href="introR.html#operators"><i class="fa fa-check"></i><b>1.3.1</b> Operators</a></li>
<li class="chapter" data-level="1.3.2" data-path="introR.html"><a href="introR.html#ifelse"><i class="fa fa-check"></i><b>1.3.2</b> If/else</a></li>
<li class="chapter" data-level="1.3.3" data-path="introR.html"><a href="introR.html#loop"><i class="fa fa-check"></i><b>1.3.3</b> Loop</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introHypoTest.html"><a href="introHypoTest.html"><i class="fa fa-check"></i><b>2</b> Introduction to Hypothesis test</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introHypoTest.html"><a href="introHypoTest.html#hypothesis-test-and-p-value"><i class="fa fa-check"></i><b>2.1</b> Hypothesis test and <em>p</em>-value</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="introHypoTest.html"><a href="introHypoTest.html#extreme-events-and-random-chance"><i class="fa fa-check"></i><b>2.1.1</b> Extreme events and random chance</a></li>
<li class="chapter" data-level="2.1.2" data-path="introHypoTest.html"><a href="introHypoTest.html#hypothesis-test-for-statistical-decision"><i class="fa fa-check"></i><b>2.1.2</b> Hypothesis test for statistical decision</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="introHypoTest.html"><a href="introHypoTest.html#basic-hypothesis-test-methods"><i class="fa fa-check"></i><b>2.2</b> Basic hypothesis test methods</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="introHypoTest.html"><a href="introHypoTest.html#permutation-test"><i class="fa fa-check"></i><b>2.2.1</b> Permutation test</a></li>
<li class="chapter" data-level="2.2.2" data-path="introHypoTest.html"><a href="introHypoTest.html#t-test-and-regression-based-test"><i class="fa fa-check"></i><b>2.2.2</b> <em>t</em>-test and regression-based test</a></li>
<li class="chapter" data-level="2.2.3" data-path="introHypoTest.html"><a href="introHypoTest.html#fishers-exact-test"><i class="fa fa-check"></i><b>2.2.3</b> Fisher’s exact test</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="introHypoTest.html"><a href="introHypoTest.html#multiple-testing-and-errors"><i class="fa fa-check"></i><b>2.3</b> Multiple testing and errors</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="introHypoTest.html"><a href="introHypoTest.html#null-distribution-of-test-statistic"><i class="fa fa-check"></i><b>2.3.1</b> Null distribution (of test statistic)</a></li>
<li class="chapter" data-level="2.3.2" data-path="introHypoTest.html"><a href="introHypoTest.html#null-distribution-of-p-value"><i class="fa fa-check"></i><b>2.3.2</b> Null distribution of p value</a></li>
<li class="chapter" data-level="2.3.3" data-path="introHypoTest.html"><a href="introHypoTest.html#minimal-p-values-in-10-tests"><i class="fa fa-check"></i><b>2.3.3</b> Minimal p values in 10 tests</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="introHypoTest.html"><a href="introHypoTest.html#power-analysis"><i class="fa fa-check"></i><b>2.4</b> Explore power and sample size (optional)</a></li>
<li class="chapter" data-level="2.5" data-path="introHypoTest.html"><a href="introHypoTest.html#summary"><i class="fa fa-check"></i><b>2.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="introLinearReg.html"><a href="introLinearReg.html"><i class="fa fa-check"></i><b>3</b> Introduction to Linear Regression</a>
<ul>
<li class="chapter" data-level="3.1" data-path="introLinearReg.html"><a href="introLinearReg.html#linear-regression-using-simulated-data"><i class="fa fa-check"></i><b>3.1</b> Linear Regression Using Simulated Data</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="introLinearReg.html"><a href="introLinearReg.html#simulating-data"><i class="fa fa-check"></i><b>3.1.1</b> Simulating data:</a></li>
<li class="chapter" data-level="3.1.2" data-path="introLinearReg.html"><a href="introLinearReg.html#model-efficacy"><i class="fa fa-check"></i><b>3.1.2</b> Model efficacy</a></li>
<li class="chapter" data-level="3.1.3" data-path="introLinearReg.html"><a href="introLinearReg.html#r-squared"><i class="fa fa-check"></i><b>3.1.3</b> <em>R-Squared</em></a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="introLinearReg.html"><a href="introLinearReg.html#least-squares-using-simulated-data"><i class="fa fa-check"></i><b>3.2</b> Least Squares Using Simulated Data</a></li>
<li class="chapter" data-level="3.3" data-path="introLinearReg.html"><a href="introLinearReg.html#diagnostic-check-of-a-fitted-regression-model"><i class="fa fa-check"></i><b>3.3</b> Diagnostic check of a fitted regression model</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="introLinearReg.html"><a href="introLinearReg.html#residual-standard-errors-rse"><i class="fa fa-check"></i><b>3.3.1</b> Residual Standard Errors (RSE)</a></li>
<li class="chapter" data-level="3.3.2" data-path="introLinearReg.html"><a href="introLinearReg.html#p-values"><i class="fa fa-check"></i><b>3.3.2</b> p-values</a></li>
<li class="chapter" data-level="3.3.3" data-path="introLinearReg.html"><a href="introLinearReg.html#f-statistics"><i class="fa fa-check"></i><b>3.3.3</b> F-statistics</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="introLinearReg.html"><a href="introLinearReg.html#simple-linear-regression-with-lm-function"><i class="fa fa-check"></i><b>3.4</b> Simple Linear Regression with <code>lm</code> function</a></li>
<li class="chapter" data-level="3.5" data-path="introLinearReg.html"><a href="introLinearReg.html#multiple-regression-with-lm-function"><i class="fa fa-check"></i><b>3.5</b> Multiple Regression with <code>lm</code> function</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="introClassifier.html"><a href="introClassifier.html"><i class="fa fa-check"></i><b>4</b> Introduction to Classification</a>
<ul>
<li class="chapter" data-level="4.1" data-path="introClassifier.html"><a href="introClassifier.html#visualise-logistic-and-logit-functions"><i class="fa fa-check"></i><b>4.1</b> Visualise logistic and logit functions</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="introClassifier.html"><a href="introClassifier.html#logistic-function"><i class="fa fa-check"></i><b>4.1.1</b> Logistic function</a></li>
<li class="chapter" data-level="4.1.2" data-path="introClassifier.html"><a href="introClassifier.html#logit-function"><i class="fa fa-check"></i><b>4.1.2</b> Logit function</a></li>
<li class="chapter" data-level="4.1.3" data-path="introClassifier.html"><a href="introClassifier.html#visualise-the-distribution"><i class="fa fa-check"></i><b>4.1.3</b> Visualise the distribution</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="introClassifier.html"><a href="introClassifier.html#logistic-regression-on-diabetes"><i class="fa fa-check"></i><b>4.2</b> Logistic regression on Diabetes</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="introClassifier.html"><a href="introClassifier.html#load-pima-indians-diabetes-database"><i class="fa fa-check"></i><b>4.2.1</b> Load Pima Indians Diabetes Database</a></li>
<li class="chapter" data-level="4.2.2" data-path="introClassifier.html"><a href="introClassifier.html#fit-logistic-regression"><i class="fa fa-check"></i><b>4.2.2</b> Fit logistic regression</a></li>
<li class="chapter" data-level="4.2.3" data-path="introClassifier.html"><a href="introClassifier.html#assess-on-test-data"><i class="fa fa-check"></i><b>4.2.3</b> Assess on test data</a></li>
<li class="chapter" data-level="4.2.4" data-path="introClassifier.html"><a href="introClassifier.html#model-selection-and-diagnosis"><i class="fa fa-check"></i><b>4.2.4</b> Model selection and diagnosis</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="introClassifier.html"><a href="introClassifier.html#cross-validation"><i class="fa fa-check"></i><b>4.3</b> Cross-validation</a></li>
<li class="chapter" data-level="4.4" data-path="introClassifier.html"><a href="introClassifier.html#more-assessment-metrics"><i class="fa fa-check"></i><b>4.4</b> More assessment metrics</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="introClassifier.html"><a href="introClassifier.html#two-types-of-error"><i class="fa fa-check"></i><b>4.4.1</b> Two types of error</a></li>
<li class="chapter" data-level="4.4.2" data-path="introClassifier.html"><a href="introClassifier.html#roc-curve"><i class="fa fa-check"></i><b>4.4.2</b> ROC curve</a></li>
<li class="chapter" data-level="4.4.3" data-path="introClassifier.html"><a href="introClassifier.html#homework"><i class="fa fa-check"></i><b>4.4.3</b> Homework</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Biomedical Data Modules</b></span></li>
<li class="chapter" data-level="5" data-path="image-digital.html"><a href="image-digital.html"><i class="fa fa-check"></i><b>5</b> Medical Image and Digital Health</a></li>
<li class="chapter" data-level="6" data-path="cancer.html"><a href="cancer.html"><i class="fa fa-check"></i><b>6</b> Cancer genomics</a>
<ul>
<li class="chapter" data-level="6.1" data-path="cancer.html"><a href="cancer.html#cancer-case1"><i class="fa fa-check"></i><b>6.1</b> Case study 1: analysis of cBioportal mutation data</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="cancer.html"><a href="cancer.html#exploratory-analysis"><i class="fa fa-check"></i><b>6.1.1</b> Exploratory analysis</a></li>
<li class="chapter" data-level="6.1.2" data-path="cancer.html"><a href="cancer.html#statistical-analysis"><i class="fa fa-check"></i><b>6.1.2</b> Statistical analysis</a></li>
<li class="chapter" data-level="6.1.3" data-path="cancer.html"><a href="cancer.html#literature-search"><i class="fa fa-check"></i><b>6.1.3</b> Literature search</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="epidemiology.html"><a href="epidemiology.html"><i class="fa fa-check"></i><b>7</b> Epidemiology</a></li>
<li class="chapter" data-level="8" data-path="pop-genetics.html"><a href="pop-genetics.html"><i class="fa fa-check"></i><b>8</b> Population Genetics</a>
<ul>
<li class="chapter" data-level="8.1" data-path="pop-genetics.html"><a href="pop-genetics.html#case-study-1-heritability-and-human-traits"><i class="fa fa-check"></i><b>8.1</b> Case study 1: Heritability and human traits</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="pop-genetics.html"><a href="pop-genetics.html#part-1"><i class="fa fa-check"></i><b>8.1.1</b> Part 1</a></li>
<li class="chapter" data-level="8.1.2" data-path="pop-genetics.html"><a href="pop-genetics.html#part-2"><i class="fa fa-check"></i><b>8.1.2</b> Part 2</a></li>
<li class="chapter" data-level="8.1.3" data-path="pop-genetics.html"><a href="pop-genetics.html#references"><i class="fa fa-check"></i><b>8.1.3</b> References</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Modules in previous years</b></span></li>
<li class="chapter" data-level="9" data-path="cancer-case2.html"><a href="cancer-case2.html"><i class="fa fa-check"></i><b>9</b> Cancer Epidemiology</a>
<ul>
<li class="chapter" data-level="9.0.1" data-path="cancer-case2.html"><a href="cancer-case2.html#scenario"><i class="fa fa-check"></i><b>9.0.1</b> Scenario</a></li>
<li class="chapter" data-level="9.0.2" data-path="cancer-case2.html"><a href="cancer-case2.html#hong-kong-population"><i class="fa fa-check"></i><b>9.0.2</b> Hong Kong population</a></li>
<li class="chapter" data-level="9.0.3" data-path="cancer-case2.html"><a href="cancer-case2.html#cancer-registry-data"><i class="fa fa-check"></i><b>9.0.3</b> Cancer registry data</a></li>
<li class="chapter" data-level="9.0.4" data-path="cancer-case2.html"><a href="cancer-case2.html#existing-cancer-funding-and-publication-data"><i class="fa fa-check"></i><b>9.0.4</b> Existing cancer funding and publication data</a></li>
<li class="chapter" data-level="9.0.5" data-path="cancer-case2.html"><a href="cancer-case2.html#open-discussion"><i class="fa fa-check"></i><b>9.0.5</b> Open discussion</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="genetic-seq.html"><a href="genetic-seq.html"><i class="fa fa-check"></i><b>10</b> Genetic sequence</a>
<ul>
<li class="chapter" data-level="10.1" data-path="genetic-seq.html"><a href="genetic-seq.html#case-study-1-genetic-sequence-analysis"><i class="fa fa-check"></i><b>10.1</b> Case study 1: Genetic sequence analysis</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="genetic-seq.html"><a href="genetic-seq.html#sequence-motif-and-k-mer"><i class="fa fa-check"></i><b>10.1.1</b> Sequence motif and k-mer</a></li>
<li class="chapter" data-level="10.1.2" data-path="genetic-seq.html"><a href="genetic-seq.html#functional-mapping"><i class="fa fa-check"></i><b>10.1.2</b> Functional mapping</a></li>
<li class="chapter" data-level="10.1.3" data-path="genetic-seq.html"><a href="genetic-seq.html#references-1"><i class="fa fa-check"></i><b>10.1.3</b> References</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="genomics-regression.html"><a href="genomics-regression.html"><i class="fa fa-check"></i><b>11</b> Genomics and prediction</a>
<ul>
<li class="chapter" data-level="11.1" data-path="genomics-regression.html"><a href="genomics-regression.html#genomics-case1"><i class="fa fa-check"></i><b>11.1</b> Case study 1: splicing fedility prediction</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="genomics-regression.html"><a href="genomics-regression.html#questions-for-discussion-1"><i class="fa fa-check"></i><b>11.1.1</b> Questions for Discussion</a></li>
<li class="chapter" data-level="11.1.2" data-path="genomics-regression.html"><a href="genomics-regression.html#hands-on-with-regression-model"><i class="fa fa-check"></i><b>11.1.2</b> Hands-on with regression model</a></li>
<li class="chapter" data-level="11.1.3" data-path="genomics-regression.html"><a href="genomics-regression.html#open-question"><i class="fa fa-check"></i><b>11.1.3</b> Open question</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Appendix</b></span></li>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html"><i class="fa fa-check"></i>Appendix A: Install R &amp; RStudio</a>
<ul>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#a.1-install-r-4.3.1"><i class="fa fa-check"></i>A.1 Install R (&gt;=4.3.1)</a>
<ul>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#r-on-windows"><i class="fa fa-check"></i>R on Windows</a></li>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#r-on-macos"><i class="fa fa-check"></i>R on macOS</a></li>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#r-on-linux-ubuntu"><i class="fa fa-check"></i>R on Linux (Ubuntu)</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#a.2-install-rstudio"><i class="fa fa-check"></i>A.2 Install RStudio</a></li>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#a.3-use-r-inside-rstudio"><i class="fa fa-check"></i>A.3 Use R inside RStudio</a>
<ul>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#r-studio"><i class="fa fa-check"></i>R studio</a></li>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#set-working-directory"><i class="fa fa-check"></i>Set working directory</a></li>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#some-general-knowledge"><i class="fa fa-check"></i>Some general knowledge</a></li>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#install-packages"><i class="fa fa-check"></i>Install packages</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#a4.-cloud-computing"><i class="fa fa-check"></i>A4. Cloud computing</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references-2.html"><a href="references-2.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Biomedical Data Science - introduction with case studies</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introClassifier" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">Chapter 4</span> Introduction to Classification<a href="introClassifier.html#introClassifier" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="visualise-logistic-and-logit-functions" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Visualise logistic and logit functions<a href="introClassifier.html#visualise-logistic-and-logit-functions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this chapter, we will focus on logistic regression for classification.
Let’s first look at what logistic and logit function look like.</p>
<div id="logistic-function" class="section level3 hasAnchor" number="4.1.1">
<h3><span class="header-section-number">4.1.1</span> Logistic function<a href="introClassifier.html#logistic-function" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s write our first function <code>logestic()</code> as follows.</p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="introClassifier.html#cb114-1" tabindex="-1"></a><span class="co"># Write your first function</span></span>
<span id="cb114-2"><a href="introClassifier.html#cb114-2" tabindex="-1"></a>logistic <span class="ot">&lt;-</span> <span class="cf">function</span>(y) {</span>
<span id="cb114-3"><a href="introClassifier.html#cb114-3" tabindex="-1"></a>  <span class="fu">exp</span>(y) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(y))</span>
<span id="cb114-4"><a href="introClassifier.html#cb114-4" tabindex="-1"></a>}</span>
<span id="cb114-5"><a href="introClassifier.html#cb114-5" tabindex="-1"></a></span>
<span id="cb114-6"><a href="introClassifier.html#cb114-6" tabindex="-1"></a><span class="co"># Try it with different values:</span></span>
<span id="cb114-7"><a href="introClassifier.html#cb114-7" tabindex="-1"></a><span class="fu">logistic</span>(<span class="fl">0.1</span>)</span>
<span id="cb114-8"><a href="introClassifier.html#cb114-8" tabindex="-1"></a><span class="co">#&gt; [1] 0.5249792</span></span>
<span id="cb114-9"><a href="introClassifier.html#cb114-9" tabindex="-1"></a><span class="fu">logistic</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="sc">-</span><span class="dv">2</span>, <span class="fl">0.5</span>, <span class="dv">3</span>, <span class="dv">5</span>))</span>
<span id="cb114-10"><a href="introClassifier.html#cb114-10" tabindex="-1"></a><span class="co">#&gt; [1] 0.04742587 0.11920292 0.62245933 0.95257413 0.99330715</span></span></code></pre></div>
<p>This is the equivalent to the built-in <code>plogis()</code> function in the <code>stat</code>
package for the
<a href="https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/Logistic">logistic distribution</a>:</p>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="introClassifier.html#cb115-1" tabindex="-1"></a><span class="fu">plogis</span>(<span class="fl">0.1</span>)</span>
<span id="cb115-2"><a href="introClassifier.html#cb115-2" tabindex="-1"></a><span class="co">#&gt; [1] 0.5249792</span></span>
<span id="cb115-3"><a href="introClassifier.html#cb115-3" tabindex="-1"></a><span class="fu">plogis</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="sc">-</span><span class="dv">2</span>, <span class="fl">0.5</span>, <span class="dv">3</span>, <span class="dv">5</span>))</span>
<span id="cb115-4"><a href="introClassifier.html#cb115-4" tabindex="-1"></a><span class="co">#&gt; [1] 0.04742587 0.11920292 0.62245933 0.95257413 0.99330715</span></span></code></pre></div>
</div>
<div id="logit-function" class="section level3 hasAnchor" number="4.1.2">
<h3><span class="header-section-number">4.1.2</span> Logit function<a href="introClassifier.html#logit-function" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now, let look at the logistic’s inverse function <code>logit()</code>, and let’s define it
manually. <strong>Note</strong>, this function only support input between 0 and 1.</p>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="introClassifier.html#cb116-1" tabindex="-1"></a><span class="co"># Write your first function</span></span>
<span id="cb116-2"><a href="introClassifier.html#cb116-2" tabindex="-1"></a>logit <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb116-3"><a href="introClassifier.html#cb116-3" tabindex="-1"></a>  <span class="fu">log</span>(x <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> x))</span>
<span id="cb116-4"><a href="introClassifier.html#cb116-4" tabindex="-1"></a>}</span>
<span id="cb116-5"><a href="introClassifier.html#cb116-5" tabindex="-1"></a></span>
<span id="cb116-6"><a href="introClassifier.html#cb116-6" tabindex="-1"></a><span class="co"># Try it with different values:</span></span>
<span id="cb116-7"><a href="introClassifier.html#cb116-7" tabindex="-1"></a><span class="fu">logit</span>(<span class="fl">0.4</span>)</span>
<span id="cb116-8"><a href="introClassifier.html#cb116-8" tabindex="-1"></a><span class="co">#&gt; [1] -0.4054651</span></span>
<span id="cb116-9"><a href="introClassifier.html#cb116-9" tabindex="-1"></a><span class="fu">logit</span>(<span class="fu">c</span>(<span class="fl">0.2</span>, <span class="fl">0.3</span>, <span class="fl">0.5</span>, <span class="fl">0.7</span>, <span class="fl">0.9</span>))</span>
<span id="cb116-10"><a href="introClassifier.html#cb116-10" tabindex="-1"></a><span class="co">#&gt; [1] -1.3862944 -0.8472979  0.0000000  0.8472979  2.1972246</span></span>
<span id="cb116-11"><a href="introClassifier.html#cb116-11" tabindex="-1"></a><span class="fu">logit</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">2</span>, <span class="fl">0.4</span>))</span>
<span id="cb116-12"><a href="introClassifier.html#cb116-12" tabindex="-1"></a><span class="co">#&gt; Warning in log(x/(1 - x)): NaNs produced</span></span>
<span id="cb116-13"><a href="introClassifier.html#cb116-13" tabindex="-1"></a><span class="co">#&gt; [1]        NaN        NaN -0.4054651</span></span></code></pre></div>
<p>Again, the built-in <code>stat</code> package’s logistic distribution has an equivalent
function <code>qlogis()</code>, though with a different name.</p>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="introClassifier.html#cb117-1" tabindex="-1"></a><span class="fu">qlogis</span>(<span class="fl">0.4</span>)</span>
<span id="cb117-2"><a href="introClassifier.html#cb117-2" tabindex="-1"></a><span class="co">#&gt; [1] -0.4054651</span></span>
<span id="cb117-3"><a href="introClassifier.html#cb117-3" tabindex="-1"></a><span class="fu">qlogis</span>(<span class="fu">c</span>(<span class="fl">0.2</span>, <span class="fl">0.3</span>, <span class="fl">0.5</span>, <span class="fl">0.7</span>, <span class="fl">0.9</span>))</span>
<span id="cb117-4"><a href="introClassifier.html#cb117-4" tabindex="-1"></a><span class="co">#&gt; [1] -1.3862944 -0.8472979  0.0000000  0.8472979  2.1972246</span></span>
<span id="cb117-5"><a href="introClassifier.html#cb117-5" tabindex="-1"></a><span class="fu">qlogis</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">2</span>, <span class="fl">0.4</span>))</span>
<span id="cb117-6"><a href="introClassifier.html#cb117-6" tabindex="-1"></a><span class="co">#&gt; Warning in qlogis(c(-1, 2, 0.4)): NaNs produced</span></span>
<span id="cb117-7"><a href="introClassifier.html#cb117-7" tabindex="-1"></a><span class="co">#&gt; [1]        NaN        NaN -0.4054651</span></span></code></pre></div>
</div>
<div id="visualise-the-distribution" class="section level3 hasAnchor" number="4.1.3">
<h3><span class="header-section-number">4.1.3</span> Visualise the distribution<a href="introClassifier.html#visualise-the-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Logisitc function</p>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb118-1"><a href="introClassifier.html#cb118-1" tabindex="-1"></a><span class="co"># You can use seq() function to generate a vector</span></span>
<span id="cb118-2"><a href="introClassifier.html#cb118-2" tabindex="-1"></a><span class="co"># Check how to use it by help(seq) or ?seq</span></span>
<span id="cb118-3"><a href="introClassifier.html#cb118-3" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">7</span>, <span class="dv">7</span>, <span class="fl">0.3</span>)</span>
<span id="cb118-4"><a href="introClassifier.html#cb118-4" tabindex="-1"></a>df <span class="ot">=</span> <span class="fu">data.frame</span>(<span class="st">&#39;x&#39;</span><span class="ot">=</span>x, <span class="st">&#39;logistic&#39;</span><span class="ot">=</span><span class="fu">plogis</span>(x))</span>
<span id="cb118-5"><a href="introClassifier.html#cb118-5" tabindex="-1"></a></span>
<span id="cb118-6"><a href="introClassifier.html#cb118-6" tabindex="-1"></a><span class="co"># You can plot by plot function</span></span>
<span id="cb118-7"><a href="introClassifier.html#cb118-7" tabindex="-1"></a><span class="co"># plot(x=df$x, y=df$logistic, type=&#39;o&#39;)</span></span>
<span id="cb118-8"><a href="introClassifier.html#cb118-8" tabindex="-1"></a></span>
<span id="cb118-9"><a href="introClassifier.html#cb118-9" tabindex="-1"></a><span class="co"># Or ggplot2</span></span>
<span id="cb118-10"><a href="introClassifier.html#cb118-10" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb118-11"><a href="introClassifier.html#cb118-11" tabindex="-1"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>logistic)) <span class="sc">+</span></span>
<span id="cb118-12"><a href="introClassifier.html#cb118-12" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_line</span>()</span></code></pre></div>
<p><img src="BMDatSci_files/figure-html/fig3-logistic-1.png" width="60%" /></p>
<p>Logit function</p>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="introClassifier.html#cb119-1" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">seq</span>(<span class="fl">0.001</span>, <span class="fl">0.999</span>, <span class="fl">0.01</span>)</span>
<span id="cb119-2"><a href="introClassifier.html#cb119-2" tabindex="-1"></a>df <span class="ot">=</span> <span class="fu">data.frame</span>(<span class="st">&#39;x&#39;</span><span class="ot">=</span>x, <span class="st">&#39;logit&#39;</span><span class="ot">=</span><span class="fu">qlogis</span>(x))</span>
<span id="cb119-3"><a href="introClassifier.html#cb119-3" tabindex="-1"></a></span>
<span id="cb119-4"><a href="introClassifier.html#cb119-4" tabindex="-1"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>logit)) <span class="sc">+</span></span>
<span id="cb119-5"><a href="introClassifier.html#cb119-5" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_line</span>()</span></code></pre></div>
<p><img src="BMDatSci_files/figure-html/fig3-logit-1.png" width="60%" /></p>
</div>
</div>
<div id="logistic-regression-on-diabetes" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> Logistic regression on Diabetes<a href="introClassifier.html#logistic-regression-on-diabetes" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="load-pima-indians-diabetes-database" class="section level3 hasAnchor" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> Load Pima Indians Diabetes Database<a href="introClassifier.html#load-pima-indians-diabetes-database" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>This <a href="https://www.rdocumentation.org/packages/mlbench/versions/2.1-3/topics/PimaIndiansDiabetes">dataset</a>
is originally from the National Institute of Diabetes and Digestive
and Kidney Diseases. The objective of the dataset is to diagnostically predict
whether or not a patient has diabetes, based on certain diagnostic measurements
included in the dataset. Several constraints were placed on the selection of
these instances from a larger database. In particular, all patients here are
females at least 21 years old of Pima Indian heritage.</p>
<p>The datasets consist of several medical predictor (independent) variables and
one target (dependent) variable, Outcome. Independent variables include the
number of pregnancies the patient has had, their BMI, insulin level, age, and
so on.</p>
<p><strong>Acknowledgement</strong>: This notebook is adapted and updated from STAT1005.</p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="introClassifier.html#cb120-1" tabindex="-1"></a><span class="co"># Install the mlbench library for loading the datasets</span></span>
<span id="cb120-2"><a href="introClassifier.html#cb120-2" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">requireNamespace</span>(<span class="st">&quot;mlbench&quot;</span>, <span class="at">quietly =</span> <span class="cn">TRUE</span>)) {</span>
<span id="cb120-3"><a href="introClassifier.html#cb120-3" tabindex="-1"></a>  <span class="fu">install.packages</span>(<span class="st">&quot;mlbench&quot;</span>)</span>
<span id="cb120-4"><a href="introClassifier.html#cb120-4" tabindex="-1"></a>}</span>
<span id="cb120-5"><a href="introClassifier.html#cb120-5" tabindex="-1"></a></span>
<span id="cb120-6"><a href="introClassifier.html#cb120-6" tabindex="-1"></a><span class="co"># Load data</span></span>
<span id="cb120-7"><a href="introClassifier.html#cb120-7" tabindex="-1"></a><span class="fu">library</span>(mlbench)</span>
<span id="cb120-8"><a href="introClassifier.html#cb120-8" tabindex="-1"></a><span class="fu">data</span>(PimaIndiansDiabetes)</span>
<span id="cb120-9"><a href="introClassifier.html#cb120-9" tabindex="-1"></a></span>
<span id="cb120-10"><a href="introClassifier.html#cb120-10" tabindex="-1"></a><span class="co"># Check the first few lines</span></span>
<span id="cb120-11"><a href="introClassifier.html#cb120-11" tabindex="-1"></a><span class="fu">dim</span>(PimaIndiansDiabetes)</span>
<span id="cb120-12"><a href="introClassifier.html#cb120-12" tabindex="-1"></a><span class="co">#&gt; [1] 768   9</span></span>
<span id="cb120-13"><a href="introClassifier.html#cb120-13" tabindex="-1"></a><span class="fu">head</span>(PimaIndiansDiabetes)</span>
<span id="cb120-14"><a href="introClassifier.html#cb120-14" tabindex="-1"></a><span class="co">#&gt;   pregnant glucose pressure triceps insulin mass pedigree age diabetes</span></span>
<span id="cb120-15"><a href="introClassifier.html#cb120-15" tabindex="-1"></a><span class="co">#&gt; 1        6     148       72      35       0 33.6    0.627  50      pos</span></span>
<span id="cb120-16"><a href="introClassifier.html#cb120-16" tabindex="-1"></a><span class="co">#&gt; 2        1      85       66      29       0 26.6    0.351  31      neg</span></span>
<span id="cb120-17"><a href="introClassifier.html#cb120-17" tabindex="-1"></a><span class="co">#&gt; 3        8     183       64       0       0 23.3    0.672  32      pos</span></span>
<span id="cb120-18"><a href="introClassifier.html#cb120-18" tabindex="-1"></a><span class="co">#&gt; 4        1      89       66      23      94 28.1    0.167  21      neg</span></span>
<span id="cb120-19"><a href="introClassifier.html#cb120-19" tabindex="-1"></a><span class="co">#&gt; 5        0     137       40      35     168 43.1    2.288  33      pos</span></span>
<span id="cb120-20"><a href="introClassifier.html#cb120-20" tabindex="-1"></a><span class="co">#&gt; 6        5     116       74       0       0 25.6    0.201  30      neg</span></span></code></pre></div>
<p>Now, let’s check two potential features: <code>glucose</code> and <code>age</code>, colored by the diabetes labels.</p>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb121-1"><a href="introClassifier.html#cb121-1" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb121-2"><a href="introClassifier.html#cb121-2" tabindex="-1"></a></span>
<span id="cb121-3"><a href="introClassifier.html#cb121-3" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data=</span>PimaIndiansDiabetes, <span class="fu">aes</span>(<span class="at">x=</span>glucose, <span class="at">y=</span>age)) <span class="sc">+</span></span>
<span id="cb121-4"><a href="introClassifier.html#cb121-4" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">color=</span>diabetes))</span></code></pre></div>
<p><img src="BMDatSci_files/figure-html/fig3-diab-scatter-1.png" width="75%" /></p>
<p>Before we start fit models, let’s split the data into training and test sets in
a 4:1 ratio. Let define it manually, though there are functions to do it
automatically.</p>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb122-1"><a href="introClassifier.html#cb122-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">0</span>)</span>
<span id="cb122-2"><a href="introClassifier.html#cb122-2" tabindex="-1"></a></span>
<span id="cb122-3"><a href="introClassifier.html#cb122-3" tabindex="-1"></a>idx_train <span class="ot">=</span> <span class="fu">sample</span>(<span class="fu">nrow</span>(PimaIndiansDiabetes), </span>
<span id="cb122-4"><a href="introClassifier.html#cb122-4" tabindex="-1"></a>                   <span class="at">size=</span><span class="fl">0.75</span><span class="sc">*</span><span class="fu">nrow</span>(PimaIndiansDiabetes),</span>
<span id="cb122-5"><a href="introClassifier.html#cb122-5" tabindex="-1"></a>                   <span class="at">replace =</span> <span class="cn">FALSE</span>)</span>
<span id="cb122-6"><a href="introClassifier.html#cb122-6" tabindex="-1"></a>df_train <span class="ot">=</span> PimaIndiansDiabetes[idx_train, ]</span>
<span id="cb122-7"><a href="introClassifier.html#cb122-7" tabindex="-1"></a>df_test  <span class="ot">=</span> PimaIndiansDiabetes[<span class="sc">-</span>idx_train, ] <span class="co"># recall the meaning of negative symbol</span></span></code></pre></div>
</div>
<div id="fit-logistic-regression" class="section level3 hasAnchor" number="4.2.2">
<h3><span class="header-section-number">4.2.2</span> Fit logistic regression<a href="introClassifier.html#fit-logistic-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In logistic regression, the predicted probability to be class 1 is:</p>
<p><span class="math display">\[P(y=1|X, W) = \sigma(w_0, x_1 * w_1 + ... + x_p * w_p)\]</span></p>
<p>where the <span class="math inline">\(\sigma()\)</span> denotes the logistic function.</p>
<p>In R, the built-in package <code>stats</code> already have functions to fit
<a href="https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/glm">generalised linear model (GLM)</a>,
including logistic regression, a type of GML.</p>
<p>Here, let’s start with the whole dataset to fit a logistic regression.</p>
<p><strong>Note</strong>, we will specify the model family as <code>binomial</code>, as the likelihood we
are using in logistic regression is a Bernoulli likelihood, a special case of
binomial likelihood when the total trial <code>n=1</code>.</p>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="introClassifier.html#cb123-1" tabindex="-1"></a><span class="co"># Define formula in different ways</span></span>
<span id="cb123-2"><a href="introClassifier.html#cb123-2" tabindex="-1"></a><span class="co"># my_formula = as.formula(diabetes ~ glucose + age)</span></span>
<span id="cb123-3"><a href="introClassifier.html#cb123-3" tabindex="-1"></a><span class="co"># my_formula = as.formula(paste(colnames(PimaIndiansDiabetes)[1:8], collapse= &quot; + &quot;))</span></span>
<span id="cb123-4"><a href="introClassifier.html#cb123-4" tabindex="-1"></a><span class="co"># my_formula = as.formula(diabetes ~ .)</span></span>
<span id="cb123-5"><a href="introClassifier.html#cb123-5" tabindex="-1"></a></span>
<span id="cb123-6"><a href="introClassifier.html#cb123-6" tabindex="-1"></a><span class="co"># Fit logistic regression</span></span>
<span id="cb123-7"><a href="introClassifier.html#cb123-7" tabindex="-1"></a>glm_res <span class="ot">&lt;-</span> <span class="fu">glm</span>(diabetes <span class="sc">~</span> ., <span class="at">data=</span>df_train, <span class="at">family =</span> binomial)</span>
<span id="cb123-8"><a href="introClassifier.html#cb123-8" tabindex="-1"></a></span>
<span id="cb123-9"><a href="introClassifier.html#cb123-9" tabindex="-1"></a><span class="co"># We can use the logLik() function to obtain the log likelihood</span></span>
<span id="cb123-10"><a href="introClassifier.html#cb123-10" tabindex="-1"></a><span class="fu">logLik</span>(glm_res)</span>
<span id="cb123-11"><a href="introClassifier.html#cb123-11" tabindex="-1"></a><span class="co">#&gt; &#39;log Lik.&#39; -281.9041 (df=9)</span></span></code></pre></div>
<p>We can use <code>summary()</code> function to see more details about the model fitting.</p>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="introClassifier.html#cb124-1" tabindex="-1"></a><span class="fu">summary</span>(glm_res)</span>
<span id="cb124-2"><a href="introClassifier.html#cb124-2" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb124-3"><a href="introClassifier.html#cb124-3" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb124-4"><a href="introClassifier.html#cb124-4" tabindex="-1"></a><span class="co">#&gt; glm(formula = diabetes ~ ., family = binomial, data = df_train)</span></span>
<span id="cb124-5"><a href="introClassifier.html#cb124-5" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb124-6"><a href="introClassifier.html#cb124-6" tabindex="-1"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb124-7"><a href="introClassifier.html#cb124-7" tabindex="-1"></a><span class="co">#&gt;              Estimate Std. Error z value Pr(&gt;|z|)    </span></span>
<span id="cb124-8"><a href="introClassifier.html#cb124-8" tabindex="-1"></a><span class="co">#&gt; (Intercept) -8.044602   0.826981  -9.728  &lt; 2e-16 ***</span></span>
<span id="cb124-9"><a href="introClassifier.html#cb124-9" tabindex="-1"></a><span class="co">#&gt; pregnant     0.130418   0.036080   3.615 0.000301 ***</span></span>
<span id="cb124-10"><a href="introClassifier.html#cb124-10" tabindex="-1"></a><span class="co">#&gt; glucose      0.032196   0.004021   8.007 1.18e-15 ***</span></span>
<span id="cb124-11"><a href="introClassifier.html#cb124-11" tabindex="-1"></a><span class="co">#&gt; pressure    -0.017158   0.006103  -2.811 0.004934 ** </span></span>
<span id="cb124-12"><a href="introClassifier.html#cb124-12" tabindex="-1"></a><span class="co">#&gt; triceps     -0.003425   0.007659  -0.447 0.654752    </span></span>
<span id="cb124-13"><a href="introClassifier.html#cb124-13" tabindex="-1"></a><span class="co">#&gt; insulin     -0.001238   0.001060  -1.169 0.242599    </span></span>
<span id="cb124-14"><a href="introClassifier.html#cb124-14" tabindex="-1"></a><span class="co">#&gt; mass         0.104029   0.018119   5.741 9.39e-09 ***</span></span>
<span id="cb124-15"><a href="introClassifier.html#cb124-15" tabindex="-1"></a><span class="co">#&gt; pedigree     0.911030   0.344362   2.646 0.008156 ** </span></span>
<span id="cb124-16"><a href="introClassifier.html#cb124-16" tabindex="-1"></a><span class="co">#&gt; age          0.012980   0.010497   1.237 0.216267    </span></span>
<span id="cb124-17"><a href="introClassifier.html#cb124-17" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb124-18"><a href="introClassifier.html#cb124-18" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb124-19"><a href="introClassifier.html#cb124-19" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb124-20"><a href="introClassifier.html#cb124-20" tabindex="-1"></a><span class="co">#&gt; (Dispersion parameter for binomial family taken to be 1)</span></span>
<span id="cb124-21"><a href="introClassifier.html#cb124-21" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb124-22"><a href="introClassifier.html#cb124-22" tabindex="-1"></a><span class="co">#&gt;     Null deviance: 756.83  on 575  degrees of freedom</span></span>
<span id="cb124-23"><a href="introClassifier.html#cb124-23" tabindex="-1"></a><span class="co">#&gt; Residual deviance: 563.81  on 567  degrees of freedom</span></span>
<span id="cb124-24"><a href="introClassifier.html#cb124-24" tabindex="-1"></a><span class="co">#&gt; AIC: 581.81</span></span>
<span id="cb124-25"><a href="introClassifier.html#cb124-25" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb124-26"><a href="introClassifier.html#cb124-26" tabindex="-1"></a><span class="co">#&gt; Number of Fisher Scoring iterations: 5</span></span></code></pre></div>
</div>
<div id="assess-on-test-data" class="section level3 hasAnchor" number="4.2.3">
<h3><span class="header-section-number">4.2.3</span> Assess on test data<a href="introClassifier.html#assess-on-test-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now, we can evaluate the accuracy of the model on the 25% test data.</p>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="introClassifier.html#cb125-1" tabindex="-1"></a><span class="co"># Train the full model on the training data</span></span>
<span id="cb125-2"><a href="introClassifier.html#cb125-2" tabindex="-1"></a>glm_train <span class="ot">&lt;-</span> <span class="fu">glm</span>(diabetes <span class="sc">~</span> ., <span class="at">data=</span>df_train, <span class="at">family =</span> binomial)</span>
<span id="cb125-3"><a href="introClassifier.html#cb125-3" tabindex="-1"></a></span>
<span id="cb125-4"><a href="introClassifier.html#cb125-4" tabindex="-1"></a><span class="co"># Predict the probability of being diabeties on test data</span></span>
<span id="cb125-5"><a href="introClassifier.html#cb125-5" tabindex="-1"></a><span class="co"># We can also set a threshold, e.g., 0.5 for the predicted label</span></span>
<span id="cb125-6"><a href="introClassifier.html#cb125-6" tabindex="-1"></a>pred_prob <span class="ot">=</span> <span class="fu">predict</span>(glm_train, df_test, <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb125-7"><a href="introClassifier.html#cb125-7" tabindex="-1"></a>pred_label <span class="ot">=</span> pred_prob <span class="sc">&gt;=</span> <span class="fl">0.5</span></span>
<span id="cb125-8"><a href="introClassifier.html#cb125-8" tabindex="-1"></a></span>
<span id="cb125-9"><a href="introClassifier.html#cb125-9" tabindex="-1"></a><span class="co"># Observed label</span></span>
<span id="cb125-10"><a href="introClassifier.html#cb125-10" tabindex="-1"></a>obse_label <span class="ot">=</span> df_test<span class="sc">$</span>diabetes <span class="sc">==</span> <span class="st">&#39;pos&#39;</span></span>
<span id="cb125-11"><a href="introClassifier.html#cb125-11" tabindex="-1"></a></span>
<span id="cb125-12"><a href="introClassifier.html#cb125-12" tabindex="-1"></a><span class="co"># Calculate the accuracy on test data</span></span>
<span id="cb125-13"><a href="introClassifier.html#cb125-13" tabindex="-1"></a><span class="co"># think how accuracy is defined</span></span>
<span id="cb125-14"><a href="introClassifier.html#cb125-14" tabindex="-1"></a><span class="co"># we can use (TN + TP) / (TN + TP + FN + FP)</span></span>
<span id="cb125-15"><a href="introClassifier.html#cb125-15" tabindex="-1"></a><span class="co"># we can also directly compare the proportion of correctness</span></span>
<span id="cb125-16"><a href="introClassifier.html#cb125-16" tabindex="-1"></a>accuracy <span class="ot">=</span> <span class="fu">mean</span>(pred_label <span class="sc">==</span> obse_label)</span>
<span id="cb125-17"><a href="introClassifier.html#cb125-17" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;Accuracy on test set:&quot;</span>, accuracy))</span>
<span id="cb125-18"><a href="introClassifier.html#cb125-18" tabindex="-1"></a><span class="co">#&gt; [1] &quot;Accuracy on test set: 0.796875&quot;</span></span></code></pre></div>
</div>
<div id="model-selection-and-diagnosis" class="section level3 hasAnchor" number="4.2.4">
<h3><span class="header-section-number">4.2.4</span> Model selection and diagnosis<a href="introClassifier.html#model-selection-and-diagnosis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="model2-new-feature-set-by-removing-triceps" class="section level4 hasAnchor" number="4.2.4.1">
<h4><span class="header-section-number">4.2.4.1</span> Model2: New feature set by removing <code>triceps</code><a href="introClassifier.html#model2-new-feature-set-by-removing-triceps" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="introClassifier.html#cb126-1" tabindex="-1"></a><span class="co"># Train the full model on the training data</span></span>
<span id="cb126-2"><a href="introClassifier.html#cb126-2" tabindex="-1"></a>glm_mod2 <span class="ot">&lt;-</span> <span class="fu">glm</span>(diabetes <span class="sc">~</span> pregnant <span class="sc">+</span> glucose <span class="sc">+</span> pressure <span class="sc">+</span> </span>
<span id="cb126-3"><a href="introClassifier.html#cb126-3" tabindex="-1"></a>                   insulin <span class="sc">+</span> mass <span class="sc">+</span> pedigree <span class="sc">+</span> age, </span>
<span id="cb126-4"><a href="introClassifier.html#cb126-4" tabindex="-1"></a>                <span class="at">data=</span>df_train, <span class="at">family =</span> binomial)</span>
<span id="cb126-5"><a href="introClassifier.html#cb126-5" tabindex="-1"></a></span>
<span id="cb126-6"><a href="introClassifier.html#cb126-6" tabindex="-1"></a><span class="fu">logLik</span>(glm_mod2)</span>
<span id="cb126-7"><a href="introClassifier.html#cb126-7" tabindex="-1"></a><span class="co">#&gt; &#39;log Lik.&#39; -282.0038 (df=8)</span></span>
<span id="cb126-8"><a href="introClassifier.html#cb126-8" tabindex="-1"></a><span class="fu">summary</span>(glm_mod2)</span>
<span id="cb126-9"><a href="introClassifier.html#cb126-9" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb126-10"><a href="introClassifier.html#cb126-10" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb126-11"><a href="introClassifier.html#cb126-11" tabindex="-1"></a><span class="co">#&gt; glm(formula = diabetes ~ pregnant + glucose + pressure + insulin + </span></span>
<span id="cb126-12"><a href="introClassifier.html#cb126-12" tabindex="-1"></a><span class="co">#&gt;     mass + pedigree + age, family = binomial, data = df_train)</span></span>
<span id="cb126-13"><a href="introClassifier.html#cb126-13" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb126-14"><a href="introClassifier.html#cb126-14" tabindex="-1"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb126-15"><a href="introClassifier.html#cb126-15" tabindex="-1"></a><span class="co">#&gt;               Estimate Std. Error z value Pr(&gt;|z|)    </span></span>
<span id="cb126-16"><a href="introClassifier.html#cb126-16" tabindex="-1"></a><span class="co">#&gt; (Intercept) -8.0317567  0.8251403  -9.734  &lt; 2e-16 ***</span></span>
<span id="cb126-17"><a href="introClassifier.html#cb126-17" tabindex="-1"></a><span class="co">#&gt; pregnant     0.1308094  0.0361230   3.621 0.000293 ***</span></span>
<span id="cb126-18"><a href="introClassifier.html#cb126-18" tabindex="-1"></a><span class="co">#&gt; glucose      0.0324606  0.0039854   8.145 3.80e-16 ***</span></span>
<span id="cb126-19"><a href="introClassifier.html#cb126-19" tabindex="-1"></a><span class="co">#&gt; pressure    -0.0175651  0.0060269  -2.914 0.003563 ** </span></span>
<span id="cb126-20"><a href="introClassifier.html#cb126-20" tabindex="-1"></a><span class="co">#&gt; insulin     -0.0014402  0.0009593  -1.501 0.133291    </span></span>
<span id="cb126-21"><a href="introClassifier.html#cb126-21" tabindex="-1"></a><span class="co">#&gt; mass         0.1018155  0.0173811   5.858 4.69e-09 ***</span></span>
<span id="cb126-22"><a href="introClassifier.html#cb126-22" tabindex="-1"></a><span class="co">#&gt; pedigree     0.9000134  0.3428652   2.625 0.008665 ** </span></span>
<span id="cb126-23"><a href="introClassifier.html#cb126-23" tabindex="-1"></a><span class="co">#&gt; age          0.0131238  0.0105147   1.248 0.211982    </span></span>
<span id="cb126-24"><a href="introClassifier.html#cb126-24" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb126-25"><a href="introClassifier.html#cb126-25" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb126-26"><a href="introClassifier.html#cb126-26" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb126-27"><a href="introClassifier.html#cb126-27" tabindex="-1"></a><span class="co">#&gt; (Dispersion parameter for binomial family taken to be 1)</span></span>
<span id="cb126-28"><a href="introClassifier.html#cb126-28" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb126-29"><a href="introClassifier.html#cb126-29" tabindex="-1"></a><span class="co">#&gt;     Null deviance: 756.83  on 575  degrees of freedom</span></span>
<span id="cb126-30"><a href="introClassifier.html#cb126-30" tabindex="-1"></a><span class="co">#&gt; Residual deviance: 564.01  on 568  degrees of freedom</span></span>
<span id="cb126-31"><a href="introClassifier.html#cb126-31" tabindex="-1"></a><span class="co">#&gt; AIC: 580.01</span></span>
<span id="cb126-32"><a href="introClassifier.html#cb126-32" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb126-33"><a href="introClassifier.html#cb126-33" tabindex="-1"></a><span class="co">#&gt; Number of Fisher Scoring iterations: 5</span></span></code></pre></div>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="introClassifier.html#cb127-1" tabindex="-1"></a><span class="co"># Predict the probability of being diabeties on test data</span></span>
<span id="cb127-2"><a href="introClassifier.html#cb127-2" tabindex="-1"></a><span class="co"># We can also set a threshold, e.g., 0.5 for the predicted label</span></span>
<span id="cb127-3"><a href="introClassifier.html#cb127-3" tabindex="-1"></a>pred_prob2 <span class="ot">=</span> <span class="fu">predict</span>(glm_mod2, df_test, <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb127-4"><a href="introClassifier.html#cb127-4" tabindex="-1"></a>pred_label2 <span class="ot">=</span> pred_prob2 <span class="sc">&gt;=</span> <span class="fl">0.5</span></span>
<span id="cb127-5"><a href="introClassifier.html#cb127-5" tabindex="-1"></a></span>
<span id="cb127-6"><a href="introClassifier.html#cb127-6" tabindex="-1"></a>accuracy2 <span class="ot">=</span> <span class="fu">mean</span>(pred_label2 <span class="sc">==</span> obse_label)</span>
<span id="cb127-7"><a href="introClassifier.html#cb127-7" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;Accuracy on test set with model2:&quot;</span>, accuracy2))</span>
<span id="cb127-8"><a href="introClassifier.html#cb127-8" tabindex="-1"></a><span class="co">#&gt; [1] &quot;Accuracy on test set with model2: 0.807291666666667&quot;</span></span></code></pre></div>
</div>
<div id="model3-new-feature-set-by-removing-triceps-and-insulin" class="section level4 hasAnchor" number="4.2.4.2">
<h4><span class="header-section-number">4.2.4.2</span> Model3: New feature set by removing <code>triceps</code> and <code>insulin</code><a href="introClassifier.html#model3-new-feature-set-by-removing-triceps-and-insulin" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="introClassifier.html#cb128-1" tabindex="-1"></a><span class="co"># Train the full model on the training data</span></span>
<span id="cb128-2"><a href="introClassifier.html#cb128-2" tabindex="-1"></a>glm_mod3 <span class="ot">&lt;-</span> <span class="fu">glm</span>(diabetes <span class="sc">~</span> pregnant <span class="sc">+</span> glucose <span class="sc">+</span> pressure <span class="sc">+</span> </span>
<span id="cb128-3"><a href="introClassifier.html#cb128-3" tabindex="-1"></a>                   mass <span class="sc">+</span> pedigree <span class="sc">+</span> age, </span>
<span id="cb128-4"><a href="introClassifier.html#cb128-4" tabindex="-1"></a>                <span class="at">data=</span>df_train, <span class="at">family =</span> binomial)</span>
<span id="cb128-5"><a href="introClassifier.html#cb128-5" tabindex="-1"></a></span>
<span id="cb128-6"><a href="introClassifier.html#cb128-6" tabindex="-1"></a><span class="fu">logLik</span>(glm_mod3)</span>
<span id="cb128-7"><a href="introClassifier.html#cb128-7" tabindex="-1"></a><span class="co">#&gt; &#39;log Lik.&#39; -283.1342 (df=7)</span></span>
<span id="cb128-8"><a href="introClassifier.html#cb128-8" tabindex="-1"></a><span class="fu">summary</span>(glm_mod3)</span>
<span id="cb128-9"><a href="introClassifier.html#cb128-9" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb128-10"><a href="introClassifier.html#cb128-10" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb128-11"><a href="introClassifier.html#cb128-11" tabindex="-1"></a><span class="co">#&gt; glm(formula = diabetes ~ pregnant + glucose + pressure + mass + </span></span>
<span id="cb128-12"><a href="introClassifier.html#cb128-12" tabindex="-1"></a><span class="co">#&gt;     pedigree + age, family = binomial, data = df_train)</span></span>
<span id="cb128-13"><a href="introClassifier.html#cb128-13" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb128-14"><a href="introClassifier.html#cb128-14" tabindex="-1"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb128-15"><a href="introClassifier.html#cb128-15" tabindex="-1"></a><span class="co">#&gt;              Estimate Std. Error z value Pr(&gt;|z|)    </span></span>
<span id="cb128-16"><a href="introClassifier.html#cb128-16" tabindex="-1"></a><span class="co">#&gt; (Intercept) -7.797803   0.802287  -9.719  &lt; 2e-16 ***</span></span>
<span id="cb128-17"><a href="introClassifier.html#cb128-17" tabindex="-1"></a><span class="co">#&gt; pregnant     0.130990   0.035957   3.643  0.00027 ***</span></span>
<span id="cb128-18"><a href="introClassifier.html#cb128-18" tabindex="-1"></a><span class="co">#&gt; glucose      0.030661   0.003755   8.164 3.23e-16 ***</span></span>
<span id="cb128-19"><a href="introClassifier.html#cb128-19" tabindex="-1"></a><span class="co">#&gt; pressure    -0.017847   0.005953  -2.998  0.00272 ** </span></span>
<span id="cb128-20"><a href="introClassifier.html#cb128-20" tabindex="-1"></a><span class="co">#&gt; mass         0.097356   0.016969   5.737 9.61e-09 ***</span></span>
<span id="cb128-21"><a href="introClassifier.html#cb128-21" tabindex="-1"></a><span class="co">#&gt; pedigree     0.824150   0.338299   2.436  0.01484 *  </span></span>
<span id="cb128-22"><a href="introClassifier.html#cb128-22" tabindex="-1"></a><span class="co">#&gt; age          0.015134   0.010426   1.452  0.14663    </span></span>
<span id="cb128-23"><a href="introClassifier.html#cb128-23" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb128-24"><a href="introClassifier.html#cb128-24" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb128-25"><a href="introClassifier.html#cb128-25" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb128-26"><a href="introClassifier.html#cb128-26" tabindex="-1"></a><span class="co">#&gt; (Dispersion parameter for binomial family taken to be 1)</span></span>
<span id="cb128-27"><a href="introClassifier.html#cb128-27" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb128-28"><a href="introClassifier.html#cb128-28" tabindex="-1"></a><span class="co">#&gt;     Null deviance: 756.83  on 575  degrees of freedom</span></span>
<span id="cb128-29"><a href="introClassifier.html#cb128-29" tabindex="-1"></a><span class="co">#&gt; Residual deviance: 566.27  on 569  degrees of freedom</span></span>
<span id="cb128-30"><a href="introClassifier.html#cb128-30" tabindex="-1"></a><span class="co">#&gt; AIC: 580.27</span></span>
<span id="cb128-31"><a href="introClassifier.html#cb128-31" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb128-32"><a href="introClassifier.html#cb128-32" tabindex="-1"></a><span class="co">#&gt; Number of Fisher Scoring iterations: 5</span></span></code></pre></div>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="introClassifier.html#cb129-1" tabindex="-1"></a><span class="co"># Predict the probability of being diabeties on test data</span></span>
<span id="cb129-2"><a href="introClassifier.html#cb129-2" tabindex="-1"></a><span class="co"># We can also set a threshold, e.g., 0.5 for the predicted label</span></span>
<span id="cb129-3"><a href="introClassifier.html#cb129-3" tabindex="-1"></a>pred_prob3 <span class="ot">=</span> <span class="fu">predict</span>(glm_mod3, df_test, <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb129-4"><a href="introClassifier.html#cb129-4" tabindex="-1"></a>pred_label3 <span class="ot">=</span> pred_prob3 <span class="sc">&gt;=</span> <span class="fl">0.5</span></span>
<span id="cb129-5"><a href="introClassifier.html#cb129-5" tabindex="-1"></a></span>
<span id="cb129-6"><a href="introClassifier.html#cb129-6" tabindex="-1"></a>accuracy3 <span class="ot">=</span> <span class="fu">mean</span>(pred_label3 <span class="sc">==</span> obse_label)</span>
<span id="cb129-7"><a href="introClassifier.html#cb129-7" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;Accuracy on test set with model3:&quot;</span>, accuracy3))</span>
<span id="cb129-8"><a href="introClassifier.html#cb129-8" tabindex="-1"></a><span class="co">#&gt; [1] &quot;Accuracy on test set with model3: 0.786458333333333&quot;</span></span></code></pre></div>
</div>
</div>
</div>
<div id="cross-validation" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> Cross-validation<a href="introClassifier.html#cross-validation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In last section, we split the whole dataset into 75% for training and 25% for
testing. However, when the dataset is small, the test set may not be big enough
and introduce high variance on the assessment.</p>
<p>One way to reduce this variance in assessment is performing cross-validation,
where we split the data into K folds and use K-1 folds for training and the
remaining fold for testing. This procedure will be repeated for fold 1 to fold
K as testing fold and all folds will be aggregated for joint assessment.</p>
<p>K is usually taken 3, 5 or 10. In extreme case that K=n_sample, we call it
leave-one-out cross-validation (LOOCV).</p>
<p>Let’s load the dataset (again) first.</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="introClassifier.html#cb130-1" tabindex="-1"></a><span class="co"># Load data</span></span>
<span id="cb130-2"><a href="introClassifier.html#cb130-2" tabindex="-1"></a><span class="fu">library</span>(mlbench)</span>
<span id="cb130-3"><a href="introClassifier.html#cb130-3" tabindex="-1"></a><span class="fu">data</span>(PimaIndiansDiabetes)</span></code></pre></div>
<p>Besides implement the cross-validation from scratch, there are packages
supporting it well, including <code>caret</code> package. We will install it and use it for
cross-validation here.</p>
<blockquote>
<p>Note, in order to calculate ROC curve later, we need to keep the predicted
probability by using <code>classProbs = TRUE</code></p>
</blockquote>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb131-1"><a href="introClassifier.html#cb131-1" tabindex="-1"></a><span class="co"># Install the caret library for cross-validation</span></span>
<span id="cb131-2"><a href="introClassifier.html#cb131-2" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">requireNamespace</span>(<span class="st">&quot;caret&quot;</span>, <span class="at">quietly =</span> <span class="cn">TRUE</span>)) {</span>
<span id="cb131-3"><a href="introClassifier.html#cb131-3" tabindex="-1"></a>  <span class="fu">install.packages</span>(<span class="st">&quot;caret&quot;</span>)</span>
<span id="cb131-4"><a href="introClassifier.html#cb131-4" tabindex="-1"></a>}</span>
<span id="cb131-5"><a href="introClassifier.html#cb131-5" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb131-6"><a href="introClassifier.html#cb131-6" tabindex="-1"></a></span>
<span id="cb131-7"><a href="introClassifier.html#cb131-7" tabindex="-1"></a><span class="co"># Define training control</span></span>
<span id="cb131-8"><a href="introClassifier.html#cb131-8" tabindex="-1"></a><span class="co"># We also want to have savePredictions=TRUE &amp; classProbs=TRUE</span></span>
<span id="cb131-9"><a href="introClassifier.html#cb131-9" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">0</span>) </span>
<span id="cb131-10"><a href="introClassifier.html#cb131-10" tabindex="-1"></a>my_trControl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">number =</span> <span class="dv">5</span>, </span>
<span id="cb131-11"><a href="introClassifier.html#cb131-11" tabindex="-1"></a>                             <span class="at">classProbs =</span> <span class="cn">TRUE</span>,</span>
<span id="cb131-12"><a href="introClassifier.html#cb131-12" tabindex="-1"></a>                             <span class="at">savePredictions =</span> <span class="cn">TRUE</span>)</span>
<span id="cb131-13"><a href="introClassifier.html#cb131-13" tabindex="-1"></a></span>
<span id="cb131-14"><a href="introClassifier.html#cb131-14" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb131-15"><a href="introClassifier.html#cb131-15" tabindex="-1"></a>cv_model <span class="ot">&lt;-</span> <span class="fu">train</span>(diabetes <span class="sc">~</span> ., <span class="at">data =</span> PimaIndiansDiabetes, </span>
<span id="cb131-16"><a href="introClassifier.html#cb131-16" tabindex="-1"></a>                  <span class="at">method =</span> <span class="st">&quot;glm&quot;</span>,</span>
<span id="cb131-17"><a href="introClassifier.html#cb131-17" tabindex="-1"></a>                  <span class="at">family=</span><span class="fu">binomial</span>(),</span>
<span id="cb131-18"><a href="introClassifier.html#cb131-18" tabindex="-1"></a>                  <span class="at">trControl =</span> my_trControl)</span>
<span id="cb131-19"><a href="introClassifier.html#cb131-19" tabindex="-1"></a></span>
<span id="cb131-20"><a href="introClassifier.html#cb131-20" tabindex="-1"></a><span class="co"># Summarize the results</span></span>
<span id="cb131-21"><a href="introClassifier.html#cb131-21" tabindex="-1"></a><span class="fu">print</span>(cv_model)</span>
<span id="cb131-22"><a href="introClassifier.html#cb131-22" tabindex="-1"></a><span class="co">#&gt; Generalized Linear Model </span></span>
<span id="cb131-23"><a href="introClassifier.html#cb131-23" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb131-24"><a href="introClassifier.html#cb131-24" tabindex="-1"></a><span class="co">#&gt; 768 samples</span></span>
<span id="cb131-25"><a href="introClassifier.html#cb131-25" tabindex="-1"></a><span class="co">#&gt;   8 predictor</span></span>
<span id="cb131-26"><a href="introClassifier.html#cb131-26" tabindex="-1"></a><span class="co">#&gt;   2 classes: &#39;neg&#39;, &#39;pos&#39; </span></span>
<span id="cb131-27"><a href="introClassifier.html#cb131-27" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb131-28"><a href="introClassifier.html#cb131-28" tabindex="-1"></a><span class="co">#&gt; No pre-processing</span></span>
<span id="cb131-29"><a href="introClassifier.html#cb131-29" tabindex="-1"></a><span class="co">#&gt; Resampling: Cross-Validated (5 fold) </span></span>
<span id="cb131-30"><a href="introClassifier.html#cb131-30" tabindex="-1"></a><span class="co">#&gt; Summary of sample sizes: 615, 614, 615, 614, 614 </span></span>
<span id="cb131-31"><a href="introClassifier.html#cb131-31" tabindex="-1"></a><span class="co">#&gt; Resampling results:</span></span>
<span id="cb131-32"><a href="introClassifier.html#cb131-32" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb131-33"><a href="introClassifier.html#cb131-33" tabindex="-1"></a><span class="co">#&gt;   Accuracy   Kappa    </span></span>
<span id="cb131-34"><a href="introClassifier.html#cb131-34" tabindex="-1"></a><span class="co">#&gt;   0.7708344  0.4695353</span></span></code></pre></div>
<p>We can also access to detailed prediction results after concatenating the K
folds:</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="introClassifier.html#cb132-1" tabindex="-1"></a><span class="fu">head</span>(cv_model<span class="sc">$</span>pred)</span>
<span id="cb132-2"><a href="introClassifier.html#cb132-2" tabindex="-1"></a><span class="co">#&gt;   pred obs       neg        pos rowIndex parameter Resample</span></span>
<span id="cb132-3"><a href="introClassifier.html#cb132-3" tabindex="-1"></a><span class="co">#&gt; 1  neg neg 0.9656694 0.03433058        4      none    Fold1</span></span>
<span id="cb132-4"><a href="introClassifier.html#cb132-4" tabindex="-1"></a><span class="co">#&gt; 2  neg neg 0.8581071 0.14189290        6      none    Fold1</span></span>
<span id="cb132-5"><a href="introClassifier.html#cb132-5" tabindex="-1"></a><span class="co">#&gt; 3  neg pos 0.9508306 0.04916940        7      none    Fold1</span></span>
<span id="cb132-6"><a href="introClassifier.html#cb132-6" tabindex="-1"></a><span class="co">#&gt; 4  neg pos 0.6541361 0.34586388       17      none    Fold1</span></span>
<span id="cb132-7"><a href="introClassifier.html#cb132-7" tabindex="-1"></a><span class="co">#&gt; 5  neg pos 0.7675666 0.23243342       20      none    Fold1</span></span>
<span id="cb132-8"><a href="introClassifier.html#cb132-8" tabindex="-1"></a><span class="co">#&gt; 6  neg pos 0.6132685 0.38673152       26      none    Fold1</span></span></code></pre></div>
<p>We can double check the accuracy:</p>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb133-1"><a href="introClassifier.html#cb133-1" tabindex="-1"></a>CV_acc <span class="ot">=</span> <span class="fu">mean</span>(cv_model<span class="sc">$</span>pred<span class="sc">$</span>pred <span class="sc">==</span> cv_model<span class="sc">$</span>pred<span class="sc">$</span>obs)</span>
<span id="cb133-2"><a href="introClassifier.html#cb133-2" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;Accuracy via 5-fold cross-validation&quot;</span>, CV_acc))</span>
<span id="cb133-3"><a href="introClassifier.html#cb133-3" tabindex="-1"></a><span class="co">#&gt; [1] &quot;Accuracy via 5-fold cross-validation 0.770833333333333&quot;</span></span></code></pre></div>
</div>
<div id="more-assessment-metrics" class="section level2 hasAnchor" number="4.4">
<h2><span class="header-section-number">4.4</span> More assessment metrics<a href="introClassifier.html#more-assessment-metrics" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="two-types-of-error" class="section level3 hasAnchor" number="4.4.1">
<h3><span class="header-section-number">4.4.1</span> Two types of error<a href="introClassifier.html#two-types-of-error" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In the above sections, we used the accuracy to perform model diagnosis, either
only on one testing dataset or aggregating cross multiple folds in cross-
validation.</p>
<p>Accuracy is a widely used metric for model evaluation, on the averaged error
rate. However, this metric still have limitations when assessing the model
performance, especially the following two:</p>
<ol style="list-style-type: decimal">
<li><p>When the samples are highly imbalance, high accuracy may not mean a good
model. For example, for a sample with 990 negative samples and 10 positive
samples, a simple model by predicting for all sample as negative will give an
accuracy of 0.99. Thus, for highly imbalanced samples, we should be careful when
interpreting the accuracy.</p></li>
<li><p>In many scenarios, our tolerance on false positive errors and false negative
errors may be different and we want to know both for a certain model. They are
often called as type I and II errors:</p></li>
</ol>
<ul>
<li>Type I error: false positive (rate)</li>
<li>Type II error: false negative (rate) - a joke way to remember what type II
mean <strong>N</strong>egative has two stripes.</li>
</ul>
<p>Here, we use the diabetes dataset and their cross-validation results above to illustrate the two types of errors and the corresponding model performance
evaluation.</p>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="introClassifier.html#cb134-1" tabindex="-1"></a><span class="co"># Let&#39;s start to define the values for the confusion matrix first</span></span>
<span id="cb134-2"><a href="introClassifier.html#cb134-2" tabindex="-1"></a><span class="co"># Recall what the difference between &amp; vs &amp;&amp;</span></span>
<span id="cb134-3"><a href="introClassifier.html#cb134-3" tabindex="-1"></a><span class="co"># Read more: https://stat.ethz.ch/R-manual/R-devel/library/base/html/Logic.html</span></span>
<span id="cb134-4"><a href="introClassifier.html#cb134-4" tabindex="-1"></a></span>
<span id="cb134-5"><a href="introClassifier.html#cb134-5" tabindex="-1"></a>TP <span class="ot">=</span> <span class="fu">sum</span>((cv_model<span class="sc">$</span>pred<span class="sc">$</span>obs <span class="sc">==</span> <span class="st">&#39;pos&#39;</span>) <span class="sc">&amp;</span> (cv_model<span class="sc">$</span>pred<span class="sc">$</span>pred <span class="sc">==</span> <span class="st">&#39;pos&#39;</span>))</span>
<span id="cb134-6"><a href="introClassifier.html#cb134-6" tabindex="-1"></a>FN <span class="ot">=</span> <span class="fu">sum</span>((cv_model<span class="sc">$</span>pred<span class="sc">$</span>obs <span class="sc">==</span> <span class="st">&#39;pos&#39;</span>) <span class="sc">&amp;</span> (cv_model<span class="sc">$</span>pred<span class="sc">$</span>pred <span class="sc">==</span> <span class="st">&#39;neg&#39;</span>))</span>
<span id="cb134-7"><a href="introClassifier.html#cb134-7" tabindex="-1"></a></span>
<span id="cb134-8"><a href="introClassifier.html#cb134-8" tabindex="-1"></a>FP <span class="ot">=</span> <span class="fu">sum</span>((cv_model<span class="sc">$</span>pred<span class="sc">$</span>obs <span class="sc">==</span> <span class="st">&#39;neg&#39;</span>) <span class="sc">&amp;</span> (cv_model<span class="sc">$</span>pred<span class="sc">$</span>pred <span class="sc">==</span> <span class="st">&#39;pos&#39;</span>))</span>
<span id="cb134-9"><a href="introClassifier.html#cb134-9" tabindex="-1"></a>TN <span class="ot">=</span> <span class="fu">sum</span>((cv_model<span class="sc">$</span>pred<span class="sc">$</span>obs <span class="sc">==</span> <span class="st">&#39;neg&#39;</span>) <span class="sc">&amp;</span> (cv_model<span class="sc">$</span>pred<span class="sc">$</span>pred <span class="sc">==</span> <span class="st">&#39;neg&#39;</span>))</span>
<span id="cb134-10"><a href="introClassifier.html#cb134-10" tabindex="-1"></a></span>
<span id="cb134-11"><a href="introClassifier.html#cb134-11" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&#39;TP, FN, FP, TN:&#39;</span>, TP, FN, FP, TN))</span>
<span id="cb134-12"><a href="introClassifier.html#cb134-12" tabindex="-1"></a><span class="co">#&gt; [1] &quot;TP, FN, FP, TN: 151 117 59 441&quot;</span></span></code></pre></div>
<p>We can also use the <code>table()</code> function to get the whole confusion matrix.
Read more about the
<a href="https://www.geeksforgeeks.org/create-a-tabular-representation-of-data-in-r-programming-table-function/">table function</a>
for counting the frequency of each element.
A similar way is the
<a href="https://www.rdocumentation.org/packages/caret/versions/3.45/topics/confusionMatrix">confusionMatrix()</a>
in <code>caret</code> package.</p>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb135-1"><a href="introClassifier.html#cb135-1" tabindex="-1"></a><span class="co"># Calculate confusion matrix</span></span>
<span id="cb135-2"><a href="introClassifier.html#cb135-2" tabindex="-1"></a>confusion_mtx <span class="ot">=</span> <span class="fu">table</span>(cv_model<span class="sc">$</span>pred[, <span class="fu">c</span>(<span class="st">&quot;obs&quot;</span>, <span class="st">&quot;pred&quot;</span>)])</span>
<span id="cb135-3"><a href="introClassifier.html#cb135-3" tabindex="-1"></a>confusion_mtx</span>
<span id="cb135-4"><a href="introClassifier.html#cb135-4" tabindex="-1"></a><span class="co">#&gt;      pred</span></span>
<span id="cb135-5"><a href="introClassifier.html#cb135-5" tabindex="-1"></a><span class="co">#&gt; obs   neg pos</span></span>
<span id="cb135-6"><a href="introClassifier.html#cb135-6" tabindex="-1"></a><span class="co">#&gt;   neg 441  59</span></span>
<span id="cb135-7"><a href="introClassifier.html#cb135-7" tabindex="-1"></a><span class="co">#&gt;   pos 117 151</span></span>
<span id="cb135-8"><a href="introClassifier.html#cb135-8" tabindex="-1"></a></span>
<span id="cb135-9"><a href="introClassifier.html#cb135-9" tabindex="-1"></a><span class="co"># similar function confusionMatrix</span></span>
<span id="cb135-10"><a href="introClassifier.html#cb135-10" tabindex="-1"></a><span class="co"># conf_mat = confusionMatrix(cv_model$pred$pred, cv_model$pred$obs)</span></span>
<span id="cb135-11"><a href="introClassifier.html#cb135-11" tabindex="-1"></a><span class="co"># conf_mat$table</span></span></code></pre></div>
<p>We can also plot out the confusion matrix</p>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="introClassifier.html#cb136-1" tabindex="-1"></a><span class="co"># Change to data.frame before using ggplot</span></span>
<span id="cb136-2"><a href="introClassifier.html#cb136-2" tabindex="-1"></a>confusion_df <span class="ot">=</span> <span class="fu">as.data.frame</span>(confusion_mtx)</span>
<span id="cb136-3"><a href="introClassifier.html#cb136-3" tabindex="-1"></a></span>
<span id="cb136-4"><a href="introClassifier.html#cb136-4" tabindex="-1"></a><span class="fu">ggplot</span>(confusion_df, <span class="fu">aes</span>(pred, obs, <span class="at">fill=</span> Freq)) <span class="sc">+</span></span>
<span id="cb136-5"><a href="introClassifier.html#cb136-5" tabindex="-1"></a>  <span class="fu">geom_tile</span>() <span class="sc">+</span> <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">label=</span>Freq)) <span class="sc">+</span> </span>
<span id="cb136-6"><a href="introClassifier.html#cb136-6" tabindex="-1"></a>  <span class="fu">scale_fill_gradient</span>(<span class="at">low=</span><span class="st">&quot;white&quot;</span>, <span class="at">high=</span><span class="st">&quot;darkgreen&quot;</span>)</span></code></pre></div>
<p><img src="BMDatSci_files/figure-html/fig-3-confusion-mtx-1.png" width="60%" /></p>
<p>Also the false positive rate, false negative rate and true negative rate.
<strong>Note</strong>, the denominator is always the number of <strong>observed</strong> samples with the
<code>same</code> label, namely they are a constant for a specific dataset.</p>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb137-1"><a href="introClassifier.html#cb137-1" tabindex="-1"></a>FPR <span class="ot">=</span> FP <span class="sc">/</span> <span class="fu">sum</span>(cv_model<span class="sc">$</span>pred<span class="sc">$</span>obs <span class="sc">==</span> <span class="st">&#39;neg&#39;</span>)</span>
<span id="cb137-2"><a href="introClassifier.html#cb137-2" tabindex="-1"></a>FNR <span class="ot">=</span> FN <span class="sc">/</span> <span class="fu">sum</span>(cv_model<span class="sc">$</span>pred<span class="sc">$</span>obs <span class="sc">==</span> <span class="st">&#39;pos&#39;</span>)</span>
<span id="cb137-3"><a href="introClassifier.html#cb137-3" tabindex="-1"></a>TPR <span class="ot">=</span> TP <span class="sc">/</span> <span class="fu">sum</span>(cv_model<span class="sc">$</span>pred<span class="sc">$</span>obs <span class="sc">==</span> <span class="st">&#39;pos&#39;</span>)</span>
<span id="cb137-4"><a href="introClassifier.html#cb137-4" tabindex="-1"></a></span>
<span id="cb137-5"><a href="introClassifier.html#cb137-5" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;False positive rate:&quot;</span>, FPR))</span>
<span id="cb137-6"><a href="introClassifier.html#cb137-6" tabindex="-1"></a><span class="co">#&gt; [1] &quot;False positive rate: 0.118&quot;</span></span>
<span id="cb137-7"><a href="introClassifier.html#cb137-7" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;False negative rate:&quot;</span>, FNR))</span>
<span id="cb137-8"><a href="introClassifier.html#cb137-8" tabindex="-1"></a><span class="co">#&gt; [1] &quot;False negative rate: 0.436567164179104&quot;</span></span>
<span id="cb137-9"><a href="introClassifier.html#cb137-9" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;True positive rate:&quot;</span>,  TPR))</span>
<span id="cb137-10"><a href="introClassifier.html#cb137-10" tabindex="-1"></a><span class="co">#&gt; [1] &quot;True positive rate: 0.563432835820896&quot;</span></span></code></pre></div>
</div>
<div id="roc-curve" class="section level3 hasAnchor" number="4.4.2">
<h3><span class="header-section-number">4.4.2</span> ROC curve<a href="introClassifier.html#roc-curve" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In the above assessment, we only used <span class="math inline">\(P&gt;0.5\)</span> to denote predicted label as
positive. We can imagine if we a lower cutoff lower, we will have more false
positives and fewer false negatives. Indeed, in different scenarios, people may
choose different level of cutoff for their tolerance of different types of
errors.</p>
<p>Let’s try cutoff <span class="math inline">\(P&gt;0.4\)</span>. Think what will you expect.</p>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="introClassifier.html#cb138-1" tabindex="-1"></a><span class="co"># Original confusion matrix</span></span>
<span id="cb138-2"><a href="introClassifier.html#cb138-2" tabindex="-1"></a><span class="fu">table</span>(cv_model<span class="sc">$</span>pred[, <span class="fu">c</span>(<span class="st">&quot;obs&quot;</span>, <span class="st">&quot;pred&quot;</span>)])</span>
<span id="cb138-3"><a href="introClassifier.html#cb138-3" tabindex="-1"></a><span class="co">#&gt;      pred</span></span>
<span id="cb138-4"><a href="introClassifier.html#cb138-4" tabindex="-1"></a><span class="co">#&gt; obs   neg pos</span></span>
<span id="cb138-5"><a href="introClassifier.html#cb138-5" tabindex="-1"></a><span class="co">#&gt;   neg 441  59</span></span>
<span id="cb138-6"><a href="introClassifier.html#cb138-6" tabindex="-1"></a><span class="co">#&gt;   pos 117 151</span></span>
<span id="cb138-7"><a href="introClassifier.html#cb138-7" tabindex="-1"></a></span>
<span id="cb138-8"><a href="introClassifier.html#cb138-8" tabindex="-1"></a><span class="co"># New confusion matrix with cutoff 0.4</span></span>
<span id="cb138-9"><a href="introClassifier.html#cb138-9" tabindex="-1"></a>cv_model<span class="sc">$</span>pred<span class="sc">$</span>pred_new <span class="ot">=</span> <span class="fu">as.integer</span>(cv_model<span class="sc">$</span>pred<span class="sc">$</span>pos <span class="sc">&gt;=</span> <span class="fl">0.4</span>)</span>
<span id="cb138-10"><a href="introClassifier.html#cb138-10" tabindex="-1"></a><span class="fu">table</span>(cv_model<span class="sc">$</span>pred[, <span class="fu">c</span>(<span class="st">&quot;obs&quot;</span>, <span class="st">&quot;pred_new&quot;</span>)])</span>
<span id="cb138-11"><a href="introClassifier.html#cb138-11" tabindex="-1"></a><span class="co">#&gt;      pred_new</span></span>
<span id="cb138-12"><a href="introClassifier.html#cb138-12" tabindex="-1"></a><span class="co">#&gt; obs     0   1</span></span>
<span id="cb138-13"><a href="introClassifier.html#cb138-13" tabindex="-1"></a><span class="co">#&gt;   neg 408  92</span></span>
<span id="cb138-14"><a href="introClassifier.html#cb138-14" tabindex="-1"></a><span class="co">#&gt;   pos  89 179</span></span></code></pre></div>
<p>Therefore, we may want to assess the model performance by varying the cutoffs
and obtain a more systematic assessment.</p>
<p>Actually, the Receiver operating characteristic (ROC) curve is what you need. It
presents the TPR (sensitivity) vs the FPR (i.e., 1 - TNR or 1 - specificity)
when varying the cutoffs.</p>
<p>In order to achieve this, we can calculate FPR and TPR manually by varying the
cutoff through a <code>for loop</code>. Read more about
<a href="https://www.datamentor.io/r-programming/for-loop/">for loop</a> and you may try
write your own and here is an example from the
<a href="https://github.com/single-cell-genetics/cardelino/blob/main/R/assessment.R#L211">cardelino package</a>.</p>
<p>For simplicity, let use an existing tool implemented in the <code>pROC</code> package to
obtain the key information for making ROC curves: <code>sensitivities</code> (TPR) and
<code>specificities</code> (1-FPR) for a list of <code>thesholds</code>:</p>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="introClassifier.html#cb139-1" tabindex="-1"></a><span class="co"># Install the pROC library for plotting ROC curve</span></span>
<span id="cb139-2"><a href="introClassifier.html#cb139-2" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">requireNamespace</span>(<span class="st">&quot;pROC&quot;</span>, <span class="at">quietly =</span> <span class="cn">TRUE</span>)) {</span>
<span id="cb139-3"><a href="introClassifier.html#cb139-3" tabindex="-1"></a>  <span class="fu">install.packages</span>(<span class="st">&quot;pROC&quot;</span>)</span>
<span id="cb139-4"><a href="introClassifier.html#cb139-4" tabindex="-1"></a>}</span>
<span id="cb139-5"><a href="introClassifier.html#cb139-5" tabindex="-1"></a></span>
<span id="cb139-6"><a href="introClassifier.html#cb139-6" tabindex="-1"></a><span class="co"># library(pROC)</span></span>
<span id="cb139-7"><a href="introClassifier.html#cb139-7" tabindex="-1"></a>roc_res <span class="ot">&lt;-</span> pROC<span class="sc">::</span><span class="fu">roc</span>(cv_model<span class="sc">$</span>pred<span class="sc">$</span>obs <span class="sc">==</span> <span class="st">&#39;pos&#39;</span>, cv_model<span class="sc">$</span>pred<span class="sc">$</span>pos)</span>
<span id="cb139-8"><a href="introClassifier.html#cb139-8" tabindex="-1"></a><span class="co">#&gt; Setting levels: control = FALSE, case = TRUE</span></span>
<span id="cb139-9"><a href="introClassifier.html#cb139-9" tabindex="-1"></a><span class="co">#&gt; Setting direction: controls &lt; cases</span></span>
<span id="cb139-10"><a href="introClassifier.html#cb139-10" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;The AUC score of this ROC curve is&quot;</span>, roc_res<span class="sc">$</span>auc))</span>
<span id="cb139-11"><a href="introClassifier.html#cb139-11" tabindex="-1"></a><span class="co">#&gt; [1] &quot;The AUC score of this ROC curve is 0.829082089552239&quot;</span></span>
<span id="cb139-12"><a href="introClassifier.html#cb139-12" tabindex="-1"></a></span>
<span id="cb139-13"><a href="introClassifier.html#cb139-13" tabindex="-1"></a>roc_table <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(</span>
<span id="cb139-14"><a href="introClassifier.html#cb139-14" tabindex="-1"></a>  roc_res[<span class="fu">c</span>(<span class="st">&quot;sensitivities&quot;</span>, <span class="st">&quot;specificities&quot;</span>, <span class="st">&quot;thresholds&quot;</span>)]</span>
<span id="cb139-15"><a href="introClassifier.html#cb139-15" tabindex="-1"></a>)</span>
<span id="cb139-16"><a href="introClassifier.html#cb139-16" tabindex="-1"></a><span class="fu">head</span>(roc_table)</span>
<span id="cb139-17"><a href="introClassifier.html#cb139-17" tabindex="-1"></a><span class="co">#&gt;   sensitivities specificities  thresholds</span></span>
<span id="cb139-18"><a href="introClassifier.html#cb139-18" tabindex="-1"></a><span class="co">#&gt; 1     1.0000000         0.000        -Inf</span></span>
<span id="cb139-19"><a href="introClassifier.html#cb139-19" tabindex="-1"></a><span class="co">#&gt; 2     1.0000000         0.002 0.001848584</span></span>
<span id="cb139-20"><a href="introClassifier.html#cb139-20" tabindex="-1"></a><span class="co">#&gt; 3     1.0000000         0.004 0.003167924</span></span>
<span id="cb139-21"><a href="introClassifier.html#cb139-21" tabindex="-1"></a><span class="co">#&gt; 4     1.0000000         0.006 0.004588208</span></span>
<span id="cb139-22"><a href="introClassifier.html#cb139-22" tabindex="-1"></a><span class="co">#&gt; 5     1.0000000         0.008 0.005750560</span></span>
<span id="cb139-23"><a href="introClassifier.html#cb139-23" tabindex="-1"></a><span class="co">#&gt; 6     0.9962687         0.008 0.007297416</span></span></code></pre></div>
<p>With this <code>roc_table</code> at hand, we can find which threshold we should use for a
certain desired FPR or TPR, for example to have <code>FPR = 0.25</code>:</p>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="introClassifier.html#cb140-1" tabindex="-1"></a>FPR <span class="ot">=</span> <span class="dv">1</span> <span class="sc">-</span> roc_table<span class="sc">$</span>specificities</span>
<span id="cb140-2"><a href="introClassifier.html#cb140-2" tabindex="-1"></a></span>
<span id="cb140-3"><a href="introClassifier.html#cb140-3" tabindex="-1"></a>idx <span class="ot">=</span> <span class="fu">which.min</span>(<span class="fu">abs</span>(FPR <span class="sc">-</span> <span class="fl">0.25</span>))</span>
<span id="cb140-4"><a href="introClassifier.html#cb140-4" tabindex="-1"></a>roc_table[idx, ]</span>
<span id="cb140-5"><a href="introClassifier.html#cb140-5" tabindex="-1"></a><span class="co">#&gt;     sensitivities specificities thresholds</span></span>
<span id="cb140-6"><a href="introClassifier.html#cb140-6" tabindex="-1"></a><span class="co">#&gt; 444     0.7462687          0.75  0.3278307</span></span>
<span id="cb140-7"><a href="introClassifier.html#cb140-7" tabindex="-1"></a></span>
<span id="cb140-8"><a href="introClassifier.html#cb140-8" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;When FPR is closest to 0.25, the threshold is&quot;</span>, roc_table[idx, <span class="dv">3</span>]))</span>
<span id="cb140-9"><a href="introClassifier.html#cb140-9" tabindex="-1"></a><span class="co">#&gt; [1] &quot;When FPR is closest to 0.25, the threshold is 0.327830708502212&quot;</span></span>
<span id="cb140-10"><a href="introClassifier.html#cb140-10" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;When FPR is closest to 0.25, the TPR is&quot;</span>, roc_table[idx, <span class="dv">1</span>]))</span>
<span id="cb140-11"><a href="introClassifier.html#cb140-11" tabindex="-1"></a><span class="co">#&gt; [1] &quot;When FPR is closest to 0.25, the TPR is 0.746268656716418&quot;</span></span></code></pre></div>
<p>By showing all thresholds, we can also directly use ggplot2 to make an ROC
curve:</p>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb141-1"><a href="introClassifier.html#cb141-1" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb141-2"><a href="introClassifier.html#cb141-2" tabindex="-1"></a><span class="co"># You can set the n.cuts to show the cutoffs on the curve</span></span>
<span id="cb141-3"><a href="introClassifier.html#cb141-3" tabindex="-1"></a>g <span class="ot">=</span> <span class="fu">ggplot</span>(roc_table, <span class="fu">aes</span>(<span class="at">x =</span> <span class="dv">1</span> <span class="sc">-</span> specificities, <span class="at">y =</span> sensitivities)) <span class="sc">+</span>   </span>
<span id="cb141-4"><a href="introClassifier.html#cb141-4" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb141-5"><a href="introClassifier.html#cb141-5" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">linetype =</span> <span class="st">&quot;dashed&quot;</span>, <span class="at">color =</span> <span class="st">&quot;grey&quot;</span>) <span class="sc">+</span></span>
<span id="cb141-6"><a href="introClassifier.html#cb141-6" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;ROC Curve&quot;</span>,</span>
<span id="cb141-7"><a href="introClassifier.html#cb141-7" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;FPR (1 - Specificity)&quot;</span>,</span>
<span id="cb141-8"><a href="introClassifier.html#cb141-8" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;TPR (Sensitivity)&quot;</span>) <span class="sc">+</span></span>
<span id="cb141-9"><a href="introClassifier.html#cb141-9" tabindex="-1"></a>  <span class="fu">coord_equal</span>()</span>
<span id="cb141-10"><a href="introClassifier.html#cb141-10" tabindex="-1"></a></span>
<span id="cb141-11"><a href="introClassifier.html#cb141-11" tabindex="-1"></a><span class="co"># Display the plot with more annotations</span></span>
<span id="cb141-12"><a href="introClassifier.html#cb141-12" tabindex="-1"></a>g <span class="sc">+</span> </span>
<span id="cb141-13"><a href="introClassifier.html#cb141-13" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="at">x=</span><span class="fl">0.8</span>, <span class="at">y=</span><span class="fl">0.1</span>, <span class="at">label=</span><span class="fu">paste</span>(<span class="st">&quot;AUC =&quot;</span>, <span class="fu">round</span>(roc_res<span class="sc">$</span>auc, <span class="dv">4</span>))) <span class="sc">+</span></span>
<span id="cb141-14"><a href="introClassifier.html#cb141-14" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">x =</span> <span class="dv">1</span> <span class="sc">-</span> roc_table[idx, <span class="dv">2</span>], <span class="at">y =</span> roc_table[idx, <span class="dv">1</span>]) <span class="sc">+</span> </span>
<span id="cb141-15"><a href="introClassifier.html#cb141-15" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="at">x =</span> <span class="dv">1</span> <span class="sc">-</span> roc_table[idx, <span class="dv">2</span>], <span class="at">y =</span> roc_table[idx, <span class="dv">1</span>],</span>
<span id="cb141-16"><a href="introClassifier.html#cb141-16" tabindex="-1"></a>            <span class="at">label =</span> <span class="fu">round</span>(roc_table[idx, <span class="dv">3</span>], <span class="dv">3</span>), <span class="at">color =</span> <span class="st">&#39;black&#39;</span>, <span class="at">hjust =</span> <span class="sc">-</span><span class="fl">0.3</span>)</span></code></pre></div>
<p><img src="BMDatSci_files/figure-html/fig3-ROC-1.png" width="75%" /></p>
</div>
<div id="homework" class="section level3 hasAnchor" number="4.4.3">
<h3><span class="header-section-number">4.4.3</span> Homework<a href="introClassifier.html#homework" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now, try another model with removing <code>triceps</code> and plot the ROC curve and
calculate the AUC score.</p>
<p>Is it higher or lower than using the full features?</p>

<!-- (ref:modulesepart) Biomedical Data Modules -->
</div>
</div>
</div>



            </section>

          </div>
        </div>
      </div>
<a href="introLinearReg.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="image-digital.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/statbiomed/BMDS-book/tree/main/01-introduction.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["BMDatSci.pdf", "BMDatSci.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
