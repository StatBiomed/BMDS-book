<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Introduction to Classification | Biomedical Data Science - introduction with case studies</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.28 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Introduction to Classification | Biomedical Data Science - introduction with case studies" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Introduction to Classification | Biomedical Data Science - introduction with case studies" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="BIOF1001 teaching team" />


<meta name="date" content="2022-09-05" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introLinearReg.html"/>
<link rel="next" href="introHypoTest.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./index.html">Biomedical Data Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#introduction-for-readers"><i class="fa fa-check"></i>Introduction for readers</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#what-we-hope-you-will-learn-from-this-course-book"><i class="fa fa-check"></i>What we hope you will learn from this course / book</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#what-we-recommend-you-do-while-reading-this-book"><i class="fa fa-check"></i>What we recommend you do while reading this book</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#last-notes"><i class="fa fa-check"></i>Last notes</a></li>
</ul></li>
<li class="part"><span><b>I Data Science Foundations</b></span></li>
<li class="chapter" data-level="1" data-path="introR.html"><a href="introR.html"><i class="fa fa-check"></i><b>1</b> Introduction to R programming</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introR.html"><a href="introR.html#data-types"><i class="fa fa-check"></i><b>1.1</b> Data types</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="introR.html"><a href="introR.html#nemeric-or-double"><i class="fa fa-check"></i><b>1.1.1</b> nemeric (or double)</a></li>
<li class="chapter" data-level="1.1.2" data-path="introR.html"><a href="introR.html#integer"><i class="fa fa-check"></i><b>1.1.2</b> integer</a></li>
<li class="chapter" data-level="1.1.3" data-path="introR.html"><a href="introR.html#logical"><i class="fa fa-check"></i><b>1.1.3</b> logical</a></li>
<li class="chapter" data-level="1.1.4" data-path="introR.html"><a href="introR.html#character"><i class="fa fa-check"></i><b>1.1.4</b> character</a></li>
<li class="chapter" data-level="1.1.5" data-path="introR.html"><a href="introR.html#memeory-usage"><i class="fa fa-check"></i><b>1.1.5</b> Memeory usage</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="introR.html"><a href="introR.html#data-structures"><i class="fa fa-check"></i><b>1.2</b> Data structures</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="introR.html"><a href="introR.html#vector"><i class="fa fa-check"></i><b>1.2.1</b> Vector</a></li>
<li class="chapter" data-level="1.2.2" data-path="introR.html"><a href="introR.html#matrix"><i class="fa fa-check"></i><b>1.2.2</b> Matrix</a></li>
<li class="chapter" data-level="1.2.3" data-path="introR.html"><a href="introR.html#list"><i class="fa fa-check"></i><b>1.2.3</b> List</a></li>
<li class="chapter" data-level="1.2.4" data-path="introR.html"><a href="introR.html#data-frame"><i class="fa fa-check"></i><b>1.2.4</b> Data Frame</a></li>
<li class="chapter" data-level="1.2.5" data-path="introR.html"><a href="introR.html#factor-vs-vector"><i class="fa fa-check"></i><b>1.2.5</b> Factor vs vector</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="introR.html"><a href="introR.html#read-and-write-files-tables"><i class="fa fa-check"></i><b>1.3</b> Read and write files (tables)</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="introR.html"><a href="introR.html#read-file"><i class="fa fa-check"></i><b>1.3.1</b> Read file</a></li>
<li class="chapter" data-level="1.3.2" data-path="introR.html"><a href="introR.html#write-file"><i class="fa fa-check"></i><b>1.3.2</b> Write file</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="introR.html"><a href="introR.html#functions-and-packages"><i class="fa fa-check"></i><b>1.4</b> Functions and Packages</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="introR.html"><a href="introR.html#install-packages"><i class="fa fa-check"></i><b>1.4.1</b> Install packages</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="introR.html"><a href="introR.html#plotting"><i class="fa fa-check"></i><b>1.5</b> Plotting</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="introR.html"><a href="introR.html#datasets"><i class="fa fa-check"></i><b>1.5.1</b> datasets</a></li>
<li class="chapter" data-level="1.5.2" data-path="introR.html"><a href="introR.html#basic-plotting"><i class="fa fa-check"></i><b>1.5.2</b> Basic plotting</a></li>
<li class="chapter" data-level="1.5.3" data-path="introR.html"><a href="introR.html#ggplot2"><i class="fa fa-check"></i><b>1.5.3</b> ggplot2</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="introR.html"><a href="introR.html#scientific-and-statistical-computating"><i class="fa fa-check"></i><b>1.6</b> Scientific and statistical computating</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="introR.html"><a href="introR.html#orders-of-operators"><i class="fa fa-check"></i><b>1.6.1</b> Orders of operators</a></li>
<li class="chapter" data-level="1.6.2" data-path="introR.html"><a href="introR.html#functions-for-statistics"><i class="fa fa-check"></i><b>1.6.2</b> Functions for statistics</a></li>
<li class="chapter" data-level="1.6.3" data-path="introR.html"><a href="introR.html#correlation"><i class="fa fa-check"></i><b>1.6.3</b> Correlation</a></li>
<li class="chapter" data-level="1.6.4" data-path="introR.html"><a href="introR.html#hypothesis-testing-t-test"><i class="fa fa-check"></i><b>1.6.4</b> Hypothesis testing (t test)</a></li>
<li class="chapter" data-level="1.6.5" data-path="introR.html"><a href="introR.html#regression"><i class="fa fa-check"></i><b>1.6.5</b> Regression</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="introR.html"><a href="introR.html#resource-links"><i class="fa fa-check"></i><b>1.7</b> Resource links</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introLinearReg.html"><a href="introLinearReg.html"><i class="fa fa-check"></i><b>2</b> Introduction to Linear Regression</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introLinearReg.html"><a href="introLinearReg.html#linear-regression-using-simulated-data"><i class="fa fa-check"></i><b>2.1</b> Linear Regression Using Simulated Data</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="introLinearReg.html"><a href="introLinearReg.html#simulating-data"><i class="fa fa-check"></i><b>2.1.1</b> Simulating data:</a></li>
<li class="chapter" data-level="2.1.2" data-path="introLinearReg.html"><a href="introLinearReg.html#model-efficacy"><i class="fa fa-check"></i><b>2.1.2</b> Model efficacy</a></li>
<li class="chapter" data-level="2.1.3" data-path="introLinearReg.html"><a href="introLinearReg.html#r-squared"><i class="fa fa-check"></i><b>2.1.3</b> <em>R-Squared</em></a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="introLinearReg.html"><a href="introLinearReg.html#least-squares-using-simulated-data"><i class="fa fa-check"></i><b>2.2</b> Least Squares Using Simulated Data</a></li>
<li class="chapter" data-level="2.3" data-path="introLinearReg.html"><a href="introLinearReg.html#diagnostic-check-of-a-fitted-regression-model"><i class="fa fa-check"></i><b>2.3</b> Diagnostic check of a fitted regression model</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="introLinearReg.html"><a href="introLinearReg.html#residual-standard-errors-rse"><i class="fa fa-check"></i><b>2.3.1</b> Residual Standard Errors (RSE)</a></li>
<li class="chapter" data-level="2.3.2" data-path="introLinearReg.html"><a href="introLinearReg.html#p-values"><i class="fa fa-check"></i><b>2.3.2</b> p-values</a></li>
<li class="chapter" data-level="2.3.3" data-path="introLinearReg.html"><a href="introLinearReg.html#f-statistics"><i class="fa fa-check"></i><b>2.3.3</b> F-statistics</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="introLinearReg.html"><a href="introLinearReg.html#simple-linear-regression-with-lm-function"><i class="fa fa-check"></i><b>2.4</b> Simple Linear Regression with <code>lm</code> function</a></li>
<li class="chapter" data-level="2.5" data-path="introLinearReg.html"><a href="introLinearReg.html#multiple-regression-with-lm-function"><i class="fa fa-check"></i><b>2.5</b> Multiple Regression with <code>lm</code> function</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="introClassifier.html"><a href="introClassifier.html"><i class="fa fa-check"></i><b>3</b> Introduction to Classification</a>
<ul>
<li class="chapter" data-level="3.1" data-path="introClassifier.html"><a href="introClassifier.html#visualise-logistic-and-logit-functions"><i class="fa fa-check"></i><b>3.1</b> Visualise logistic and logit functions</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="introClassifier.html"><a href="introClassifier.html#logistic-function"><i class="fa fa-check"></i><b>3.1.1</b> Logistic function</a></li>
<li class="chapter" data-level="3.1.2" data-path="introClassifier.html"><a href="introClassifier.html#logit-function"><i class="fa fa-check"></i><b>3.1.2</b> Logit function</a></li>
<li class="chapter" data-level="3.1.3" data-path="introClassifier.html"><a href="introClassifier.html#visualise-the-distribution"><i class="fa fa-check"></i><b>3.1.3</b> Visualise the distribution</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="introClassifier.html"><a href="introClassifier.html#logistic-regression-on-diabetes"><i class="fa fa-check"></i><b>3.2</b> Logistic regression on Diabetes</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="introClassifier.html"><a href="introClassifier.html#load-pima-indians-diabetes-database"><i class="fa fa-check"></i><b>3.2.1</b> Load Pima Indians Diabetes Database</a></li>
<li class="chapter" data-level="3.2.2" data-path="introClassifier.html"><a href="introClassifier.html#fit-logistic-regression"><i class="fa fa-check"></i><b>3.2.2</b> Fit logistic regression</a></li>
<li class="chapter" data-level="3.2.3" data-path="introClassifier.html"><a href="introClassifier.html#assess-on-test-data"><i class="fa fa-check"></i><b>3.2.3</b> Assess on test data</a></li>
<li class="chapter" data-level="3.2.4" data-path="introClassifier.html"><a href="introClassifier.html#model-selection-and-diagnosis"><i class="fa fa-check"></i><b>3.2.4</b> Model selection and diagnosis</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="introClassifier.html"><a href="introClassifier.html#cross-validation"><i class="fa fa-check"></i><b>3.3</b> Cross-validation</a></li>
<li class="chapter" data-level="3.4" data-path="introClassifier.html"><a href="introClassifier.html#more-assessment-metrics"><i class="fa fa-check"></i><b>3.4</b> More assessment metrics</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="introClassifier.html"><a href="introClassifier.html#two-types-of-error"><i class="fa fa-check"></i><b>3.4.1</b> Two types of error</a></li>
<li class="chapter" data-level="3.4.2" data-path="introClassifier.html"><a href="introClassifier.html#roc-curve"><i class="fa fa-check"></i><b>3.4.2</b> ROC curve</a></li>
<li class="chapter" data-level="3.4.3" data-path="introClassifier.html"><a href="introClassifier.html#homework"><i class="fa fa-check"></i><b>3.4.3</b> Homework</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="introHypoTest.html"><a href="introHypoTest.html"><i class="fa fa-check"></i><b>4</b> Introduction to Hypothesis testing</a></li>
<li class="part"><span><b>II Biomedical Data Modules</b></span></li>
<li class="chapter" data-level="5" data-path="genomics.html"><a href="genomics.html"><i class="fa fa-check"></i><b>5</b> Personalised Genomic Medicine</a></li>
<li class="chapter" data-level="6" data-path="image-digital.html"><a href="image-digital.html"><i class="fa fa-check"></i><b>6</b> Medical Image and Digital Health</a></li>
<li class="chapter" data-level="7" data-path="infectious-dis.html"><a href="infectious-dis.html"><i class="fa fa-check"></i><b>7</b> Infectious Disease Informatics</a></li>
<li class="chapter" data-level="8" data-path="pop-genetics.html"><a href="pop-genetics.html"><i class="fa fa-check"></i><b>8</b> Population Genetics and Diseases</a></li>
<li class="chapter" data-level="9" data-path="epidemiology.html"><a href="epidemiology.html"><i class="fa fa-check"></i><b>9</b> Epidemiology of Cancer and Other Diseases</a></li>
<li class="part"><span><b>III Appendix</b></span></li>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html"><i class="fa fa-check"></i>Appendix A: Install R &amp; RStudio</a>
<ul>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#a.1-install-r"><i class="fa fa-check"></i>A.1 Install R</a>
<ul>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#r-on-windows"><i class="fa fa-check"></i>R on Windows</a></li>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#r-on-macos"><i class="fa fa-check"></i>R on macOS</a></li>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#r-on-ubuntu"><i class="fa fa-check"></i>R on Ubuntu</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#a.2-install-rstudio"><i class="fa fa-check"></i>A.2 Install RStudio</a></li>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#a.3-use-r-inside-rstudio"><i class="fa fa-check"></i>A.3 Use R inside RStudio</a>
<ul>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#r-studio"><i class="fa fa-check"></i>R studio</a></li>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#set-working-directory"><i class="fa fa-check"></i>Set working directory</a></li>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#some-general-knowledge"><i class="fa fa-check"></i>Some general knowledge</a></li>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#install-packages-1"><i class="fa fa-check"></i>Install packages</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#a4.-cloud-computing"><i class="fa fa-check"></i>A4. Cloud computing</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Biomedical Data Science - introduction with case studies</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introClassifier" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">Chapter 3</span> Introduction to Classification<a href="introClassifier.html#introClassifier" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="visualise-logistic-and-logit-functions" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> Visualise logistic and logit functions<a href="introClassifier.html#visualise-logistic-and-logit-functions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this chapter, we will focus on logistic regression for classification.
Let’s first look at what logistic and logit function look like.</p>
<div id="logistic-function" class="section level3 hasAnchor" number="3.1.1">
<h3><span class="header-section-number">3.1.1</span> Logistic function<a href="introClassifier.html#logistic-function" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s write our first function <code>logestic()</code> as follows.</p>
<div class="sourceCode" id="cb196"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb196-1"><a href="introClassifier.html#cb196-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Write your first function</span></span>
<span id="cb196-2"><a href="introClassifier.html#cb196-2" aria-hidden="true" tabindex="-1"></a>logistic <span class="ot">&lt;-</span> <span class="cf">function</span>(y) {</span>
<span id="cb196-3"><a href="introClassifier.html#cb196-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">exp</span>(y) <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(y))</span>
<span id="cb196-4"><a href="introClassifier.html#cb196-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb196-5"><a href="introClassifier.html#cb196-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb196-6"><a href="introClassifier.html#cb196-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Try it with different values:</span></span>
<span id="cb196-7"><a href="introClassifier.html#cb196-7" aria-hidden="true" tabindex="-1"></a><span class="fu">logistic</span>(<span class="fl">0.1</span>)</span></code></pre></div>
<pre><code>## [1] 0.5249792</code></pre>
<div class="sourceCode" id="cb198"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb198-1"><a href="introClassifier.html#cb198-1" aria-hidden="true" tabindex="-1"></a><span class="fu">logistic</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="sc">-</span><span class="dv">2</span>, <span class="fl">0.5</span>, <span class="dv">3</span>, <span class="dv">5</span>))</span></code></pre></div>
<pre><code>## [1] 0.04742587 0.11920292 0.62245933 0.95257413 0.99330715</code></pre>
<p>This is the equivalent to the built-in <code>plogis()</code> function in the <code>stat</code>
package for the
<a href="https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/Logistic">logistic distribution</a>:</p>
<div class="sourceCode" id="cb200"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb200-1"><a href="introClassifier.html#cb200-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plogis</span>(<span class="fl">0.1</span>)</span></code></pre></div>
<pre><code>## [1] 0.5249792</code></pre>
<div class="sourceCode" id="cb202"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb202-1"><a href="introClassifier.html#cb202-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plogis</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="sc">-</span><span class="dv">2</span>, <span class="fl">0.5</span>, <span class="dv">3</span>, <span class="dv">5</span>))</span></code></pre></div>
<pre><code>## [1] 0.04742587 0.11920292 0.62245933 0.95257413 0.99330715</code></pre>
</div>
<div id="logit-function" class="section level3 hasAnchor" number="3.1.2">
<h3><span class="header-section-number">3.1.2</span> Logit function<a href="introClassifier.html#logit-function" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now, let look at the logistic’s inverse function <code>logit()</code>, and let’s define it
manually. <strong>Note</strong>, this function only support input between 0 and 1.</p>
<div class="sourceCode" id="cb204"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb204-1"><a href="introClassifier.html#cb204-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Write your first function</span></span>
<span id="cb204-2"><a href="introClassifier.html#cb204-2" aria-hidden="true" tabindex="-1"></a>logit <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb204-3"><a href="introClassifier.html#cb204-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">log</span>(x <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> x))</span>
<span id="cb204-4"><a href="introClassifier.html#cb204-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb204-5"><a href="introClassifier.html#cb204-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb204-6"><a href="introClassifier.html#cb204-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Try it with different values:</span></span>
<span id="cb204-7"><a href="introClassifier.html#cb204-7" aria-hidden="true" tabindex="-1"></a><span class="fu">logit</span>(<span class="fl">0.4</span>)</span></code></pre></div>
<pre><code>## [1] -0.4054651</code></pre>
<div class="sourceCode" id="cb206"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb206-1"><a href="introClassifier.html#cb206-1" aria-hidden="true" tabindex="-1"></a><span class="fu">logit</span>(<span class="fu">c</span>(<span class="fl">0.2</span>, <span class="fl">0.3</span>, <span class="fl">0.5</span>, <span class="fl">0.7</span>, <span class="fl">0.9</span>))</span></code></pre></div>
<pre><code>## [1] -1.3862944 -0.8472979  0.0000000  0.8472979  2.1972246</code></pre>
<div class="sourceCode" id="cb208"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb208-1"><a href="introClassifier.html#cb208-1" aria-hidden="true" tabindex="-1"></a><span class="fu">logit</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">2</span>, <span class="fl">0.4</span>))</span></code></pre></div>
<pre><code>## Warning in log(x/(1 - x)): NaNs produced</code></pre>
<pre><code>## [1]        NaN        NaN -0.4054651</code></pre>
<p>Again, the built-in <code>stat</code> package’s logistic distribution has an equivalent
function <code>qlogis()</code>, though with a different name.</p>
<div class="sourceCode" id="cb211"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb211-1"><a href="introClassifier.html#cb211-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qlogis</span>(<span class="fl">0.4</span>)</span></code></pre></div>
<pre><code>## [1] -0.4054651</code></pre>
<div class="sourceCode" id="cb213"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb213-1"><a href="introClassifier.html#cb213-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qlogis</span>(<span class="fu">c</span>(<span class="fl">0.2</span>, <span class="fl">0.3</span>, <span class="fl">0.5</span>, <span class="fl">0.7</span>, <span class="fl">0.9</span>))</span></code></pre></div>
<pre><code>## [1] -1.3862944 -0.8472979  0.0000000  0.8472979  2.1972246</code></pre>
<div class="sourceCode" id="cb215"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb215-1"><a href="introClassifier.html#cb215-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qlogis</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">2</span>, <span class="fl">0.4</span>))</span></code></pre></div>
<pre><code>## Warning in qlogis(c(-1, 2, 0.4)): NaNs produced</code></pre>
<pre><code>## [1]        NaN        NaN -0.4054651</code></pre>
</div>
<div id="visualise-the-distribution" class="section level3 hasAnchor" number="3.1.3">
<h3><span class="header-section-number">3.1.3</span> Visualise the distribution<a href="introClassifier.html#visualise-the-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Logisitc function</p>
<div class="sourceCode" id="cb218"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb218-1"><a href="introClassifier.html#cb218-1" aria-hidden="true" tabindex="-1"></a><span class="co"># You can use seq() function to generate a vector</span></span>
<span id="cb218-2"><a href="introClassifier.html#cb218-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Check how to use it by help(seq) or ?seq</span></span>
<span id="cb218-3"><a href="introClassifier.html#cb218-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">7</span>, <span class="dv">7</span>, <span class="fl">0.3</span>)</span>
<span id="cb218-4"><a href="introClassifier.html#cb218-4" aria-hidden="true" tabindex="-1"></a>df <span class="ot">=</span> <span class="fu">data.frame</span>(<span class="st">&#39;x&#39;</span><span class="ot">=</span>x, <span class="st">&#39;logistic&#39;</span><span class="ot">=</span><span class="fu">plogis</span>(x))</span>
<span id="cb218-5"><a href="introClassifier.html#cb218-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb218-6"><a href="introClassifier.html#cb218-6" aria-hidden="true" tabindex="-1"></a><span class="co"># You can plot by plot function</span></span>
<span id="cb218-7"><a href="introClassifier.html#cb218-7" aria-hidden="true" tabindex="-1"></a><span class="co"># plot(x=df$x, y=df$logistic, type=&#39;o&#39;)</span></span>
<span id="cb218-8"><a href="introClassifier.html#cb218-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb218-9"><a href="introClassifier.html#cb218-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Or ggplot2</span></span>
<span id="cb218-10"><a href="introClassifier.html#cb218-10" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb218-11"><a href="introClassifier.html#cb218-11" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>logistic)) <span class="sc">+</span></span>
<span id="cb218-12"><a href="introClassifier.html#cb218-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_line</span>()</span></code></pre></div>
<p><img src="BMDatSci_files/figure-html/fig3-logistic-1.png" width="60%" /></p>
<p>Logit function</p>
<div class="sourceCode" id="cb219"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb219-1"><a href="introClassifier.html#cb219-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">seq</span>(<span class="fl">0.001</span>, <span class="fl">0.999</span>, <span class="fl">0.01</span>)</span>
<span id="cb219-2"><a href="introClassifier.html#cb219-2" aria-hidden="true" tabindex="-1"></a>df <span class="ot">=</span> <span class="fu">data.frame</span>(<span class="st">&#39;x&#39;</span><span class="ot">=</span>x, <span class="st">&#39;logit&#39;</span><span class="ot">=</span><span class="fu">qlogis</span>(x))</span>
<span id="cb219-3"><a href="introClassifier.html#cb219-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb219-4"><a href="introClassifier.html#cb219-4" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>logit)) <span class="sc">+</span></span>
<span id="cb219-5"><a href="introClassifier.html#cb219-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_line</span>()</span></code></pre></div>
<p><img src="BMDatSci_files/figure-html/fig3-logit-1.png" width="60%" /></p>
</div>
</div>
<div id="logistic-regression-on-diabetes" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> Logistic regression on Diabetes<a href="introClassifier.html#logistic-regression-on-diabetes" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="load-pima-indians-diabetes-database" class="section level3 hasAnchor" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> Load Pima Indians Diabetes Database<a href="introClassifier.html#load-pima-indians-diabetes-database" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>This <a href="https://www.rdocumentation.org/packages/mlbench/versions/2.1-3/topics/PimaIndiansDiabetes">dataset</a>
is originally from the National Institute of Diabetes and Digestive
and Kidney Diseases. The objective of the dataset is to diagnostically predict
whether or not a patient has diabetes, based on certain diagnostic measurements
included in the dataset. Several constraints were placed on the selection of
these instances from a larger database. In particular, all patients here are
females at least 21 years old of Pima Indian heritage.</p>
<p>The datasets consist of several medical predictor (independent) variables and
one target (dependent) variable, Outcome. Independent variables include the
number of pregnancies the patient has had, their BMI, insulin level, age, and
so on.</p>
<p><strong>Acknowledgement</strong>: This notebook is adapted and updated from STAT1005.</p>
<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb220-1"><a href="introClassifier.html#cb220-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install the mlbench library for loading the datasets</span></span>
<span id="cb220-2"><a href="introClassifier.html#cb220-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">requireNamespace</span>(<span class="st">&quot;mlbench&quot;</span>, <span class="at">quietly =</span> <span class="cn">TRUE</span>)) {</span>
<span id="cb220-3"><a href="introClassifier.html#cb220-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">install.packages</span>(<span class="st">&quot;mlbench&quot;</span>)</span>
<span id="cb220-4"><a href="introClassifier.html#cb220-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb220-5"><a href="introClassifier.html#cb220-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb220-6"><a href="introClassifier.html#cb220-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data</span></span>
<span id="cb220-7"><a href="introClassifier.html#cb220-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlbench)</span>
<span id="cb220-8"><a href="introClassifier.html#cb220-8" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(PimaIndiansDiabetes)</span>
<span id="cb220-9"><a href="introClassifier.html#cb220-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb220-10"><a href="introClassifier.html#cb220-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Check the first few lines</span></span>
<span id="cb220-11"><a href="introClassifier.html#cb220-11" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(PimaIndiansDiabetes)</span></code></pre></div>
<pre><code>## [1] 768   9</code></pre>
<div class="sourceCode" id="cb222"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb222-1"><a href="introClassifier.html#cb222-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(PimaIndiansDiabetes)</span></code></pre></div>
<pre><code>##   pregnant glucose pressure triceps insulin mass pedigree age diabetes
## 1        6     148       72      35       0 33.6    0.627  50      pos
## 2        1      85       66      29       0 26.6    0.351  31      neg
## 3        8     183       64       0       0 23.3    0.672  32      pos
## 4        1      89       66      23      94 28.1    0.167  21      neg
## 5        0     137       40      35     168 43.1    2.288  33      pos
## 6        5     116       74       0       0 25.6    0.201  30      neg</code></pre>
<p>Now, let’s check two potential features: <code>glucose</code> and <code>age</code>, colored by the diabetes labels.</p>
<div class="sourceCode" id="cb224"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb224-1"><a href="introClassifier.html#cb224-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb224-2"><a href="introClassifier.html#cb224-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb224-3"><a href="introClassifier.html#cb224-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data=</span>PimaIndiansDiabetes, <span class="fu">aes</span>(<span class="at">x=</span>glucose, <span class="at">y=</span>age)) <span class="sc">+</span></span>
<span id="cb224-4"><a href="introClassifier.html#cb224-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">color=</span>diabetes))</span></code></pre></div>
<p><img src="BMDatSci_files/figure-html/fig3-diab-scatter-1.png" width="75%" /></p>
<p>Before we start fit models, let’s split the data into training and test sets in
a 4:1 ratio. Let define it manually, though there are functions to do it
automatically.</p>
<div class="sourceCode" id="cb225"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb225-1"><a href="introClassifier.html#cb225-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">0</span>)</span>
<span id="cb225-2"><a href="introClassifier.html#cb225-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb225-3"><a href="introClassifier.html#cb225-3" aria-hidden="true" tabindex="-1"></a>idx_train <span class="ot">=</span> <span class="fu">sample</span>(<span class="fu">nrow</span>(PimaIndiansDiabetes), </span>
<span id="cb225-4"><a href="introClassifier.html#cb225-4" aria-hidden="true" tabindex="-1"></a>                   <span class="at">size=</span><span class="fl">0.75</span><span class="sc">*</span><span class="fu">nrow</span>(PimaIndiansDiabetes),</span>
<span id="cb225-5"><a href="introClassifier.html#cb225-5" aria-hidden="true" tabindex="-1"></a>                   <span class="at">replace =</span> <span class="cn">FALSE</span>)</span>
<span id="cb225-6"><a href="introClassifier.html#cb225-6" aria-hidden="true" tabindex="-1"></a>df_train <span class="ot">=</span> PimaIndiansDiabetes[idx_train, ]</span>
<span id="cb225-7"><a href="introClassifier.html#cb225-7" aria-hidden="true" tabindex="-1"></a>df_test  <span class="ot">=</span> PimaIndiansDiabetes[<span class="sc">-</span>idx_train, ] <span class="co"># recall the meaning of negative symbol</span></span></code></pre></div>
</div>
<div id="fit-logistic-regression" class="section level3 hasAnchor" number="3.2.2">
<h3><span class="header-section-number">3.2.2</span> Fit logistic regression<a href="introClassifier.html#fit-logistic-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In logistic regression, the predicted probability to be class 1 is:</p>
<p><span class="math display">\[P(y=1|X, W) = \sigma(w_0, x_1 * w_1 + ... + x_p * w_p)\]</span></p>
<p>where the <span class="math inline">\(\sigma()\)</span> denotes the logistic function.</p>
<p>In R, the built-in package <code>stats</code> already have functions to fit
<a href="https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/glm">generalised linear model (GLM)</a>,
including logistic regression, a type of GML.</p>
<p>Here, let’s start with the whole dataset to fit a logistic regression.</p>
<p><strong>Note</strong>, we will specify the model family as <code>binomial</code>, as the likelihood we
are using in logistic regression is a Bernoulli likelihood, a special case of
binomial likelihood when the total trial <code>n=1</code>.</p>
<div class="sourceCode" id="cb226"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb226-1"><a href="introClassifier.html#cb226-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define formula in different ways</span></span>
<span id="cb226-2"><a href="introClassifier.html#cb226-2" aria-hidden="true" tabindex="-1"></a><span class="co"># my_formula = as.formula(diabetes ~ glucose + age)</span></span>
<span id="cb226-3"><a href="introClassifier.html#cb226-3" aria-hidden="true" tabindex="-1"></a><span class="co"># my_formula = as.formula(paste(colnames(PimaIndiansDiabetes)[1:8], collapse= &quot; + &quot;))</span></span>
<span id="cb226-4"><a href="introClassifier.html#cb226-4" aria-hidden="true" tabindex="-1"></a><span class="co"># my_formula = as.formula(diabetes ~ .)</span></span>
<span id="cb226-5"><a href="introClassifier.html#cb226-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb226-6"><a href="introClassifier.html#cb226-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit logistic regression</span></span>
<span id="cb226-7"><a href="introClassifier.html#cb226-7" aria-hidden="true" tabindex="-1"></a>glm_res <span class="ot">&lt;-</span> <span class="fu">glm</span>(diabetes <span class="sc">~</span> ., <span class="at">data=</span>df_train, <span class="at">family =</span> binomial)</span>
<span id="cb226-8"><a href="introClassifier.html#cb226-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb226-9"><a href="introClassifier.html#cb226-9" aria-hidden="true" tabindex="-1"></a><span class="co"># We can use the logLik() function to obtain the log likelihood</span></span>
<span id="cb226-10"><a href="introClassifier.html#cb226-10" aria-hidden="true" tabindex="-1"></a><span class="fu">logLik</span>(glm_res)</span></code></pre></div>
<pre><code>## &#39;log Lik.&#39; -281.9041 (df=9)</code></pre>
<p>We can use <code>summary()</code> function to see more details about the model fitting.</p>
<div class="sourceCode" id="cb228"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb228-1"><a href="introClassifier.html#cb228-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(glm_res)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = diabetes ~ ., family = binomial, data = df_train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.5366  -0.7691  -0.4238   0.7910   2.7698  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -8.044602   0.826981  -9.728  &lt; 2e-16 ***
## pregnant     0.130418   0.036080   3.615 0.000301 ***
## glucose      0.032196   0.004021   8.007 1.18e-15 ***
## pressure    -0.017158   0.006103  -2.811 0.004934 ** 
## triceps     -0.003425   0.007659  -0.447 0.654752    
## insulin     -0.001238   0.001060  -1.169 0.242599    
## mass         0.104029   0.018119   5.741 9.39e-09 ***
## pedigree     0.911030   0.344362   2.646 0.008156 ** 
## age          0.012980   0.010497   1.237 0.216267    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 756.83  on 575  degrees of freedom
## Residual deviance: 563.81  on 567  degrees of freedom
## AIC: 581.81
## 
## Number of Fisher Scoring iterations: 5</code></pre>
</div>
<div id="assess-on-test-data" class="section level3 hasAnchor" number="3.2.3">
<h3><span class="header-section-number">3.2.3</span> Assess on test data<a href="introClassifier.html#assess-on-test-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now, we can evaluate the accuracy of the model on the 25% test data.</p>
<div class="sourceCode" id="cb230"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb230-1"><a href="introClassifier.html#cb230-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the full model on the training data</span></span>
<span id="cb230-2"><a href="introClassifier.html#cb230-2" aria-hidden="true" tabindex="-1"></a>glm_train <span class="ot">&lt;-</span> <span class="fu">glm</span>(diabetes <span class="sc">~</span> ., <span class="at">data=</span>df_train, <span class="at">family =</span> binomial)</span>
<span id="cb230-3"><a href="introClassifier.html#cb230-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb230-4"><a href="introClassifier.html#cb230-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict the probability of being diabeties on test data</span></span>
<span id="cb230-5"><a href="introClassifier.html#cb230-5" aria-hidden="true" tabindex="-1"></a><span class="co"># We can also set a threshold, e.g., 0.5 for the predicted label</span></span>
<span id="cb230-6"><a href="introClassifier.html#cb230-6" aria-hidden="true" tabindex="-1"></a>pred_prob <span class="ot">=</span> <span class="fu">predict</span>(glm_train, df_test, <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb230-7"><a href="introClassifier.html#cb230-7" aria-hidden="true" tabindex="-1"></a>pred_label <span class="ot">=</span> pred_prob <span class="sc">&gt;=</span> <span class="fl">0.5</span></span>
<span id="cb230-8"><a href="introClassifier.html#cb230-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb230-9"><a href="introClassifier.html#cb230-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Observed label</span></span>
<span id="cb230-10"><a href="introClassifier.html#cb230-10" aria-hidden="true" tabindex="-1"></a>obse_label <span class="ot">=</span> df_test<span class="sc">$</span>diabetes <span class="sc">==</span> <span class="st">&#39;pos&#39;</span></span>
<span id="cb230-11"><a href="introClassifier.html#cb230-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb230-12"><a href="introClassifier.html#cb230-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the accuracy on test data</span></span>
<span id="cb230-13"><a href="introClassifier.html#cb230-13" aria-hidden="true" tabindex="-1"></a><span class="co"># think how accuracy is defined</span></span>
<span id="cb230-14"><a href="introClassifier.html#cb230-14" aria-hidden="true" tabindex="-1"></a><span class="co"># we can use (TN + TP) / (TN + TP + FN + FP)</span></span>
<span id="cb230-15"><a href="introClassifier.html#cb230-15" aria-hidden="true" tabindex="-1"></a><span class="co"># we can also directly compare the proportion of correctness</span></span>
<span id="cb230-16"><a href="introClassifier.html#cb230-16" aria-hidden="true" tabindex="-1"></a>accuracy <span class="ot">=</span> <span class="fu">mean</span>(pred_label <span class="sc">==</span> obse_label)</span>
<span id="cb230-17"><a href="introClassifier.html#cb230-17" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;Accuracy on test set:&quot;</span>, accuracy))</span></code></pre></div>
<pre><code>## [1] &quot;Accuracy on test set: 0.796875&quot;</code></pre>
</div>
<div id="model-selection-and-diagnosis" class="section level3 hasAnchor" number="3.2.4">
<h3><span class="header-section-number">3.2.4</span> Model selection and diagnosis<a href="introClassifier.html#model-selection-and-diagnosis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="model2-new-feature-set-by-removing-triceps" class="section level4 hasAnchor" number="3.2.4.1">
<h4><span class="header-section-number">3.2.4.1</span> Model2: New feature set by removing <code>triceps</code><a href="introClassifier.html#model2-new-feature-set-by-removing-triceps" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb232-1"><a href="introClassifier.html#cb232-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the full model on the training data</span></span>
<span id="cb232-2"><a href="introClassifier.html#cb232-2" aria-hidden="true" tabindex="-1"></a>glm_mod2 <span class="ot">&lt;-</span> <span class="fu">glm</span>(diabetes <span class="sc">~</span> pregnant <span class="sc">+</span> glucose <span class="sc">+</span> pressure <span class="sc">+</span> </span>
<span id="cb232-3"><a href="introClassifier.html#cb232-3" aria-hidden="true" tabindex="-1"></a>                   insulin <span class="sc">+</span> mass <span class="sc">+</span> pedigree <span class="sc">+</span> age, </span>
<span id="cb232-4"><a href="introClassifier.html#cb232-4" aria-hidden="true" tabindex="-1"></a>                <span class="at">data=</span>df_train, <span class="at">family =</span> binomial)</span>
<span id="cb232-5"><a href="introClassifier.html#cb232-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb232-6"><a href="introClassifier.html#cb232-6" aria-hidden="true" tabindex="-1"></a><span class="fu">logLik</span>(glm_mod2)</span></code></pre></div>
<pre><code>## &#39;log Lik.&#39; -282.0038 (df=8)</code></pre>
<div class="sourceCode" id="cb234"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb234-1"><a href="introClassifier.html#cb234-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(glm_mod2)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = diabetes ~ pregnant + glucose + pressure + insulin + 
##     mass + pedigree + age, family = binomial, data = df_train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.5083  -0.7693  -0.4240   0.8034   2.7689  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -8.0317567  0.8251403  -9.734  &lt; 2e-16 ***
## pregnant     0.1308094  0.0361230   3.621 0.000293 ***
## glucose      0.0324606  0.0039854   8.145 3.80e-16 ***
## pressure    -0.0175651  0.0060269  -2.914 0.003563 ** 
## insulin     -0.0014402  0.0009593  -1.501 0.133291    
## mass         0.1018155  0.0173811   5.858 4.69e-09 ***
## pedigree     0.9000134  0.3428652   2.625 0.008665 ** 
## age          0.0131238  0.0105147   1.248 0.211982    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 756.83  on 575  degrees of freedom
## Residual deviance: 564.01  on 568  degrees of freedom
## AIC: 580.01
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<div class="sourceCode" id="cb236"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb236-1"><a href="introClassifier.html#cb236-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict the probability of being diabeties on test data</span></span>
<span id="cb236-2"><a href="introClassifier.html#cb236-2" aria-hidden="true" tabindex="-1"></a><span class="co"># We can also set a threshold, e.g., 0.5 for the predicted label</span></span>
<span id="cb236-3"><a href="introClassifier.html#cb236-3" aria-hidden="true" tabindex="-1"></a>pred_prob2 <span class="ot">=</span> <span class="fu">predict</span>(glm_mod2, df_test, <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb236-4"><a href="introClassifier.html#cb236-4" aria-hidden="true" tabindex="-1"></a>pred_label2 <span class="ot">=</span> pred_prob2 <span class="sc">&gt;=</span> <span class="fl">0.5</span></span>
<span id="cb236-5"><a href="introClassifier.html#cb236-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb236-6"><a href="introClassifier.html#cb236-6" aria-hidden="true" tabindex="-1"></a>accuracy2 <span class="ot">=</span> <span class="fu">mean</span>(pred_label2 <span class="sc">==</span> obse_label)</span>
<span id="cb236-7"><a href="introClassifier.html#cb236-7" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;Accuracy on test set with model2:&quot;</span>, accuracy2))</span></code></pre></div>
<pre><code>## [1] &quot;Accuracy on test set with model2: 0.807291666666667&quot;</code></pre>
</div>
<div id="model3-new-feature-set-by-removing-triceps-and-insulin" class="section level4 hasAnchor" number="3.2.4.2">
<h4><span class="header-section-number">3.2.4.2</span> Model3: New feature set by removing <code>triceps</code> and <code>insulin</code><a href="introClassifier.html#model3-new-feature-set-by-removing-triceps-and-insulin" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb238-1"><a href="introClassifier.html#cb238-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the full model on the training data</span></span>
<span id="cb238-2"><a href="introClassifier.html#cb238-2" aria-hidden="true" tabindex="-1"></a>glm_mod3 <span class="ot">&lt;-</span> <span class="fu">glm</span>(diabetes <span class="sc">~</span> pregnant <span class="sc">+</span> glucose <span class="sc">+</span> pressure <span class="sc">+</span> </span>
<span id="cb238-3"><a href="introClassifier.html#cb238-3" aria-hidden="true" tabindex="-1"></a>                   mass <span class="sc">+</span> pedigree <span class="sc">+</span> age, </span>
<span id="cb238-4"><a href="introClassifier.html#cb238-4" aria-hidden="true" tabindex="-1"></a>                <span class="at">data=</span>df_train, <span class="at">family =</span> binomial)</span>
<span id="cb238-5"><a href="introClassifier.html#cb238-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb238-6"><a href="introClassifier.html#cb238-6" aria-hidden="true" tabindex="-1"></a><span class="fu">logLik</span>(glm_mod3)</span></code></pre></div>
<pre><code>## &#39;log Lik.&#39; -283.1342 (df=7)</code></pre>
<div class="sourceCode" id="cb240"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb240-1"><a href="introClassifier.html#cb240-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(glm_mod3)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = diabetes ~ pregnant + glucose + pressure + mass + 
##     pedigree + age, family = binomial, data = df_train)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.6492  -0.7697  -0.4213   0.8011   2.7414  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -7.797803   0.802287  -9.719  &lt; 2e-16 ***
## pregnant     0.130990   0.035957   3.643  0.00027 ***
## glucose      0.030661   0.003755   8.164 3.23e-16 ***
## pressure    -0.017847   0.005953  -2.998  0.00272 ** 
## mass         0.097356   0.016969   5.737 9.61e-09 ***
## pedigree     0.824150   0.338299   2.436  0.01484 *  
## age          0.015134   0.010426   1.452  0.14663    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 756.83  on 575  degrees of freedom
## Residual deviance: 566.27  on 569  degrees of freedom
## AIC: 580.27
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb242-1"><a href="introClassifier.html#cb242-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict the probability of being diabeties on test data</span></span>
<span id="cb242-2"><a href="introClassifier.html#cb242-2" aria-hidden="true" tabindex="-1"></a><span class="co"># We can also set a threshold, e.g., 0.5 for the predicted label</span></span>
<span id="cb242-3"><a href="introClassifier.html#cb242-3" aria-hidden="true" tabindex="-1"></a>pred_prob3 <span class="ot">=</span> <span class="fu">predict</span>(glm_mod3, df_test, <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb242-4"><a href="introClassifier.html#cb242-4" aria-hidden="true" tabindex="-1"></a>pred_label3 <span class="ot">=</span> pred_prob3 <span class="sc">&gt;=</span> <span class="fl">0.5</span></span>
<span id="cb242-5"><a href="introClassifier.html#cb242-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb242-6"><a href="introClassifier.html#cb242-6" aria-hidden="true" tabindex="-1"></a>accuracy3 <span class="ot">=</span> <span class="fu">mean</span>(pred_label3 <span class="sc">==</span> obse_label)</span>
<span id="cb242-7"><a href="introClassifier.html#cb242-7" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;Accuracy on test set with model3:&quot;</span>, accuracy3))</span></code></pre></div>
<pre><code>## [1] &quot;Accuracy on test set with model3: 0.786458333333333&quot;</code></pre>
</div>
</div>
</div>
<div id="cross-validation" class="section level2 hasAnchor" number="3.3">
<h2><span class="header-section-number">3.3</span> Cross-validation<a href="introClassifier.html#cross-validation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In last section, we split the whole dataset into 75% for training and 25% for
testing. However, when the dataset is small, the test set may not be big enough
and introduce high variance on the assessment.</p>
<p>One way to reduce this variance in assessment is performing cross-validation,
where we split the data into K folds and use K-1 folds for training and the
remaining fold for testing. This procedure will be repeated for fold 1 to fold
K as testing fold and all folds will be aggregated for joint assessment.</p>
<p>K is usually taken 3, 5 or 10. In extreme case that K=n_sample, we call it
leave-one-out cross-validation (LOOCV).</p>
<p>Let’s load the dataset (again) first.</p>
<div class="sourceCode" id="cb244"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb244-1"><a href="introClassifier.html#cb244-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data</span></span>
<span id="cb244-2"><a href="introClassifier.html#cb244-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlbench)</span>
<span id="cb244-3"><a href="introClassifier.html#cb244-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(PimaIndiansDiabetes)</span></code></pre></div>
<p>Besides implement the cross-validation from scratch, there are packages
supporting it well, including <code>caret</code> package. We will install it and use it for
cross-validation here.</p>
<div class="sourceCode" id="cb245"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb245-1"><a href="introClassifier.html#cb245-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install the caret library for cross-validation</span></span>
<span id="cb245-2"><a href="introClassifier.html#cb245-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">requireNamespace</span>(<span class="st">&quot;caret&quot;</span>, <span class="at">quietly =</span> <span class="cn">TRUE</span>)) {</span>
<span id="cb245-3"><a href="introClassifier.html#cb245-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">install.packages</span>(<span class="st">&quot;caret&quot;</span>)</span>
<span id="cb245-4"><a href="introClassifier.html#cb245-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb245-5"><a href="introClassifier.html#cb245-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span></code></pre></div>
<pre><code>## Loading required package: lattice</code></pre>
<div class="sourceCode" id="cb247"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb247-1"><a href="introClassifier.html#cb247-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define training control</span></span>
<span id="cb247-2"><a href="introClassifier.html#cb247-2" aria-hidden="true" tabindex="-1"></a><span class="co"># We also want to have savePredictions=TRUE &amp; classProbs=TRUE</span></span>
<span id="cb247-3"><a href="introClassifier.html#cb247-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">0</span>) </span>
<span id="cb247-4"><a href="introClassifier.html#cb247-4" aria-hidden="true" tabindex="-1"></a>my_trControl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">number =</span> <span class="dv">5</span>, </span>
<span id="cb247-5"><a href="introClassifier.html#cb247-5" aria-hidden="true" tabindex="-1"></a>                             <span class="at">classProbs =</span> <span class="cn">TRUE</span>,</span>
<span id="cb247-6"><a href="introClassifier.html#cb247-6" aria-hidden="true" tabindex="-1"></a>                             <span class="at">savePredictions =</span> <span class="cn">TRUE</span>)</span>
<span id="cb247-7"><a href="introClassifier.html#cb247-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb247-8"><a href="introClassifier.html#cb247-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb247-9"><a href="introClassifier.html#cb247-9" aria-hidden="true" tabindex="-1"></a>cv_model <span class="ot">&lt;-</span> <span class="fu">train</span>(diabetes <span class="sc">~</span> ., <span class="at">data =</span> PimaIndiansDiabetes, </span>
<span id="cb247-10"><a href="introClassifier.html#cb247-10" aria-hidden="true" tabindex="-1"></a>                  <span class="at">method =</span> <span class="st">&quot;glm&quot;</span>,</span>
<span id="cb247-11"><a href="introClassifier.html#cb247-11" aria-hidden="true" tabindex="-1"></a>                  <span class="at">family=</span><span class="fu">binomial</span>(),</span>
<span id="cb247-12"><a href="introClassifier.html#cb247-12" aria-hidden="true" tabindex="-1"></a>                  <span class="at">trControl =</span> my_trControl)</span>
<span id="cb247-13"><a href="introClassifier.html#cb247-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb247-14"><a href="introClassifier.html#cb247-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Summarize the results</span></span>
<span id="cb247-15"><a href="introClassifier.html#cb247-15" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(cv_model)</span></code></pre></div>
<pre><code>## Generalized Linear Model 
## 
## 768 samples
##   8 predictor
##   2 classes: &#39;neg&#39;, &#39;pos&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 615, 614, 615, 614, 614 
## Resampling results:
## 
##   Accuracy   Kappa    
##   0.7708344  0.4695353</code></pre>
<p>We can also access to detailed prediction results after concatenating the K
folds:</p>
<div class="sourceCode" id="cb249"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb249-1"><a href="introClassifier.html#cb249-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(cv_model<span class="sc">$</span>pred)</span></code></pre></div>
<pre><code>##   pred obs       neg        pos rowIndex parameter Resample
## 1  neg neg 0.9656694 0.03433058        4      none    Fold1
## 2  neg neg 0.8581071 0.14189290        6      none    Fold1
## 3  neg pos 0.9508306 0.04916940        7      none    Fold1
## 4  neg pos 0.6541361 0.34586388       17      none    Fold1
## 5  neg pos 0.7675666 0.23243342       20      none    Fold1
## 6  neg pos 0.6132685 0.38673152       26      none    Fold1</code></pre>
<p>We can double check the accuracy:</p>
<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb251-1"><a href="introClassifier.html#cb251-1" aria-hidden="true" tabindex="-1"></a>CV_acc <span class="ot">=</span> <span class="fu">mean</span>(cv_model<span class="sc">$</span>pred<span class="sc">$</span>pred <span class="sc">==</span> cv_model<span class="sc">$</span>pred<span class="sc">$</span>obs)</span>
<span id="cb251-2"><a href="introClassifier.html#cb251-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;Accuracy via 5-fold cross-validation&quot;</span>, CV_acc))</span></code></pre></div>
<pre><code>## [1] &quot;Accuracy via 5-fold cross-validation 0.770833333333333&quot;</code></pre>
</div>
<div id="more-assessment-metrics" class="section level2 hasAnchor" number="3.4">
<h2><span class="header-section-number">3.4</span> More assessment metrics<a href="introClassifier.html#more-assessment-metrics" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="two-types-of-error" class="section level3 hasAnchor" number="3.4.1">
<h3><span class="header-section-number">3.4.1</span> Two types of error<a href="introClassifier.html#two-types-of-error" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In the above sections, we used the accuracy to perform model diagnosis, either
only on one testing dataset or aggregating cross multiple folds in cross-
validation.</p>
<p>Accuracy is a widely used metric for model evaluation, on the averaged error
rate. However, this metric still have limitations when assessing the model
performance, especially the following two:</p>
<ol style="list-style-type: decimal">
<li><p>When the samples are highly imbalance, high accuracy may not mean a good
model. For example, for a sample with 990 negative samples and 10 positive
samples, a simple model by predicting for all sample as negative will give an
accuracy of 0.99. Thus, for highly imbalanced samples, we should be careful when
interpreting the accuracy.</p></li>
<li><p>In many scenarios, our tolerance on false positive errors and false negative
errors may be different and we want to know both for a certain model. They are
often called as type I and II errors:</p></li>
</ol>
<ul>
<li>Type I error: false positive (rate)</li>
<li>Type II error: false negative (rate) - a joke way to remember what type II
mean <strong>N</strong>egative has two stripes.</li>
</ul>
<p>Here, we use the diabetes dataset and their cross-validation results above to illustrate the two types of errors and the corresponding model performance
evaluation.</p>
<div class="sourceCode" id="cb253"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb253-1"><a href="introClassifier.html#cb253-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let&#39;s start to define the values for the confusion matrix first</span></span>
<span id="cb253-2"><a href="introClassifier.html#cb253-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Recall what the difference between &amp; vs &amp;&amp;</span></span>
<span id="cb253-3"><a href="introClassifier.html#cb253-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Read more: https://stat.ethz.ch/R-manual/R-devel/library/base/html/Logic.html</span></span>
<span id="cb253-4"><a href="introClassifier.html#cb253-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb253-5"><a href="introClassifier.html#cb253-5" aria-hidden="true" tabindex="-1"></a>TP <span class="ot">=</span> <span class="fu">sum</span>((cv_model<span class="sc">$</span>pred<span class="sc">$</span>obs <span class="sc">==</span> <span class="st">&#39;pos&#39;</span>) <span class="sc">&amp;</span> (cv_model<span class="sc">$</span>pred<span class="sc">$</span>pred <span class="sc">==</span> <span class="st">&#39;pos&#39;</span>))</span>
<span id="cb253-6"><a href="introClassifier.html#cb253-6" aria-hidden="true" tabindex="-1"></a>FN <span class="ot">=</span> <span class="fu">sum</span>((cv_model<span class="sc">$</span>pred<span class="sc">$</span>obs <span class="sc">==</span> <span class="st">&#39;pos&#39;</span>) <span class="sc">&amp;</span> (cv_model<span class="sc">$</span>pred<span class="sc">$</span>pred <span class="sc">==</span> <span class="st">&#39;neg&#39;</span>))</span>
<span id="cb253-7"><a href="introClassifier.html#cb253-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb253-8"><a href="introClassifier.html#cb253-8" aria-hidden="true" tabindex="-1"></a>FP <span class="ot">=</span> <span class="fu">sum</span>((cv_model<span class="sc">$</span>pred<span class="sc">$</span>obs <span class="sc">==</span> <span class="st">&#39;neg&#39;</span>) <span class="sc">&amp;</span> (cv_model<span class="sc">$</span>pred<span class="sc">$</span>pred <span class="sc">==</span> <span class="st">&#39;pos&#39;</span>))</span>
<span id="cb253-9"><a href="introClassifier.html#cb253-9" aria-hidden="true" tabindex="-1"></a>TN <span class="ot">=</span> <span class="fu">sum</span>((cv_model<span class="sc">$</span>pred<span class="sc">$</span>obs <span class="sc">==</span> <span class="st">&#39;neg&#39;</span>) <span class="sc">&amp;</span> (cv_model<span class="sc">$</span>pred<span class="sc">$</span>pred <span class="sc">==</span> <span class="st">&#39;neg&#39;</span>))</span>
<span id="cb253-10"><a href="introClassifier.html#cb253-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb253-11"><a href="introClassifier.html#cb253-11" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&#39;TP, FN, FP, TN:&#39;</span>, TP, FN, FP, TN))</span></code></pre></div>
<pre><code>## [1] &quot;TP, FN, FP, TN: 151 117 59 441&quot;</code></pre>
<p>We can also use the <code>table()</code> function to get the whole confusion matrix.
Read more about the
<a href="https://www.geeksforgeeks.org/create-a-tabular-representation-of-data-in-r-programming-table-function/">table function</a>
for counting the frequency of each element.
A similar way is the
<a href="https://www.rdocumentation.org/packages/caret/versions/3.45/topics/confusionMatrix">confusionMatrix()</a>
in <code>caret</code> package.</p>
<div class="sourceCode" id="cb255"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb255-1"><a href="introClassifier.html#cb255-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate confusion matrix</span></span>
<span id="cb255-2"><a href="introClassifier.html#cb255-2" aria-hidden="true" tabindex="-1"></a>confusion_mtx <span class="ot">=</span> <span class="fu">table</span>(cv_model<span class="sc">$</span>pred[, <span class="fu">c</span>(<span class="st">&quot;obs&quot;</span>, <span class="st">&quot;pred&quot;</span>)])</span>
<span id="cb255-3"><a href="introClassifier.html#cb255-3" aria-hidden="true" tabindex="-1"></a>confusion_mtx</span></code></pre></div>
<pre><code>##      pred
## obs   neg pos
##   neg 441  59
##   pos 117 151</code></pre>
<div class="sourceCode" id="cb257"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb257-1"><a href="introClassifier.html#cb257-1" aria-hidden="true" tabindex="-1"></a><span class="co"># similar function confusionMatrix</span></span>
<span id="cb257-2"><a href="introClassifier.html#cb257-2" aria-hidden="true" tabindex="-1"></a><span class="co"># conf_mat = confusionMatrix(cv_model$pred$pred, cv_model$pred$obs)</span></span>
<span id="cb257-3"><a href="introClassifier.html#cb257-3" aria-hidden="true" tabindex="-1"></a><span class="co"># conf_mat$table</span></span></code></pre></div>
<p>We can also plot out the confusion matrix</p>
<div class="sourceCode" id="cb258"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb258-1"><a href="introClassifier.html#cb258-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Change to data.frame before using ggplot</span></span>
<span id="cb258-2"><a href="introClassifier.html#cb258-2" aria-hidden="true" tabindex="-1"></a>confusion_df <span class="ot">=</span> <span class="fu">as.data.frame</span>(confusion_mtx)</span>
<span id="cb258-3"><a href="introClassifier.html#cb258-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb258-4"><a href="introClassifier.html#cb258-4" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(confusion_df, <span class="fu">aes</span>(pred, obs, <span class="at">fill=</span> Freq)) <span class="sc">+</span></span>
<span id="cb258-5"><a href="introClassifier.html#cb258-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_tile</span>() <span class="sc">+</span> <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">label=</span>Freq)) <span class="sc">+</span> </span>
<span id="cb258-6"><a href="introClassifier.html#cb258-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_gradient</span>(<span class="at">low=</span><span class="st">&quot;white&quot;</span>, <span class="at">high=</span><span class="st">&quot;darkgreen&quot;</span>)</span></code></pre></div>
<p><img src="BMDatSci_files/figure-html/fig-3-confusion-mtx-1.png" width="60%" /></p>
<p>Also the false positive rate, false negative rate and true negative rate.
<strong>Note</strong>, the denominator is always the number of <strong>observed</strong> samples with the
<code>same</code> label, namely they are a constant for a specific dataset.</p>
<div class="sourceCode" id="cb259"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb259-1"><a href="introClassifier.html#cb259-1" aria-hidden="true" tabindex="-1"></a>FPR <span class="ot">=</span> FP <span class="sc">/</span> <span class="fu">sum</span>(cv_model<span class="sc">$</span>pred<span class="sc">$</span>obs <span class="sc">==</span> <span class="st">&#39;neg&#39;</span>)</span>
<span id="cb259-2"><a href="introClassifier.html#cb259-2" aria-hidden="true" tabindex="-1"></a>FNR <span class="ot">=</span> FN <span class="sc">/</span> <span class="fu">sum</span>(cv_model<span class="sc">$</span>pred<span class="sc">$</span>obs <span class="sc">==</span> <span class="st">&#39;pos&#39;</span>)</span>
<span id="cb259-3"><a href="introClassifier.html#cb259-3" aria-hidden="true" tabindex="-1"></a>TPR <span class="ot">=</span> TP <span class="sc">/</span> <span class="fu">sum</span>(cv_model<span class="sc">$</span>pred<span class="sc">$</span>obs <span class="sc">==</span> <span class="st">&#39;pos&#39;</span>)</span>
<span id="cb259-4"><a href="introClassifier.html#cb259-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb259-5"><a href="introClassifier.html#cb259-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;False positive rate:&quot;</span>, FPR))</span></code></pre></div>
<pre><code>## [1] &quot;False positive rate: 0.118&quot;</code></pre>
<div class="sourceCode" id="cb261"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb261-1"><a href="introClassifier.html#cb261-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;False negative rate:&quot;</span>, FNR))</span></code></pre></div>
<pre><code>## [1] &quot;False negative rate: 0.436567164179104&quot;</code></pre>
<div class="sourceCode" id="cb263"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb263-1"><a href="introClassifier.html#cb263-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;True positive rate:&quot;</span>,  TPR))</span></code></pre></div>
<pre><code>## [1] &quot;True positive rate: 0.563432835820896&quot;</code></pre>
</div>
<div id="roc-curve" class="section level3 hasAnchor" number="3.4.2">
<h3><span class="header-section-number">3.4.2</span> ROC curve<a href="introClassifier.html#roc-curve" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In the above assessment, we only used <span class="math inline">\(P&gt;0.5\)</span> to denote predicted label as
positive. We can imagine if we a lower cutoff lower, we will have more false
positives and fewer false negatives. Indeed, in different scenarios, people may
choose different level of cutoff for their tolerance of different types of
errors.</p>
<p>Let’s try cutoff <span class="math inline">\(P&gt;0.4\)</span>. Think what will you expect.</p>
<div class="sourceCode" id="cb265"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb265-1"><a href="introClassifier.html#cb265-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Original confusion matrix</span></span>
<span id="cb265-2"><a href="introClassifier.html#cb265-2" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(cv_model<span class="sc">$</span>pred[, <span class="fu">c</span>(<span class="st">&quot;obs&quot;</span>, <span class="st">&quot;pred&quot;</span>)])</span></code></pre></div>
<pre><code>##      pred
## obs   neg pos
##   neg 441  59
##   pos 117 151</code></pre>
<div class="sourceCode" id="cb267"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb267-1"><a href="introClassifier.html#cb267-1" aria-hidden="true" tabindex="-1"></a><span class="co"># New confusion matrix with cutoff 0.4</span></span>
<span id="cb267-2"><a href="introClassifier.html#cb267-2" aria-hidden="true" tabindex="-1"></a>cv_model<span class="sc">$</span>pred<span class="sc">$</span>pred_new <span class="ot">=</span> <span class="fu">as.integer</span>(cv_model<span class="sc">$</span>pred<span class="sc">$</span>pos <span class="sc">&gt;=</span> <span class="fl">0.4</span>)</span>
<span id="cb267-3"><a href="introClassifier.html#cb267-3" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(cv_model<span class="sc">$</span>pred[, <span class="fu">c</span>(<span class="st">&quot;obs&quot;</span>, <span class="st">&quot;pred_new&quot;</span>)])</span></code></pre></div>
<pre><code>##      pred_new
## obs     0   1
##   neg 408  92
##   pos  89 179</code></pre>
<p>Therefore, we may want to assess the model performance by varying the cutoffs
and obtain a more systematic assessment.</p>
<p>Actually, the Receiver operating characteristic (ROC) curve is what you need. It
presents the TPR (sensitivity) vs the FPR (i.e., 1 - TNR or 1 - specificity)
when varying the cutoffs.</p>
<p>In order to achieve this, we can calculate FPR and TPR manually by varying the
cutoff through a <code>for loop</code>. Read more about
<a href="https://www.datamentor.io/r-programming/for-loop/">for loop</a> and you may try
write your own and here is an example from the
<a href="https://github.com/single-cell-genetics/cardelino/blob/main/R/assessment.R#L211">cardelino package</a>.</p>
<p>For simplicity, let use an existing tool implemented in the <code>plotROC</code> package:
<code>plotROC::geom_roc()</code> that is compatible with ggplot2.</p>
<div class="sourceCode" id="cb269"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb269-1"><a href="introClassifier.html#cb269-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Install the plotROC library for plotting ROC curve</span></span>
<span id="cb269-2"><a href="introClassifier.html#cb269-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">requireNamespace</span>(<span class="st">&quot;plotROC&quot;</span>, <span class="at">quietly =</span> <span class="cn">TRUE</span>)) {</span>
<span id="cb269-3"><a href="introClassifier.html#cb269-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">install.packages</span>(<span class="st">&quot;plotROC&quot;</span>)</span>
<span id="cb269-4"><a href="introClassifier.html#cb269-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb269-5"><a href="introClassifier.html#cb269-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb269-6"><a href="introClassifier.html#cb269-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb269-7"><a href="introClassifier.html#cb269-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(plotROC)</span>
<span id="cb269-8"><a href="introClassifier.html#cb269-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb269-9"><a href="introClassifier.html#cb269-9" aria-hidden="true" tabindex="-1"></a><span class="co"># You can set the n.cuts to show the cutoffs on the curve</span></span>
<span id="cb269-10"><a href="introClassifier.html#cb269-10" aria-hidden="true" tabindex="-1"></a>g <span class="ot">=</span> <span class="fu">ggplot</span>(cv_model<span class="sc">$</span>pred, <span class="fu">aes</span>(<span class="at">m =</span> pos, <span class="at">d =</span> <span class="fu">as.integer</span>(obs<span class="sc">==</span><span class="st">&#39;pos&#39;</span>))) <span class="sc">+</span>   </span>
<span id="cb269-11"><a href="introClassifier.html#cb269-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_roc</span>(<span class="at">n.cuts=</span><span class="dv">7</span>, <span class="at">hjust =</span> <span class="sc">-</span><span class="fl">0.4</span>, <span class="at">vjust =</span> <span class="fl">1.5</span>) <span class="sc">+</span> </span>
<span id="cb269-12"><a href="introClassifier.html#cb269-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_equal</span>() <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">&quot;ROC curve&quot;</span>)</span>
<span id="cb269-13"><a href="introClassifier.html#cb269-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb269-14"><a href="introClassifier.html#cb269-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate AUC from the graph</span></span>
<span id="cb269-15"><a href="introClassifier.html#cb269-15" aria-hidden="true" tabindex="-1"></a>AUC_val <span class="ot">=</span> <span class="fu">calc_auc</span>(g)<span class="sc">$</span>AUC</span>
<span id="cb269-16"><a href="introClassifier.html#cb269-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb269-17"><a href="introClassifier.html#cb269-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the plot</span></span>
<span id="cb269-18"><a href="introClassifier.html#cb269-18" aria-hidden="true" tabindex="-1"></a>g <span class="sc">+</span> <span class="fu">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="at">x=</span><span class="fl">0.8</span>, <span class="at">y=</span><span class="fl">0.1</span>, <span class="at">label=</span><span class="fu">paste</span>(<span class="st">&quot;AUC =&quot;</span>, <span class="fu">round</span>(AUC_val, <span class="dv">4</span>)))</span></code></pre></div>
<p><img src="BMDatSci_files/figure-html/fig3-ROC-1.png" width="75%" /></p>
</div>
<div id="homework" class="section level3 hasAnchor" number="3.4.3">
<h3><span class="header-section-number">3.4.3</span> Homework<a href="introClassifier.html#homework" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now, try another model with removing <code>triceps</code> and plot the ROC curve and
calculate the AUC score.</p>
<p>Is it higher or lower than using the full features?</p>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introLinearReg.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="introHypoTest.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/statbiomed/BMDS-book/tree/main/01-introduction.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["BMDatSci.pdf", "BMDatSci.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
