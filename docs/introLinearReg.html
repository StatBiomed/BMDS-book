<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Introduction to Linear Regression | Biomedical Data Science - introduction with case studies</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.35 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Introduction to Linear Regression | Biomedical Data Science - introduction with case studies" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Introduction to Linear Regression | Biomedical Data Science - introduction with case studies" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="BIOF1001 teaching team" />


<meta name="date" content="2023-09-05" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introR.html"/>
<link rel="next" href="introClassifier.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./index.html">Biomedical Data Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#introduction-for-readers"><i class="fa fa-check"></i>Introduction for readers</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#what-you-will-learn-from-this-coursebook"><i class="fa fa-check"></i>What you will learn from this course/book</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#what-we-recommend-you-do-while-reading-this-book"><i class="fa fa-check"></i>What we recommend you do while reading this book</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#other-reference-books"><i class="fa fa-check"></i>Other reference books</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="part"><span><b>I Data Science Foundations</b></span></li>
<li class="chapter" data-level="1" data-path="introR.html"><a href="introR.html"><i class="fa fa-check"></i><b>1</b> Introduction to R programming</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introR.html"><a href="introR.html#data-types"><i class="fa fa-check"></i><b>1.1</b> Data types</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="introR.html"><a href="introR.html#nemeric-or-double"><i class="fa fa-check"></i><b>1.1.1</b> nemeric (or double)</a></li>
<li class="chapter" data-level="1.1.2" data-path="introR.html"><a href="introR.html#integer"><i class="fa fa-check"></i><b>1.1.2</b> integer</a></li>
<li class="chapter" data-level="1.1.3" data-path="introR.html"><a href="introR.html#logical"><i class="fa fa-check"></i><b>1.1.3</b> logical</a></li>
<li class="chapter" data-level="1.1.4" data-path="introR.html"><a href="introR.html#character"><i class="fa fa-check"></i><b>1.1.4</b> character</a></li>
<li class="chapter" data-level="1.1.5" data-path="introR.html"><a href="introR.html#memeory-usage"><i class="fa fa-check"></i><b>1.1.5</b> Memeory usage</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="introR.html"><a href="introR.html#data-structures"><i class="fa fa-check"></i><b>1.2</b> Data structures</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="introR.html"><a href="introR.html#vector"><i class="fa fa-check"></i><b>1.2.1</b> Vector</a></li>
<li class="chapter" data-level="1.2.2" data-path="introR.html"><a href="introR.html#matrix"><i class="fa fa-check"></i><b>1.2.2</b> Matrix</a></li>
<li class="chapter" data-level="1.2.3" data-path="introR.html"><a href="introR.html#list"><i class="fa fa-check"></i><b>1.2.3</b> List</a></li>
<li class="chapter" data-level="1.2.4" data-path="introR.html"><a href="introR.html#data-frame"><i class="fa fa-check"></i><b>1.2.4</b> Data Frame</a></li>
<li class="chapter" data-level="1.2.5" data-path="introR.html"><a href="introR.html#factor-vs-vector"><i class="fa fa-check"></i><b>1.2.5</b> Factor vs vector</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="introR.html"><a href="introR.html#read-and-write-files-tables"><i class="fa fa-check"></i><b>1.3</b> Read and write files (tables)</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="introR.html"><a href="introR.html#read-file"><i class="fa fa-check"></i><b>1.3.1</b> Read file</a></li>
<li class="chapter" data-level="1.3.2" data-path="introR.html"><a href="introR.html#write-file"><i class="fa fa-check"></i><b>1.3.2</b> Write file</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="introR.html"><a href="introR.html#functions-and-packages"><i class="fa fa-check"></i><b>1.4</b> Functions and Packages</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="introR.html"><a href="introR.html#install-packages"><i class="fa fa-check"></i><b>1.4.1</b> Install packages</a></li>
<li class="chapter" data-level="1.4.2" data-path="introR.html"><a href="introR.html#apply-function-repeatly"><i class="fa fa-check"></i><b>1.4.2</b> Apply function repeatly</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="introR.html"><a href="introR.html#plotting"><i class="fa fa-check"></i><b>1.5</b> Plotting</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="introR.html"><a href="introR.html#datasets"><i class="fa fa-check"></i><b>1.5.1</b> datasets</a></li>
<li class="chapter" data-level="1.5.2" data-path="introR.html"><a href="introR.html#basic-plotting"><i class="fa fa-check"></i><b>1.5.2</b> Basic plotting</a></li>
<li class="chapter" data-level="1.5.3" data-path="introR.html"><a href="introR.html#ggplot2"><i class="fa fa-check"></i><b>1.5.3</b> ggplot2</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="introR.html"><a href="introR.html#scientific-and-statistical-computating"><i class="fa fa-check"></i><b>1.6</b> Scientific and statistical computating</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="introR.html"><a href="introR.html#orders-of-operators"><i class="fa fa-check"></i><b>1.6.1</b> Orders of operators</a></li>
<li class="chapter" data-level="1.6.2" data-path="introR.html"><a href="introR.html#functions-for-statistics"><i class="fa fa-check"></i><b>1.6.2</b> Functions for statistics</a></li>
<li class="chapter" data-level="1.6.3" data-path="introR.html"><a href="introR.html#correlation"><i class="fa fa-check"></i><b>1.6.3</b> Correlation</a></li>
<li class="chapter" data-level="1.6.4" data-path="introR.html"><a href="introR.html#hypothesis-testing-t-test"><i class="fa fa-check"></i><b>1.6.4</b> Hypothesis testing (t test)</a></li>
<li class="chapter" data-level="1.6.5" data-path="introR.html"><a href="introR.html#regression"><i class="fa fa-check"></i><b>1.6.5</b> Regression</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="introR.html"><a href="introR.html#resource-links"><i class="fa fa-check"></i><b>1.7</b> Resource links</a></li>
<li class="chapter" data-level="1.8" data-path="introR.html"><a href="introR.html#exercises"><i class="fa fa-check"></i><b>1.8</b> Exercises</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="introR.html"><a href="introR.html#exercises-p1"><i class="fa fa-check"></i><b>1.8.1</b> Part 1. Basics (~40min)</a></li>
<li class="chapter" data-level="1.8.2" data-path="introR.html"><a href="introR.html#exercises-p2"><i class="fa fa-check"></i><b>1.8.2</b> Part 2. Making plotting (~40min)</a></li>
<li class="chapter" data-level="1.8.3" data-path="introR.html"><a href="introR.html#exercises-p3"><i class="fa fa-check"></i><b>1.8.3</b> Part 3. For loop and repeating processing (~40min)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introLinearReg.html"><a href="introLinearReg.html"><i class="fa fa-check"></i><b>2</b> Introduction to Linear Regression</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introLinearReg.html"><a href="introLinearReg.html#linear-regression-using-simulated-data"><i class="fa fa-check"></i><b>2.1</b> Linear Regression Using Simulated Data</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="introLinearReg.html"><a href="introLinearReg.html#simulating-data"><i class="fa fa-check"></i><b>2.1.1</b> Simulating data:</a></li>
<li class="chapter" data-level="2.1.2" data-path="introLinearReg.html"><a href="introLinearReg.html#model-efficacy"><i class="fa fa-check"></i><b>2.1.2</b> Model efficacy</a></li>
<li class="chapter" data-level="2.1.3" data-path="introLinearReg.html"><a href="introLinearReg.html#r-squared"><i class="fa fa-check"></i><b>2.1.3</b> <em>R-Squared</em></a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="introLinearReg.html"><a href="introLinearReg.html#least-squares-using-simulated-data"><i class="fa fa-check"></i><b>2.2</b> Least Squares Using Simulated Data</a></li>
<li class="chapter" data-level="2.3" data-path="introLinearReg.html"><a href="introLinearReg.html#diagnostic-check-of-a-fitted-regression-model"><i class="fa fa-check"></i><b>2.3</b> Diagnostic check of a fitted regression model</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="introLinearReg.html"><a href="introLinearReg.html#residual-standard-errors-rse"><i class="fa fa-check"></i><b>2.3.1</b> Residual Standard Errors (RSE)</a></li>
<li class="chapter" data-level="2.3.2" data-path="introLinearReg.html"><a href="introLinearReg.html#p-values"><i class="fa fa-check"></i><b>2.3.2</b> p-values</a></li>
<li class="chapter" data-level="2.3.3" data-path="introLinearReg.html"><a href="introLinearReg.html#f-statistics"><i class="fa fa-check"></i><b>2.3.3</b> F-statistics</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="introLinearReg.html"><a href="introLinearReg.html#simple-linear-regression-with-lm-function"><i class="fa fa-check"></i><b>2.4</b> Simple Linear Regression with <code>lm</code> function</a></li>
<li class="chapter" data-level="2.5" data-path="introLinearReg.html"><a href="introLinearReg.html#multiple-regression-with-lm-function"><i class="fa fa-check"></i><b>2.5</b> Multiple Regression with <code>lm</code> function</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="introClassifier.html"><a href="introClassifier.html"><i class="fa fa-check"></i><b>3</b> Introduction to Classification</a>
<ul>
<li class="chapter" data-level="3.1" data-path="introClassifier.html"><a href="introClassifier.html#visualise-logistic-and-logit-functions"><i class="fa fa-check"></i><b>3.1</b> Visualise logistic and logit functions</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="introClassifier.html"><a href="introClassifier.html#logistic-function"><i class="fa fa-check"></i><b>3.1.1</b> Logistic function</a></li>
<li class="chapter" data-level="3.1.2" data-path="introClassifier.html"><a href="introClassifier.html#logit-function"><i class="fa fa-check"></i><b>3.1.2</b> Logit function</a></li>
<li class="chapter" data-level="3.1.3" data-path="introClassifier.html"><a href="introClassifier.html#visualise-the-distribution"><i class="fa fa-check"></i><b>3.1.3</b> Visualise the distribution</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="introClassifier.html"><a href="introClassifier.html#logistic-regression-on-diabetes"><i class="fa fa-check"></i><b>3.2</b> Logistic regression on Diabetes</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="introClassifier.html"><a href="introClassifier.html#load-pima-indians-diabetes-database"><i class="fa fa-check"></i><b>3.2.1</b> Load Pima Indians Diabetes Database</a></li>
<li class="chapter" data-level="3.2.2" data-path="introClassifier.html"><a href="introClassifier.html#fit-logistic-regression"><i class="fa fa-check"></i><b>3.2.2</b> Fit logistic regression</a></li>
<li class="chapter" data-level="3.2.3" data-path="introClassifier.html"><a href="introClassifier.html#assess-on-test-data"><i class="fa fa-check"></i><b>3.2.3</b> Assess on test data</a></li>
<li class="chapter" data-level="3.2.4" data-path="introClassifier.html"><a href="introClassifier.html#model-selection-and-diagnosis"><i class="fa fa-check"></i><b>3.2.4</b> Model selection and diagnosis</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="introClassifier.html"><a href="introClassifier.html#cross-validation"><i class="fa fa-check"></i><b>3.3</b> Cross-validation</a></li>
<li class="chapter" data-level="3.4" data-path="introClassifier.html"><a href="introClassifier.html#more-assessment-metrics"><i class="fa fa-check"></i><b>3.4</b> More assessment metrics</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="introClassifier.html"><a href="introClassifier.html#two-types-of-error"><i class="fa fa-check"></i><b>3.4.1</b> Two types of error</a></li>
<li class="chapter" data-level="3.4.2" data-path="introClassifier.html"><a href="introClassifier.html#roc-curve"><i class="fa fa-check"></i><b>3.4.2</b> ROC curve</a></li>
<li class="chapter" data-level="3.4.3" data-path="introClassifier.html"><a href="introClassifier.html#homework"><i class="fa fa-check"></i><b>3.4.3</b> Homework</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="introHypoTest.html"><a href="introHypoTest.html"><i class="fa fa-check"></i><b>4</b> Introduction to Hypothesis testing</a>
<ul>
<li class="chapter" data-level="4.1" data-path="introHypoTest.html"><a href="introHypoTest.html#hypothesis-testing-and-p-value"><i class="fa fa-check"></i><b>4.1</b> Hypothesis testing and <em>p</em> value</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="introHypoTest.html"><a href="introHypoTest.html#example-1-probability-of-rolling-a-six"><i class="fa fa-check"></i><b>4.1.1</b> Example 1: probability of rolling a six?</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="introHypoTest.html"><a href="introHypoTest.html#permutation-test"><i class="fa fa-check"></i><b>4.2</b> Permutation test</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="introHypoTest.html"><a href="introHypoTest.html#example-2-difference-in-birth-weight"><i class="fa fa-check"></i><b>4.2.1</b> Example 2: difference in birth weight</a></li>
<li class="chapter" data-level="4.2.2" data-path="introHypoTest.html"><a href="introHypoTest.html#null-distribution-approximated-by-resampling"><i class="fa fa-check"></i><b>4.2.2</b> Null distribution approximated by resampling</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="introHypoTest.html"><a href="introHypoTest.html#t-test"><i class="fa fa-check"></i><b>4.3</b> <em>t</em> test</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="introHypoTest.html"><a href="introHypoTest.html#derivation-of-t-distribution"><i class="fa fa-check"></i><b>4.3.1</b> Derivation of t distribution</a></li>
<li class="chapter" data-level="4.3.2" data-path="introHypoTest.html"><a href="introHypoTest.html#direct-use-of-t.test"><i class="fa fa-check"></i><b>4.3.2</b> Direct use of <code>t.test()</code></a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="introHypoTest.html"><a href="introHypoTest.html#glm-test"><i class="fa fa-check"></i><b>4.4</b> GLM test</a></li>
<li class="chapter" data-level="4.5" data-path="introHypoTest.html"><a href="introHypoTest.html#multiple-testing"><i class="fa fa-check"></i><b>4.5</b> Multiple testing</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="introHypoTest.html"><a href="introHypoTest.html#null-distribution-of-test-statistic"><i class="fa fa-check"></i><b>4.5.1</b> Null distribution (of test statistic)</a></li>
<li class="chapter" data-level="4.5.2" data-path="introHypoTest.html"><a href="introHypoTest.html#null-distribution-of-p-value"><i class="fa fa-check"></i><b>4.5.2</b> Null distribution of p value</a></li>
<li class="chapter" data-level="4.5.3" data-path="introHypoTest.html"><a href="introHypoTest.html#minimal-p-values-in-10-tests"><i class="fa fa-check"></i><b>4.5.3</b> Minimal p values in 10 tests</a></li>
<li class="chapter" data-level="4.5.4" data-path="introHypoTest.html"><a href="introHypoTest.html#homework-1"><i class="fa fa-check"></i><b>4.5.4</b> Homework</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Biomedical Data Modules</b></span></li>
<li class="chapter" data-level="5" data-path="image-digital.html"><a href="image-digital.html"><i class="fa fa-check"></i><b>5</b> Medical Image and Digital Health</a></li>
<li class="chapter" data-level="6" data-path="infectious-dis.html"><a href="infectious-dis.html"><i class="fa fa-check"></i><b>6</b> Infectious Disease Informatics</a></li>
<li class="chapter" data-level="7" data-path="cancer.html"><a href="cancer.html"><i class="fa fa-check"></i><b>7</b> Cancer genomics and epidemiology</a>
<ul>
<li class="chapter" data-level="7.1" data-path="cancer.html"><a href="cancer.html#cancer-case1"><i class="fa fa-check"></i><b>7.1</b> Case study 1: analysis of cBioportal mutation data</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="cancer.html"><a href="cancer.html#exploratory-analysis"><i class="fa fa-check"></i><b>7.1.1</b> Exploratory analysis</a></li>
<li class="chapter" data-level="7.1.2" data-path="cancer.html"><a href="cancer.html#statistical-analysis"><i class="fa fa-check"></i><b>7.1.2</b> Statistical analysis</a></li>
<li class="chapter" data-level="7.1.3" data-path="cancer.html"><a href="cancer.html#literature-search"><i class="fa fa-check"></i><b>7.1.3</b> Literature search</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="cancer.html"><a href="cancer.html#cancer-case2"><i class="fa fa-check"></i><b>7.2</b> Case study 2: Cancer Epidemiology</a></li>
<li class="chapter" data-level="7.3" data-path="cancer.html"><a href="cancer.html#scenario"><i class="fa fa-check"></i><b>7.3</b> 1. Scenario</a></li>
<li class="chapter" data-level="7.4" data-path="cancer.html"><a href="cancer.html#hong-kong-population"><i class="fa fa-check"></i><b>7.4</b> 2. Hong Kong population</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="cancer.html"><a href="cancer.html#download-population-data"><i class="fa fa-check"></i><b>7.4.1</b> Download population data</a></li>
<li class="chapter" data-level="7.4.2" data-path="cancer.html"><a href="cancer.html#format-data-for-plotting"><i class="fa fa-check"></i><b>7.4.2</b> Format data for plotting</a></li>
<li class="chapter" data-level="7.4.3" data-path="cancer.html"><a href="cancer.html#plotting-population-data"><i class="fa fa-check"></i><b>7.4.3</b> Plotting population data</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="cancer.html"><a href="cancer.html#cancer-registry-data"><i class="fa fa-check"></i><b>7.5</b> 3. Cancer registry data</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="cancer.html"><a href="cancer.html#download-cancer-registry-data"><i class="fa fa-check"></i><b>7.5.1</b> Download cancer registry data</a></li>
<li class="chapter" data-level="7.5.2" data-path="cancer.html"><a href="cancer.html#a.-visualise-changes-in-incidence-and-mortality"><i class="fa fa-check"></i><b>7.5.2</b> 3a. Visualise changes in incidence and mortality</a></li>
<li class="chapter" data-level="7.5.3" data-path="cancer.html"><a href="cancer.html#b.-calculate-cancer-risk-and-mortality-rate"><i class="fa fa-check"></i><b>7.5.3</b> 3b. Calculate cancer risk and mortality rate</a></li>
<li class="chapter" data-level="7.5.4" data-path="cancer.html"><a href="cancer.html#c.-mortality-incidence-ratio"><i class="fa fa-check"></i><b>7.5.4</b> 3c. Mortality-incidence ratio</a></li>
<li class="chapter" data-level="7.5.5" data-path="cancer.html"><a href="cancer.html#d.-paired-t-test-on-mortality-incidence-ratio-change"><i class="fa fa-check"></i><b>7.5.5</b> 3d. Paired t-test on mortality-incidence ratio change</a></li>
<li class="chapter" data-level="7.5.6" data-path="cancer.html"><a href="cancer.html#e.-childhood-versus-elderly-cancers"><i class="fa fa-check"></i><b>7.5.6</b> 3e. Childhood versus elderly cancers</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="cancer.html"><a href="cancer.html#existing-cancer-funding-and-publication-data"><i class="fa fa-check"></i><b>7.6</b> 4. Existing cancer funding and publication data</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="cancer.html"><a href="cancer.html#download-hmrf-grants-and-pubmed-data"><i class="fa fa-check"></i><b>7.6.1</b> Download HMRF grants and Pubmed data</a></li>
<li class="chapter" data-level="7.6.2" data-path="cancer.html"><a href="cancer.html#make-word-cloud-for-grants"><i class="fa fa-check"></i><b>7.6.2</b> Make word cloud for grants</a></li>
<li class="chapter" data-level="7.6.3" data-path="cancer.html"><a href="cancer.html#make-compare-grant-funding-with-incidence-and-mortality"><i class="fa fa-check"></i><b>7.6.3</b> Make compare grant funding with incidence and mortality</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="cancer.html"><a href="cancer.html#task-to-be-completed-in-tutotial-2-by-300pm-and-shared-with-other-tutorial-group"><i class="fa fa-check"></i><b>7.7</b> 5. Task (to be completed in Tutotial 2 by 3:00pm and shared with other tutorial group)</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="pop-genetics.html"><a href="pop-genetics.html"><i class="fa fa-check"></i><b>8</b> Population Genetics and Diseases</a>
<ul>
<li class="chapter" data-level="8.1" data-path="pop-genetics.html"><a href="pop-genetics.html#case-study-1-heritability-and-human-traits"><i class="fa fa-check"></i><b>8.1</b> Case study 1: Heritability and human traits</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="pop-genetics.html"><a href="pop-genetics.html#part-1"><i class="fa fa-check"></i><b>8.1.1</b> Part 1</a></li>
<li class="chapter" data-level="8.1.2" data-path="pop-genetics.html"><a href="pop-genetics.html#part-2"><i class="fa fa-check"></i><b>8.1.2</b> Part 2</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Appendix</b></span></li>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html"><i class="fa fa-check"></i>Appendix A: Install R &amp; RStudio</a>
<ul>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#a.1-install-r"><i class="fa fa-check"></i>A.1 Install R</a>
<ul>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#r-on-windows"><i class="fa fa-check"></i>R on Windows</a></li>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#r-on-macos"><i class="fa fa-check"></i>R on macOS</a></li>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#r-on-linux-ubuntu"><i class="fa fa-check"></i>R on Linux (Ubuntu)</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#a.2-install-rstudio"><i class="fa fa-check"></i>A.2 Install RStudio</a></li>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#a.3-use-r-inside-rstudio"><i class="fa fa-check"></i>A.3 Use R inside RStudio</a>
<ul>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#r-studio"><i class="fa fa-check"></i>R studio</a></li>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#set-working-directory"><i class="fa fa-check"></i>Set working directory</a></li>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#some-general-knowledge"><i class="fa fa-check"></i>Some general knowledge</a></li>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#install-packages-1"><i class="fa fa-check"></i>Install packages</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="install.html"><a href="install.html#a4.-cloud-computing"><i class="fa fa-check"></i>A4. Cloud computing</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Biomedical Data Science - introduction with case studies</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introLinearReg" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">Chapter 2</span> Introduction to Linear Regression<a href="introLinearReg.html#introLinearReg" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Acknowledgements: this chapter is adapted and updated from the materials originally produced by STAT1005 teaching team, especially Prof. Jeff Yao.</p>
<div id="linear-regression-using-simulated-data" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Linear Regression Using Simulated Data<a href="introLinearReg.html#linear-regression-using-simulated-data" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let’s first simulate some data and look at how the
predicted values (<em>Y<sub>e</sub></em>) differ from the actual value (<em>Y</em>).</p>
<div id="simulating-data" class="section level3 hasAnchor" number="2.1.1">
<h3><span class="header-section-number">2.1.1</span> Simulating data:<a href="introLinearReg.html#simulating-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>For <em>X</em>, we generate 100 normally distributed random numbers with mean 1.5
and standard deviation 2.5.</p></li>
<li><p>For predicted value <em>Y<sub>e</sub></em>, we assume an intercept (α) of 2 and a
slope (β) of 0.3 and we write <span class="math inline">\(Y_e = 2 + 0.3 x\)</span></p>
<p>Later, we will estimate the values of α and β using the least squares method
and see how that changes the efficacy of the model.</p></li>
<li><p>Though we estimate <span class="math inline">\(Y_e = \alpha + \beta X\)</span>, in reality Y is rarely perfectly
linear. It usually has an error component or
<strong>residual</strong>: <span class="math inline">\(Y = \alpha + \beta X + R\)</span>, where <em>R</em> is a random variable and
is assumed to be normally distributed.</p>
<p>Therefore for the actual value <em>Y</em>, we add a residual term (<code>res</code>), a random
variable distributed normally with mean 0 and a standard deviation of 0.5.</p></li>
</ul>
<p>The following cell shows the code snippet to generate these numbers and convert
these three columns in a data frame. Read through the code carefully and run
the cell to output a sample of our simulated data.</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="introLinearReg.html#cb50-1" tabindex="-1"></a><span class="co"># Fix seed: each run gives the same random numbers so the same outputs. </span></span>
<span id="cb50-2"><a href="introLinearReg.html#cb50-2" tabindex="-1"></a><span class="co"># Commenting out this line would read similar but different outputs at each run. </span></span>
<span id="cb50-3"><a href="introLinearReg.html#cb50-3" tabindex="-1"></a><span class="co"># Try it out!</span></span>
<span id="cb50-4"><a href="introLinearReg.html#cb50-4" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">0</span>)</span>
<span id="cb50-5"><a href="introLinearReg.html#cb50-5" tabindex="-1"></a></span>
<span id="cb50-6"><a href="introLinearReg.html#cb50-6" tabindex="-1"></a><span class="co"># Generate data</span></span>
<span id="cb50-7"><a href="introLinearReg.html#cb50-7" tabindex="-1"></a>X <span class="ot">=</span> <span class="fl">2.5</span> <span class="sc">*</span> <span class="fu">rnorm</span>(<span class="dv">100</span>) <span class="sc">+</span> <span class="fl">1.5</span>   <span class="co"># Array of 100 values with mean = 1.5, stddev = 2.5</span></span>
<span id="cb50-8"><a href="introLinearReg.html#cb50-8" tabindex="-1"></a>ypred <span class="ot">=</span> <span class="dv">2</span> <span class="sc">+</span> <span class="fl">0.3</span> <span class="sc">*</span> X          <span class="co"># Prediction of Y, assuming a = 2, b = 0.3</span></span>
<span id="cb50-9"><a href="introLinearReg.html#cb50-9" tabindex="-1"></a></span>
<span id="cb50-10"><a href="introLinearReg.html#cb50-10" tabindex="-1"></a>res <span class="ot">=</span> <span class="fl">0.5</span> <span class="sc">*</span> <span class="fu">rnorm</span>(<span class="dv">100</span>)       <span class="co"># Generate 100 residual terms</span></span>
<span id="cb50-11"><a href="introLinearReg.html#cb50-11" tabindex="-1"></a>yact <span class="ot">=</span> <span class="dv">2</span> <span class="sc">+</span> <span class="fl">0.3</span> <span class="sc">*</span> X <span class="sc">+</span> res     <span class="co"># Actual values of Y</span></span>
<span id="cb50-12"><a href="introLinearReg.html#cb50-12" tabindex="-1"></a></span>
<span id="cb50-13"><a href="introLinearReg.html#cb50-13" tabindex="-1"></a><span class="co"># Create dataframe to store our X, ypred, and yact values</span></span>
<span id="cb50-14"><a href="introLinearReg.html#cb50-14" tabindex="-1"></a>df <span class="ot">=</span> <span class="fu">data.frame</span>(<span class="st">&#39;X&#39;</span> <span class="ot">=</span> X, <span class="st">&#39;ypred&#39;</span> <span class="ot">=</span> ypred, <span class="st">&#39;yact&#39;</span> <span class="ot">=</span> yact)</span></code></pre></div>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="introLinearReg.html#cb51-1" tabindex="-1"></a><span class="co"># Show the first six rows of our dataframe</span></span>
<span id="cb51-2"><a href="introLinearReg.html#cb51-2" tabindex="-1"></a><span class="fu">head</span>(df)</span>
<span id="cb51-3"><a href="introLinearReg.html#cb51-3" tabindex="-1"></a><span class="co">#&gt;            X    ypred     yact</span></span>
<span id="cb51-4"><a href="introLinearReg.html#cb51-4" tabindex="-1"></a><span class="co">#&gt; 1  4.6573857 3.397216 3.788145</span></span>
<span id="cb51-5"><a href="introLinearReg.html#cb51-5" tabindex="-1"></a><span class="co">#&gt; 2  0.6844166 2.205325 1.816937</span></span>
<span id="cb51-6"><a href="introLinearReg.html#cb51-6" tabindex="-1"></a><span class="co">#&gt; 3  4.8244982 3.447349 3.139354</span></span>
<span id="cb51-7"><a href="introLinearReg.html#cb51-7" tabindex="-1"></a><span class="co">#&gt; 4  4.6810733 3.404322 3.427612</span></span>
<span id="cb51-8"><a href="introLinearReg.html#cb51-8" tabindex="-1"></a><span class="co">#&gt; 5  2.5366036 2.760981 2.195788</span></span>
<span id="cb51-9"><a href="introLinearReg.html#cb51-9" tabindex="-1"></a><span class="co">#&gt; 6 -2.3498751 1.295037 1.583397</span></span></code></pre></div>
<p>Now let’s plot both the actual output (<code>yact</code>) and predicted output (<code>ypred</code>)
against the input variable (<code>X</code>) to see what the difference between <code>yact</code> and
<code>ypred</code> is, and therefore, to see how accurately the proposed equation
(<code>ypred = 2 + 0.3 * X</code>) has been able to predict the value of the output:</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="introLinearReg.html#cb52-1" tabindex="-1"></a><span class="co"># You can use basic plotting functions</span></span>
<span id="cb52-2"><a href="introLinearReg.html#cb52-2" tabindex="-1"></a><span class="co"># plot(x=df$X, y=df$yact, col=&quot;red&quot;)</span></span>
<span id="cb52-3"><a href="introLinearReg.html#cb52-3" tabindex="-1"></a><span class="co"># lines(x=df$X, y=df$ypred, col=&quot;darkgreen&quot;)</span></span>
<span id="cb52-4"><a href="introLinearReg.html#cb52-4" tabindex="-1"></a></span>
<span id="cb52-5"><a href="introLinearReg.html#cb52-5" tabindex="-1"></a></span>
<span id="cb52-6"><a href="introLinearReg.html#cb52-6" tabindex="-1"></a><span class="co"># But let&#39;s use ggplot2 for higher flexibility</span></span>
<span id="cb52-7"><a href="introLinearReg.html#cb52-7" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb52-8"><a href="introLinearReg.html#cb52-8" tabindex="-1"></a></span>
<span id="cb52-9"><a href="introLinearReg.html#cb52-9" tabindex="-1"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(X)) <span class="sc">+</span>                              <span class="co"># basic graphical object</span></span>
<span id="cb52-10"><a href="introLinearReg.html#cb52-10" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y=</span>yact), <span class="at">colour=</span><span class="st">&quot;black&quot;</span>) <span class="sc">+</span>       <span class="co"># first layer</span></span>
<span id="cb52-11"><a href="introLinearReg.html#cb52-11" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y=</span>ypred), <span class="at">colour=</span><span class="st">&quot;darkgreen&quot;</span>) <span class="sc">+</span>   <span class="co"># second layer</span></span>
<span id="cb52-12"><a href="introLinearReg.html#cb52-12" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&#39;Actual vs Predicted values from the dummy dataset&#39;</span>)</span></code></pre></div>
<p><img src="BMDatSci_files/figure-html/fig2-simu-scatter-1.png" width="75%" /></p>
</div>
<div id="model-efficacy" class="section level3 hasAnchor" number="2.1.2">
<h3><span class="header-section-number">2.1.2</span> Model efficacy<a href="introLinearReg.html#model-efficacy" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>How do we know the values we calculate for α and β are giving us a good model?
We can explain the total variability in our model with the
<strong>Total Sum of Squares</strong> or SST:</p>
<p><span class="math display">\[SST = \sum_{i=1}^n\Bigl(\text{yact}_i - \text{yavg}\Bigr)^2, \qquad\qquad \text{yavg}=\frac1n \sum_{i=1}^n \text{yact}_i\]</span></p>
<p>Mathematically, we have</p>
<p><span class="math display">\[ \sum_{i=1}^n\Bigl(\text{yact}_i - \text{yavg}\Bigr)^2
= \sum_{i=1}^n\Bigl(\text{ypred}_i -\text{yavg} \Bigr)^2
+ \sum_{i=1}^n\Bigl(\text{yact}_i - \text{ypred}_i\Bigr)^2\]</span></p>
<p>The identity reads as</p>
<p><strong>Sum of Squares Total</strong> = <strong>Sum of Squares Regression</strong> + <strong>Sum of Squares Error</strong>,</p>
<p>or simply ,</p>
<p><strong>SST</strong> = <strong>SSR</strong> + <strong>SSE</strong>.</p>
<p>The Regression Sum of Squares or SSR measures the variation of the
regression/predicted values, and the Sum of Squares Error SSE the
variation between the actual and the predicted values.<br />
An alternative saying is that SSR is the difference explained by the model, SSE
is the difference not explained by the model and is random, and SST is the
total error.
<strong>Note</strong>, we often use SSE (Sum of Squares Error) and SSD (Sum of Squares
Difference) interchangeably.</p>
</div>
<div id="r-squared" class="section level3 hasAnchor" number="2.1.3">
<h3><span class="header-section-number">2.1.3</span> <em>R-Squared</em><a href="introLinearReg.html#r-squared" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The higher the ratio of SSR to SST, the better the model is. This ratio is
quantified by the <strong>coefficient of determination</strong> (also known as
<strong><em>R<sup>2</sup></em></strong> or <strong><em>R</em>-squared</strong>):</p>
<p><span class="math display">\[ R^2= \frac{SSR}{SST}\]</span></p>
<p>Since <span class="math inline">\(SST= SSR+SSE\)</span>, <span class="math inline">\(\qquad 0\le R^2\le 1\)</span>.</p>
<p>The closer it is to 1, the better the model. Note that there are many other
factors that we need to analyse before we can conclude a linear regression
model is effective, but a high <span class="math inline">\(R^2\)</span> is a pretty good indicator.</p>
<p>Let’s see what the value of <span class="math inline">\(R^2\)</span> is for our simulated dataset.</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="introLinearReg.html#cb53-1" tabindex="-1"></a><span class="co"># Calculate the mean of Y</span></span>
<span id="cb53-2"><a href="introLinearReg.html#cb53-2" tabindex="-1"></a>ymean <span class="ot">=</span> <span class="fu">mean</span>(df<span class="sc">$</span>yact)</span>
<span id="cb53-3"><a href="introLinearReg.html#cb53-3" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&#39;Mean of Y =&#39;</span>, ymean)) <span class="co"># paste brings a white space by default</span></span>
<span id="cb53-4"><a href="introLinearReg.html#cb53-4" tabindex="-1"></a><span class="co">#&gt; [1] &quot;Mean of Y = 2.44422555811815&quot;</span></span>
<span id="cb53-5"><a href="introLinearReg.html#cb53-5" tabindex="-1"></a></span>
<span id="cb53-6"><a href="introLinearReg.html#cb53-6" tabindex="-1"></a><span class="co"># Calculate SSR and SST</span></span>
<span id="cb53-7"><a href="introLinearReg.html#cb53-7" tabindex="-1"></a>df[<span class="st">&#39;SSR&#39;</span>] <span class="ot">=</span> (df[<span class="st">&#39;ypred&#39;</span>] <span class="sc">-</span> ymean)<span class="sc">**</span><span class="dv">2</span></span>
<span id="cb53-8"><a href="introLinearReg.html#cb53-8" tabindex="-1"></a>df[<span class="st">&#39;SST&#39;</span>] <span class="ot">=</span> (df[<span class="st">&#39;yact&#39;</span>] <span class="sc">-</span> ymean)<span class="sc">**</span><span class="dv">2</span></span>
<span id="cb53-9"><a href="introLinearReg.html#cb53-9" tabindex="-1"></a>SSR <span class="ot">=</span> <span class="fu">sum</span>(df[<span class="st">&#39;SSR&#39;</span>])</span>
<span id="cb53-10"><a href="introLinearReg.html#cb53-10" tabindex="-1"></a>SST <span class="ot">=</span> <span class="fu">sum</span>(df[<span class="st">&#39;SST&#39;</span>])</span>
<span id="cb53-11"><a href="introLinearReg.html#cb53-11" tabindex="-1"></a></span>
<span id="cb53-12"><a href="introLinearReg.html#cb53-12" tabindex="-1"></a><span class="co"># Calculate R-squared</span></span>
<span id="cb53-13"><a href="introLinearReg.html#cb53-13" tabindex="-1"></a>R2 <span class="ot">=</span> SSR <span class="sc">/</span> SST</span>
<span id="cb53-14"><a href="introLinearReg.html#cb53-14" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&#39;R2 =&#39;</span>, R2))</span>
<span id="cb53-15"><a href="introLinearReg.html#cb53-15" tabindex="-1"></a><span class="co">#&gt; [1] &quot;R2 = 0.583160943681119&quot;</span></span></code></pre></div>
<p>The value of <span class="math inline">\(R^2=0.583\)</span> suggests that <code>ypred</code> provides a decent prediction of
the <code>yact</code>.</p>
<p>We have randomly assumed some values for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>, but these may
or may not be the best values. In the next step, we will use the least sum of
square method to calculate the optimum value for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> to see if
there is an improvement in <span class="math inline">\(R^2\)</span>.</p>
<p>To get started on the next step, open the notebook called <code>02-linearReg-02.Rmd</code>.</p>
</div>
</div>
<div id="least-squares-using-simulated-data" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> Least Squares Using Simulated Data<a href="introLinearReg.html#least-squares-using-simulated-data" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Now, using our simulated data from the previous step, let’s estimate the optimum values of our variable coefficients, <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>. Using the predictor variable, <code>X</code>, and the output variable, <code>yact</code>, we will calculate the values of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> using the Least Squares method described in the lecture.</p>
<p>The cell below creates the same dataframe as previously. Run the cell to get started!</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="introLinearReg.html#cb54-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">0</span>)</span>
<span id="cb54-2"><a href="introLinearReg.html#cb54-2" tabindex="-1"></a></span>
<span id="cb54-3"><a href="introLinearReg.html#cb54-3" tabindex="-1"></a><span class="co"># Generate data</span></span>
<span id="cb54-4"><a href="introLinearReg.html#cb54-4" tabindex="-1"></a>X <span class="ot">=</span> <span class="fl">2.5</span> <span class="sc">*</span> <span class="fu">rnorm</span>(<span class="dv">100</span>) <span class="sc">+</span> <span class="fl">1.5</span>   <span class="co"># Array of 100 values with mean = 1.5, stddev = 2.5</span></span>
<span id="cb54-5"><a href="introLinearReg.html#cb54-5" tabindex="-1"></a>ypred <span class="ot">=</span> <span class="dv">2</span> <span class="sc">+</span> <span class="fl">0.3</span> <span class="sc">*</span> X          <span class="co"># Prediction of Y, assuming a = 2, b = 0.3</span></span>
<span id="cb54-6"><a href="introLinearReg.html#cb54-6" tabindex="-1"></a></span>
<span id="cb54-7"><a href="introLinearReg.html#cb54-7" tabindex="-1"></a>res <span class="ot">=</span> <span class="fl">0.5</span> <span class="sc">*</span> <span class="fu">rnorm</span>(<span class="dv">100</span>)       <span class="co"># Generate 100 residual terms</span></span>
<span id="cb54-8"><a href="introLinearReg.html#cb54-8" tabindex="-1"></a>yact <span class="ot">=</span> <span class="dv">2</span> <span class="sc">+</span> <span class="fl">0.3</span> <span class="sc">*</span> X <span class="sc">+</span> res     <span class="co"># Actual values of Y</span></span>
<span id="cb54-9"><a href="introLinearReg.html#cb54-9" tabindex="-1"></a></span>
<span id="cb54-10"><a href="introLinearReg.html#cb54-10" tabindex="-1"></a><span class="co"># Create dataframe to store our X, ypred, and yact values</span></span>
<span id="cb54-11"><a href="introLinearReg.html#cb54-11" tabindex="-1"></a>df <span class="ot">=</span> <span class="fu">data.frame</span>(<span class="st">&#39;X&#39;</span> <span class="ot">=</span> X, <span class="st">&#39;ypred&#39;</span> <span class="ot">=</span> ypred, <span class="st">&#39;yact&#39;</span> <span class="ot">=</span> yact)</span></code></pre></div>
<p>Just to reiterate, here are the formulas for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> again:</p>
<p><span class="math display">\[\hat\beta=\frac{\sum_{i=1}^n(X_i-\bar X)(Y_i-\bar Y)}{\sum_{i=1}^n(X_i-\bar X)^2}=\frac{\text{cov}(X,Y)}{\text{var}(X)}\]</span></p>
<p><span class="math display">\[\hat\alpha=\bar Y-\hat\beta * \bar X\]</span></p>
<p>To calculate these coefficients, we will create a few more columns in our <code>df</code>
data frame. We need to calculate <code>xmean</code> and <code>ymean</code> to calculate the covariance
of X and Y (<code>xycov</code>) and the variance of X (<code>xvar</code>) before we can work out the
values for <code>alpha</code> and <code>beta</code>.</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="introLinearReg.html#cb55-1" tabindex="-1"></a><span class="co"># Calculate the mean of X and Y</span></span>
<span id="cb55-2"><a href="introLinearReg.html#cb55-2" tabindex="-1"></a>xmean <span class="ot">=</span> <span class="fu">mean</span>(X)</span>
<span id="cb55-3"><a href="introLinearReg.html#cb55-3" tabindex="-1"></a>ymean <span class="ot">=</span> <span class="fu">mean</span>(yact)</span>
<span id="cb55-4"><a href="introLinearReg.html#cb55-4" tabindex="-1"></a></span>
<span id="cb55-5"><a href="introLinearReg.html#cb55-5" tabindex="-1"></a><span class="co"># Calculate the terms needed for the numator and denominator of beta</span></span>
<span id="cb55-6"><a href="introLinearReg.html#cb55-6" tabindex="-1"></a>df[<span class="st">&#39;xycov&#39;</span>] <span class="ot">=</span> (df[<span class="st">&#39;X&#39;</span>] <span class="sc">-</span> xmean) <span class="sc">*</span> (df[<span class="st">&#39;yact&#39;</span>] <span class="sc">-</span> ymean)</span>
<span id="cb55-7"><a href="introLinearReg.html#cb55-7" tabindex="-1"></a>df[<span class="st">&#39;xvar&#39;</span>] <span class="ot">=</span> (df[<span class="st">&#39;X&#39;</span>] <span class="sc">-</span> xmean)<span class="sc">**</span><span class="dv">2</span></span>
<span id="cb55-8"><a href="introLinearReg.html#cb55-8" tabindex="-1"></a></span>
<span id="cb55-9"><a href="introLinearReg.html#cb55-9" tabindex="-1"></a><span class="co"># Calculate beta and alpha</span></span>
<span id="cb55-10"><a href="introLinearReg.html#cb55-10" tabindex="-1"></a>beta <span class="ot">=</span> <span class="fu">sum</span>(df[<span class="st">&#39;xycov&#39;</span>]) <span class="sc">/</span> <span class="fu">sum</span>(df[<span class="st">&#39;xvar&#39;</span>])</span>
<span id="cb55-11"><a href="introLinearReg.html#cb55-11" tabindex="-1"></a>alpha <span class="ot">=</span> ymean <span class="sc">-</span> (beta <span class="sc">*</span> xmean)</span>
<span id="cb55-12"><a href="introLinearReg.html#cb55-12" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&#39;alpha =&#39;</span>, alpha, <span class="st">&#39;;&#39;</span>, <span class="st">&#39;beta =&#39;</span>, beta))</span>
<span id="cb55-13"><a href="introLinearReg.html#cb55-13" tabindex="-1"></a><span class="co">#&gt; [1] &quot;alpha = 1.93401265576322 ; beta = 0.327758955833308&quot;</span></span></code></pre></div>
<p>As we can see, the values are only a little different from what we had assumed
earlier.</p>
<p>Let’s see how the value of <span class="math inline">\(R^2\)</span> changes if we use the new values of <span class="math inline">\(\alpha\)</span>
and <span class="math inline">\(\beta\)</span>.</p>
<p>The equation for the new model can be written as:
<span class="math display">\[ y=1.934 + 0.328 * x \]</span></p>
<p>Let’s create a new column in <code>df</code> to accommodate the values generated by this
equation and call this <code>ypred2</code>, and calculate the new <span class="math inline">\(R^2\)</span>.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="introLinearReg.html#cb56-1" tabindex="-1"></a><span class="co"># Create new column to store new predictions</span></span>
<span id="cb56-2"><a href="introLinearReg.html#cb56-2" tabindex="-1"></a>df[<span class="st">&#39;ypred2&#39;</span>] <span class="ot">=</span> alpha <span class="sc">+</span> beta <span class="sc">*</span> df[<span class="st">&#39;X&#39;</span>]</span>
<span id="cb56-3"><a href="introLinearReg.html#cb56-3" tabindex="-1"></a></span>
<span id="cb56-4"><a href="introLinearReg.html#cb56-4" tabindex="-1"></a><span class="co"># Calculate new SSR with new predictions of Y.</span></span>
<span id="cb56-5"><a href="introLinearReg.html#cb56-5" tabindex="-1"></a><span class="co"># Note that SST remains the same since yact and ymean do not change.</span></span>
<span id="cb56-6"><a href="introLinearReg.html#cb56-6" tabindex="-1"></a>df[<span class="st">&#39;SSR2&#39;</span>] <span class="ot">=</span> (df[<span class="st">&#39;ypred2&#39;</span>] <span class="sc">-</span> ymean)<span class="sc">**</span><span class="dv">2</span></span>
<span id="cb56-7"><a href="introLinearReg.html#cb56-7" tabindex="-1"></a>df[<span class="st">&#39;SST&#39;</span>] <span class="ot">=</span> (df[<span class="st">&#39;yact&#39;</span>] <span class="sc">-</span> ymean)<span class="sc">**</span><span class="dv">2</span></span>
<span id="cb56-8"><a href="introLinearReg.html#cb56-8" tabindex="-1"></a>SSR2 <span class="ot">=</span> <span class="fu">sum</span>(df[<span class="st">&#39;SSR2&#39;</span>])</span>
<span id="cb56-9"><a href="introLinearReg.html#cb56-9" tabindex="-1"></a>SST <span class="ot">=</span> <span class="fu">sum</span>(df[<span class="st">&#39;SST&#39;</span>])</span>
<span id="cb56-10"><a href="introLinearReg.html#cb56-10" tabindex="-1"></a></span>
<span id="cb56-11"><a href="introLinearReg.html#cb56-11" tabindex="-1"></a><span class="co"># Calculate new R2</span></span>
<span id="cb56-12"><a href="introLinearReg.html#cb56-12" tabindex="-1"></a>R2_2 <span class="ot">=</span> SSR2 <span class="sc">/</span> SST</span>
<span id="cb56-13"><a href="introLinearReg.html#cb56-13" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&#39;New R2 =&#39;</span>, R2_2))</span>
<span id="cb56-14"><a href="introLinearReg.html#cb56-14" tabindex="-1"></a><span class="co">#&gt; [1] &quot;New R2 = 0.69524214766491&quot;</span></span></code></pre></div>
<p>The new value of <span class="math inline">\(R^2= 0.695\)</span> shows a slight improvement from the previous
value of <span class="math inline">\(R^2=0.583\)</span> (obtained with <span class="math inline">\(\alpha=2,~\beta=0.3\)</span>).</p>
<p>Let’s also plot our new prediction model against the actual values and our
earlier assumed model, just to get a better visual understanding.</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="introLinearReg.html#cb57-1" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb57-2"><a href="introLinearReg.html#cb57-2" tabindex="-1"></a></span>
<span id="cb57-3"><a href="introLinearReg.html#cb57-3" tabindex="-1"></a><span class="co"># Put color into aes</span></span>
<span id="cb57-4"><a href="introLinearReg.html#cb57-4" tabindex="-1"></a><span class="fu">ggplot</span>(df, <span class="fu">aes</span>(X)) <span class="sc">+</span>                              <span class="co"># basic graphical object</span></span>
<span id="cb57-5"><a href="introLinearReg.html#cb57-5" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y=</span>yact), <span class="at">colour=</span><span class="st">&quot;black&quot;</span>) <span class="sc">+</span>       <span class="co"># first layer</span></span>
<span id="cb57-6"><a href="introLinearReg.html#cb57-6" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y=</span>ypred, <span class="at">colour=</span><span class="st">&quot;Guess&quot;</span>)) <span class="sc">+</span>       <span class="co"># second layer</span></span>
<span id="cb57-7"><a href="introLinearReg.html#cb57-7" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y=</span>ypred2, <span class="at">colour=</span><span class="st">&quot;OLS&quot;</span>)) <span class="sc">+</span>        <span class="co"># third layer</span></span>
<span id="cb57-8"><a href="introLinearReg.html#cb57-8" tabindex="-1"></a>  <span class="fu">scale_colour_manual</span>(<span class="at">name=</span><span class="st">&quot;Models&quot;</span>, <span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;Guess&quot;</span><span class="ot">=</span><span class="st">&quot;darkgreen&quot;</span>, <span class="st">&quot;OLS&quot;</span><span class="ot">=</span><span class="st">&quot;red&quot;</span>)) <span class="sc">+</span></span>
<span id="cb57-9"><a href="introLinearReg.html#cb57-9" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&#39;Actual vs Predicted with guessed parameters vs Predicted with calculated parameters&#39;</span>)</span></code></pre></div>
<p><img src="BMDatSci_files/figure-html/fig2-simu-OLS-1.png" width="75%" /></p>
<p>As we can see, the <code>ypred2</code> and <code>ypred</code> are more or less overlapping since the
respective values of ɑ and β are not very different.</p>
<p>Next, we will explore other methods of determining model efficacy by using the
notebook called <code>02-linearReg-03.Rmd</code>.</p>
</div>
<div id="diagnostic-check-of-a-fitted-regression-model" class="section level2 hasAnchor" number="2.3">
<h2><span class="header-section-number">2.3</span> Diagnostic check of a fitted regression model<a href="introLinearReg.html#diagnostic-check-of-a-fitted-regression-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Apart from the <span class="math inline">\(R^2\)</span> statistic, there are other statistics and parameters that
you need to look at in order to determine if the model is efficient. We will
discuss some commonly used statistics – Residual Standard Errors, <span class="math inline">\(p\)</span>-values,
and <span class="math inline">\(F\)</span>-statistics.</p>
<div id="residual-standard-errors-rse" class="section level3 hasAnchor" number="2.3.1">
<h3><span class="header-section-number">2.3.1</span> Residual Standard Errors (RSE)<a href="introLinearReg.html#residual-standard-errors-rse" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>RSE is a common statistic used to calculate the accuracy of values predicted by
a model. It is an estimate of the variance of the error term, <code>res</code>. For a
simple linear regression model, RSE is defined as:
<span class="math display">\[  RSE^2 = \frac{SSE}{n-2} = \frac1{n-2} \sum_{i=1}^n  \Bigl(\text{yact}_i - \text{ypred}_i \Bigr)^2.
\]</span></p>
<p>In general,</p>
<p><span class="math display">\[  RSE^2 = \frac{SSE}{n-p-1} = \frac1{n-p-1} \sum_{i=1}^n  \Bigl(\text{yact}_i - \text{ypred}_i \Bigr)^2.
\]</span></p>
<p>where <span class="math inline">\(p\)</span> is the number of predictor variables in a model where we have more
than one predictor variables.</p>
<p>A <strong>multiple linear regression</strong> model is a linear regression model with
multiple predictors, written as<br />
<span class="math display">\[  Y_e = \alpha +\beta_1 * X_1 +\cdots +\beta_p X_p.
\]</span></p>
<p>As you see, the parameters and predictors are subscripted from 1 up to the
number of predictors <span class="math inline">\(p\)</span>.</p>
<p>In multiple regression, the value of RSE generally decreases as we add
variables that are more significant predictors of the output variable.</p>
<p>Using our simulated data from the previous steps, the following code snippet
shows how the RSE for a model can be calculated:</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="introLinearReg.html#cb58-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">0</span>)</span>
<span id="cb58-2"><a href="introLinearReg.html#cb58-2" tabindex="-1"></a></span>
<span id="cb58-3"><a href="introLinearReg.html#cb58-3" tabindex="-1"></a><span class="co"># Generate data</span></span>
<span id="cb58-4"><a href="introLinearReg.html#cb58-4" tabindex="-1"></a>X <span class="ot">=</span> <span class="fl">2.5</span> <span class="sc">*</span> <span class="fu">rnorm</span>(<span class="dv">100</span>) <span class="sc">+</span> <span class="fl">1.5</span>   <span class="co"># Array of 100 values with mean = 1.5, stddev = 2.5</span></span>
<span id="cb58-5"><a href="introLinearReg.html#cb58-5" tabindex="-1"></a>res <span class="ot">=</span> <span class="fl">0.5</span> <span class="sc">*</span> <span class="fu">rnorm</span>(<span class="dv">100</span>)       <span class="co"># Generate 100 residual terms</span></span>
<span id="cb58-6"><a href="introLinearReg.html#cb58-6" tabindex="-1"></a>yact <span class="ot">=</span> <span class="dv">2</span> <span class="sc">+</span> <span class="fl">0.3</span> <span class="sc">*</span> X <span class="sc">+</span> res     <span class="co"># Actual values of Y</span></span>
<span id="cb58-7"><a href="introLinearReg.html#cb58-7" tabindex="-1"></a></span>
<span id="cb58-8"><a href="introLinearReg.html#cb58-8" tabindex="-1"></a><span class="co"># Create dataframe to store our X, ypred, and yact values</span></span>
<span id="cb58-9"><a href="introLinearReg.html#cb58-9" tabindex="-1"></a>df <span class="ot">=</span> <span class="fu">data.frame</span>(<span class="st">&#39;X&#39;</span> <span class="ot">=</span> X, <span class="st">&#39;yact&#39;</span> <span class="ot">=</span> yact)</span>
<span id="cb58-10"><a href="introLinearReg.html#cb58-10" tabindex="-1"></a></span>
<span id="cb58-11"><a href="introLinearReg.html#cb58-11" tabindex="-1"></a><span class="co"># Calculate the mean of X and Y</span></span>
<span id="cb58-12"><a href="introLinearReg.html#cb58-12" tabindex="-1"></a>xmean <span class="ot">=</span> <span class="fu">mean</span>(X)</span>
<span id="cb58-13"><a href="introLinearReg.html#cb58-13" tabindex="-1"></a>ymean <span class="ot">=</span> <span class="fu">mean</span>(yact)</span>
<span id="cb58-14"><a href="introLinearReg.html#cb58-14" tabindex="-1"></a></span>
<span id="cb58-15"><a href="introLinearReg.html#cb58-15" tabindex="-1"></a><span class="co"># Calculate the terms needed for the numator and denominator of beta</span></span>
<span id="cb58-16"><a href="introLinearReg.html#cb58-16" tabindex="-1"></a>df[<span class="st">&#39;xycov&#39;</span>] <span class="ot">=</span> (df[<span class="st">&#39;X&#39;</span>] <span class="sc">-</span> xmean) <span class="sc">*</span> (df[<span class="st">&#39;yact&#39;</span>] <span class="sc">-</span> ymean)</span>
<span id="cb58-17"><a href="introLinearReg.html#cb58-17" tabindex="-1"></a>df[<span class="st">&#39;xvar&#39;</span>] <span class="ot">=</span> (df[<span class="st">&#39;X&#39;</span>] <span class="sc">-</span> xmean)<span class="sc">**</span><span class="dv">2</span></span>
<span id="cb58-18"><a href="introLinearReg.html#cb58-18" tabindex="-1"></a></span>
<span id="cb58-19"><a href="introLinearReg.html#cb58-19" tabindex="-1"></a><span class="co"># Calculate beta and alpha</span></span>
<span id="cb58-20"><a href="introLinearReg.html#cb58-20" tabindex="-1"></a>beta <span class="ot">=</span> <span class="fu">sum</span>(df[<span class="st">&#39;xycov&#39;</span>]) <span class="sc">/</span> <span class="fu">sum</span>(df[<span class="st">&#39;xvar&#39;</span>])</span>
<span id="cb58-21"><a href="introLinearReg.html#cb58-21" tabindex="-1"></a>alpha <span class="ot">=</span> ymean <span class="sc">-</span> (beta <span class="sc">*</span> xmean)</span>
<span id="cb58-22"><a href="introLinearReg.html#cb58-22" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&#39;alpha =&#39;</span>, alpha, <span class="st">&#39;;&#39;</span>, <span class="st">&#39;beta =&#39;</span>, beta))</span>
<span id="cb58-23"><a href="introLinearReg.html#cb58-23" tabindex="-1"></a><span class="co">#&gt; [1] &quot;alpha = 1.93401265576322 ; beta = 0.327758955833308&quot;</span></span>
<span id="cb58-24"><a href="introLinearReg.html#cb58-24" tabindex="-1"></a></span>
<span id="cb58-25"><a href="introLinearReg.html#cb58-25" tabindex="-1"></a><span class="co"># Store predictions as in previous step</span></span>
<span id="cb58-26"><a href="introLinearReg.html#cb58-26" tabindex="-1"></a>df[<span class="st">&#39;ypred&#39;</span>] <span class="ot">=</span> alpha <span class="sc">+</span> beta <span class="sc">*</span> df[<span class="st">&#39;X&#39;</span>]</span>
<span id="cb58-27"><a href="introLinearReg.html#cb58-27" tabindex="-1"></a></span>
<span id="cb58-28"><a href="introLinearReg.html#cb58-28" tabindex="-1"></a><span class="co"># Show first five rows of dataframe</span></span>
<span id="cb58-29"><a href="introLinearReg.html#cb58-29" tabindex="-1"></a><span class="fu">head</span>(df)</span>
<span id="cb58-30"><a href="introLinearReg.html#cb58-30" tabindex="-1"></a><span class="co">#&gt;            X     yact      xycov       xvar    ypred</span></span>
<span id="cb58-31"><a href="introLinearReg.html#cb58-31" tabindex="-1"></a><span class="co">#&gt; 1  4.6573857 3.788145  4.1671116  9.6144310 3.460513</span></span>
<span id="cb58-32"><a href="introLinearReg.html#cb58-32" tabindex="-1"></a><span class="co">#&gt; 2  0.6844166 1.816937  0.5471556  0.7608280 2.158336</span></span>
<span id="cb58-33"><a href="introLinearReg.html#cb58-33" tabindex="-1"></a><span class="co">#&gt; 3  4.8244982 3.139354  2.2715611 10.6786935 3.515285</span></span>
<span id="cb58-34"><a href="introLinearReg.html#cb58-34" tabindex="-1"></a><span class="co">#&gt; 4  4.6810733 3.427612  3.0724952  9.7618890 3.468276</span></span>
<span id="cb58-35"><a href="introLinearReg.html#cb58-35" tabindex="-1"></a><span class="co">#&gt; 5  2.5366036 2.195788 -0.2434518  0.9602676 2.765407</span></span>
<span id="cb58-36"><a href="introLinearReg.html#cb58-36" tabindex="-1"></a><span class="co">#&gt; 6 -2.3498751 1.583397  3.3628671 15.2611034 1.163820</span></span></code></pre></div>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="introLinearReg.html#cb59-1" tabindex="-1"></a><span class="co"># Calculate SSE</span></span>
<span id="cb59-2"><a href="introLinearReg.html#cb59-2" tabindex="-1"></a>df[<span class="st">&#39;SSE&#39;</span>] <span class="ot">=</span> (df[<span class="st">&#39;yact&#39;</span>] <span class="sc">-</span> df[<span class="st">&#39;ypred&#39;</span>])<span class="sc">**</span><span class="dv">2</span></span>
<span id="cb59-3"><a href="introLinearReg.html#cb59-3" tabindex="-1"></a>SSE <span class="ot">=</span> <span class="fu">sum</span>(df[<span class="st">&#39;SSE&#39;</span>])</span>
<span id="cb59-4"><a href="introLinearReg.html#cb59-4" tabindex="-1"></a></span>
<span id="cb59-5"><a href="introLinearReg.html#cb59-5" tabindex="-1"></a><span class="co"># Calculate RSE</span></span>
<span id="cb59-6"><a href="introLinearReg.html#cb59-6" tabindex="-1"></a>RSE <span class="ot">=</span> <span class="fu">sqrt</span>(SSE <span class="sc">/</span> <span class="dv">98</span>)   <span class="co"># n = 100</span></span>
<span id="cb59-7"><a href="introLinearReg.html#cb59-7" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&#39;RSE =&#39;</span>, RSE))</span>
<span id="cb59-8"><a href="introLinearReg.html#cb59-8" tabindex="-1"></a><span class="co">#&gt; [1] &quot;RSE = 0.481279277134956&quot;</span></span></code></pre></div>
<p>The value of <code>RSE</code> comes out to be 0.48.</p>
<p>As you might have guessed, the smaller the residual standard errors, the better
the model is.</p>
<p>The benchmark to compare this to is the mean of the actual values, <code>yact</code>. As
shown previously, this value is <code>ymean = 2.54</code>. In plain English, this means we
observe an error of 0.48 over 2.44 - approximately 19.69%.</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="introLinearReg.html#cb60-1" tabindex="-1"></a>error <span class="ot">=</span> RSE <span class="sc">/</span> ymean</span>
<span id="cb60-2"><a href="introLinearReg.html#cb60-2" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&#39;Mean Y =&#39;</span>, ymean))</span>
<span id="cb60-3"><a href="introLinearReg.html#cb60-3" tabindex="-1"></a><span class="co">#&gt; [1] &quot;Mean Y = 2.44422555811815&quot;</span></span>
<span id="cb60-4"><a href="introLinearReg.html#cb60-4" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&#39;Error =&#39;</span>, error))</span>
<span id="cb60-5"><a href="introLinearReg.html#cb60-5" tabindex="-1"></a><span class="co">#&gt; [1] &quot;Error = 0.196904608716023&quot;</span></span></code></pre></div>
</div>
<div id="p-values" class="section level3 hasAnchor" number="2.3.2">
<h3><span class="header-section-number">2.3.2</span> p-values<a href="introLinearReg.html#p-values" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The calculation of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are estimates, not exact calculations.
Whether their values are significant or not needs to be tested using a
<strong>hypothesis test</strong>.</p>
<p>In the equation, <span class="math inline">\(Y = \alpha + \beta X\)</span>, if we set <span class="math inline">\(\beta=0\)</span>, there will be no
relation between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>. Therefore, the hypothesis tests whether the value
of <span class="math inline">\(\beta\)</span> is non-zero or not.</p>
<p><span class="math display">\[\begin{align*} \text{Null hypothesis}~  H_0~:~  \beta=0, &amp; \quad \text{versus} \\
\text{Alternative hypothesis}~ H_1~:~ \beta\ne 0.&amp;  \end{align*}  \]</span></p>
<p>Whenever a regression task is performed and <span class="math inline">\(\beta\)</span> is calculated, there will
be an accompanying <strong>p-value</strong> corresponding to this hypothesis test. We will
not go through how this is calculated in this course (you can learn more
<a href="https://www.dummies.com/education/math/statistics/how-to-determine-a-p-value-when-testing-a-null-hypothesis/">here</a>),
since it is calculated automatically by ready-made methods in R.</p>
<p>If the p-value is less than a chosen <strong>significance level</strong> (e.g. 0.05) then
the null hypothesis that <span class="math inline">\(\beta = 0\)</span> is rejected and <span class="math inline">\(\beta\)</span> is said to be
<b>significant and non-zero</b>.</p>
<p>In the case of multiple linear regression, the p-value associated with each
<span class="math inline">\(\beta_k\)</span> can be used to weed out insignificant predictors from the model.
The higher the p-value for <span class="math inline">\(\beta_k\)</span>, the less significant <span class="math inline">\(X_k\)</span> is to the
model.</p>
</div>
<div id="f-statistics" class="section level3 hasAnchor" number="2.3.3">
<h3><span class="header-section-number">2.3.3</span> F-statistics<a href="introLinearReg.html#f-statistics" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In a multiple regression model, apart from testing the significance of
individual variables by checking the p-values, it is also necessary to check
whether, as a group all the predictors are significant. This can be done using
the following hypothesis:</p>
<p><span class="math display">\[\begin{align*} \text{Null hypothesis}~  H_0~:~ &amp; \beta_1=\beta_2=\cdots=\beta_p=0, \quad \text{versus} \\
\text{Alternative hypothesis}~ H_1~:~&amp; \text{at least one of the} ~\beta_k&#39;s ~ \text{is non zero}. \end{align*}  \]</span></p>
<p>The statistic that is used to test this hypothesis is called the <strong>F-statistic</strong>
and is defined as follows:</p>
<p><span class="math display">\[  F\text{-statistic} = \text{Fisher statistic}=  \frac{ (SST-SSE)/p}{ SSE/(n-p-1)}
\]</span></p>
<p>where <span class="math inline">\(n\)</span> = number of rows (sample points) in the dataset and <span class="math inline">\(p\)</span> = number of
predictor variables in the model.</p>
<p>There is a <span class="math inline">\(p\)</span>-value that is associated with this <span class="math inline">\(F\)</span>-statistic. If the
<span class="math inline">\(p\)</span>-value is smaller than the chosen significance level, the null hypothesis
can be rejected.</p>
<p>It is important to look at the F-statistic because:</p>
<ul>
<li>p-values are about individual relationships between predictors and the outcome
variable. However, one predictor’s relationship with the output might be
impacted by the presence of other variables.</li>
<li>When the number of predictors in the model is very large and all the
<span class="math inline">\(\beta_i\)</span> are very close to zero, the individual p-values associated with the
predictors might give very small values so we might incorrectly conclude that
there is a relationship between the predictors and the outcome.</li>
</ul>
</div>
</div>
<div id="simple-linear-regression-with-lm-function" class="section level2 hasAnchor" number="2.4">
<h2><span class="header-section-number">2.4</span> Simple Linear Regression with <code>lm</code> function<a href="introLinearReg.html#simple-linear-regression-with-lm-function" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>There are a few R packages, e.g., the built-in <code>stat</code> package have a <code>lm</code>
(linear model) function to fit linear regression very easy - much easier than
implementing from scratch like we did in the last lesson. See more details in the
<a href="https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/lm">lm manual</a>.</p>
<p>We will start with the <code>datarium</code> library which contain the <code>advertising</code> data.</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="introLinearReg.html#cb61-1" tabindex="-1"></a><span class="co"># Install datarium library if you haven&#39;t</span></span>
<span id="cb61-2"><a href="introLinearReg.html#cb61-2" tabindex="-1"></a><span class="cf">if</span> (<span class="sc">!</span><span class="fu">requireNamespace</span>(<span class="st">&quot;datarium&quot;</span>, <span class="at">quietly =</span> <span class="cn">TRUE</span>)) {</span>
<span id="cb61-3"><a href="introLinearReg.html#cb61-3" tabindex="-1"></a>  <span class="fu">install.packages</span>(<span class="st">&quot;datarium&quot;</span>)</span>
<span id="cb61-4"><a href="introLinearReg.html#cb61-4" tabindex="-1"></a>}</span>
<span id="cb61-5"><a href="introLinearReg.html#cb61-5" tabindex="-1"></a></span>
<span id="cb61-6"><a href="introLinearReg.html#cb61-6" tabindex="-1"></a><span class="fu">library</span>(datarium)</span>
<span id="cb61-7"><a href="introLinearReg.html#cb61-7" tabindex="-1"></a></span>
<span id="cb61-8"><a href="introLinearReg.html#cb61-8" tabindex="-1"></a><span class="co"># Load data: then we will have a data.frame with name marketing</span></span>
<span id="cb61-9"><a href="introLinearReg.html#cb61-9" tabindex="-1"></a><span class="fu">data</span>(marketing)</span>
<span id="cb61-10"><a href="introLinearReg.html#cb61-10" tabindex="-1"></a></span>
<span id="cb61-11"><a href="introLinearReg.html#cb61-11" tabindex="-1"></a><span class="fu">head</span>(marketing)</span>
<span id="cb61-12"><a href="introLinearReg.html#cb61-12" tabindex="-1"></a><span class="co">#&gt;   youtube facebook newspaper sales</span></span>
<span id="cb61-13"><a href="introLinearReg.html#cb61-13" tabindex="-1"></a><span class="co">#&gt; 1  276.12    45.36     83.04 26.52</span></span>
<span id="cb61-14"><a href="introLinearReg.html#cb61-14" tabindex="-1"></a><span class="co">#&gt; 2   53.40    47.16     54.12 12.48</span></span>
<span id="cb61-15"><a href="introLinearReg.html#cb61-15" tabindex="-1"></a><span class="co">#&gt; 3   20.64    55.08     83.16 11.16</span></span>
<span id="cb61-16"><a href="introLinearReg.html#cb61-16" tabindex="-1"></a><span class="co">#&gt; 4  181.80    49.56     70.20 22.20</span></span>
<span id="cb61-17"><a href="introLinearReg.html#cb61-17" tabindex="-1"></a><span class="co">#&gt; 5  216.96    12.96     70.08 15.48</span></span>
<span id="cb61-18"><a href="introLinearReg.html#cb61-18" tabindex="-1"></a><span class="co">#&gt; 6   10.44    58.68     90.00  8.64</span></span></code></pre></div>
<p>We can also check summary statistics of each column</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="introLinearReg.html#cb62-1" tabindex="-1"></a><span class="fu">summary</span>(marketing)</span>
<span id="cb62-2"><a href="introLinearReg.html#cb62-2" tabindex="-1"></a><span class="co">#&gt;     youtube          facebook       newspaper          sales      </span></span>
<span id="cb62-3"><a href="introLinearReg.html#cb62-3" tabindex="-1"></a><span class="co">#&gt;  Min.   :  0.84   Min.   : 0.00   Min.   :  0.36   Min.   : 1.92  </span></span>
<span id="cb62-4"><a href="introLinearReg.html#cb62-4" tabindex="-1"></a><span class="co">#&gt;  1st Qu.: 89.25   1st Qu.:11.97   1st Qu.: 15.30   1st Qu.:12.45  </span></span>
<span id="cb62-5"><a href="introLinearReg.html#cb62-5" tabindex="-1"></a><span class="co">#&gt;  Median :179.70   Median :27.48   Median : 30.90   Median :15.48  </span></span>
<span id="cb62-6"><a href="introLinearReg.html#cb62-6" tabindex="-1"></a><span class="co">#&gt;  Mean   :176.45   Mean   :27.92   Mean   : 36.66   Mean   :16.83  </span></span>
<span id="cb62-7"><a href="introLinearReg.html#cb62-7" tabindex="-1"></a><span class="co">#&gt;  3rd Qu.:262.59   3rd Qu.:43.83   3rd Qu.: 54.12   3rd Qu.:20.88  </span></span>
<span id="cb62-8"><a href="introLinearReg.html#cb62-8" tabindex="-1"></a><span class="co">#&gt;  Max.   :355.68   Max.   :59.52   Max.   :136.80   Max.   :32.40</span></span></code></pre></div>
<p>This dataset contains data about the advertising budget spent on YouTub, Radio, and
Newspapers for a particular product and the resulting sales. We expect a
positive correlation between such <b>advertising costs</b> and <b>sales</b>.</p>
<p>Let’s start with <b> YouTub advertising costs</b> to create a simple linear
regression model. First let’s plot the variables to get a better sense of
their relationship:</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="introLinearReg.html#cb63-1" tabindex="-1"></a><span class="co"># Create scatter plot</span></span>
<span id="cb63-2"><a href="introLinearReg.html#cb63-2" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb63-3"><a href="introLinearReg.html#cb63-3" tabindex="-1"></a></span>
<span id="cb63-4"><a href="introLinearReg.html#cb63-4" tabindex="-1"></a><span class="fu">ggplot</span>(marketing, <span class="fu">aes</span>(<span class="at">x=</span>youtube, <span class="at">y=</span>sales)) <span class="sc">+</span> </span>
<span id="cb63-5"><a href="introLinearReg.html#cb63-5" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">colour=</span><span class="st">&quot;black&quot;</span>) <span class="sc">+</span> </span>
<span id="cb63-6"><a href="introLinearReg.html#cb63-6" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&#39;YouTube vs Sales&#39;</span>)</span></code></pre></div>
<p><img src="BMDatSci_files/figure-html/fig2-sale-scatter-1.png" width="75%" /></p>
<p>As YouTube advertisement cost increases, sales also increase – they are
positively correlated!</p>
<p>Now with the linear model <code>lm</code> function, let’s create a line of best fit using
the least sum of square method.</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="introLinearReg.html#cb64-1" tabindex="-1"></a><span class="co"># Fit linear regression</span></span>
<span id="cb64-2"><a href="introLinearReg.html#cb64-2" tabindex="-1"></a><span class="co"># By default it include an incepter, so it is equvialent to add &quot;+ 1&quot;</span></span>
<span id="cb64-3"><a href="introLinearReg.html#cb64-3" tabindex="-1"></a><span class="co"># res.lm &lt;- lm(sales ~ youtube + 1, data = marketing)</span></span>
<span id="cb64-4"><a href="introLinearReg.html#cb64-4" tabindex="-1"></a></span>
<span id="cb64-5"><a href="introLinearReg.html#cb64-5" tabindex="-1"></a>res.lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(sales <span class="sc">~</span> youtube, <span class="at">data =</span> marketing)</span></code></pre></div>
<p>In the above code, we used <code>lm</code> to fit our simple linear regression model. This
takes the formula <code>y ~ X</code>, where <code>X</code> is the predictor variable (YouTube
advertising costs) and <code>y</code> is the output variable (Sales). Then, this function
will return fitted model via a ordinary least squares (OLS) method. The <code>res.lm</code>
is a list, you can get the it attributes by e.g., <code>res.lm$coefficients</code></p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="introLinearReg.html#cb65-1" tabindex="-1"></a>res.lm<span class="sc">$</span>coefficients</span>
<span id="cb65-2"><a href="introLinearReg.html#cb65-2" tabindex="-1"></a><span class="co">#&gt; (Intercept)     youtube </span></span>
<span id="cb65-3"><a href="introLinearReg.html#cb65-3" tabindex="-1"></a><span class="co">#&gt;  8.43911226  0.04753664</span></span></code></pre></div>
<p>In the notation that we have been using, <span class="math inline">\(\alpha\)</span> is the intercept and <span class="math inline">\(\beta\)</span>
is the slope i.e.:</p>
<p><span class="math inline">\(\alpha = 8.439, \quad \beta = 0.048\)</span></p>
<p>Thus, the equation for the model will be:</p>
<p><span class="math inline">\(\text{Sales} = 8.439 + 0.048*\text{YouTube}\)</span></p>
<p>Let’s also check an indicator of the model efficacy, <em>R<sup>2</sup></em>. Luckily,
<code>summary</code> function can calculate it from the <code>lm</code> output and gives us a
ready-made method for doing this so we don’t need to code all the math ourselves:</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="introLinearReg.html#cb66-1" tabindex="-1"></a>res_summary <span class="ot">=</span> <span class="fu">summary</span>(res.lm)</span>
<span id="cb66-2"><a href="introLinearReg.html#cb66-2" tabindex="-1"></a></span>
<span id="cb66-3"><a href="introLinearReg.html#cb66-3" tabindex="-1"></a><span class="co"># Again, res_summary is also a list</span></span>
<span id="cb66-4"><a href="introLinearReg.html#cb66-4" tabindex="-1"></a>res_summary<span class="sc">$</span>r.squared</span>
<span id="cb66-5"><a href="introLinearReg.html#cb66-5" tabindex="-1"></a><span class="co">#&gt; [1] 0.6118751</span></span></code></pre></div>
<p>We can also take a look at the model summary by writing this snippet:</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="introLinearReg.html#cb67-1" tabindex="-1"></a><span class="co"># Print out the summary</span></span>
<span id="cb67-2"><a href="introLinearReg.html#cb67-2" tabindex="-1"></a><span class="fu">summary</span>(res.lm)</span>
<span id="cb67-3"><a href="introLinearReg.html#cb67-3" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb67-4"><a href="introLinearReg.html#cb67-4" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb67-5"><a href="introLinearReg.html#cb67-5" tabindex="-1"></a><span class="co">#&gt; lm(formula = sales ~ youtube, data = marketing)</span></span>
<span id="cb67-6"><a href="introLinearReg.html#cb67-6" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb67-7"><a href="introLinearReg.html#cb67-7" tabindex="-1"></a><span class="co">#&gt; Residuals:</span></span>
<span id="cb67-8"><a href="introLinearReg.html#cb67-8" tabindex="-1"></a><span class="co">#&gt;      Min       1Q   Median       3Q      Max </span></span>
<span id="cb67-9"><a href="introLinearReg.html#cb67-9" tabindex="-1"></a><span class="co">#&gt; -10.0632  -2.3454  -0.2295   2.4805   8.6548 </span></span>
<span id="cb67-10"><a href="introLinearReg.html#cb67-10" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb67-11"><a href="introLinearReg.html#cb67-11" tabindex="-1"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb67-12"><a href="introLinearReg.html#cb67-12" tabindex="-1"></a><span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span id="cb67-13"><a href="introLinearReg.html#cb67-13" tabindex="-1"></a><span class="co">#&gt; (Intercept) 8.439112   0.549412   15.36   &lt;2e-16 ***</span></span>
<span id="cb67-14"><a href="introLinearReg.html#cb67-14" tabindex="-1"></a><span class="co">#&gt; youtube     0.047537   0.002691   17.67   &lt;2e-16 ***</span></span>
<span id="cb67-15"><a href="introLinearReg.html#cb67-15" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb67-16"><a href="introLinearReg.html#cb67-16" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb67-17"><a href="introLinearReg.html#cb67-17" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb67-18"><a href="introLinearReg.html#cb67-18" tabindex="-1"></a><span class="co">#&gt; Residual standard error: 3.91 on 198 degrees of freedom</span></span>
<span id="cb67-19"><a href="introLinearReg.html#cb67-19" tabindex="-1"></a><span class="co">#&gt; Multiple R-squared:  0.6119, Adjusted R-squared:  0.6099 </span></span>
<span id="cb67-20"><a href="introLinearReg.html#cb67-20" tabindex="-1"></a><span class="co">#&gt; F-statistic: 312.1 on 1 and 198 DF,  p-value: &lt; 2.2e-16</span></span></code></pre></div>
<p>There is a lot here. Of these results, we have discussed:</p>
<ul>
<li>R-squared</li>
<li>F-statistic</li>
<li>Prob (F-statistic) - this is the p-value of the F-statistic</li>
<li>Intercept coef - this is <code>alpha</code></li>
<li>YouTub coef - this is <code>beta</code> for predictor <code>YouTub</code></li>
<li>P&gt;|t| - this is the p-value for our coefficients</li>
</ul>
<p>Now that we’ve fit a simple regression model, we can try to predict the values
of sales based on the equation we just derived!</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="introLinearReg.html#cb68-1" tabindex="-1"></a>sales_pred <span class="ot">=</span> <span class="fu">predict</span>(res.lm, <span class="at">newdata =</span> marketing[<span class="fu">c</span>(<span class="st">&#39;youtube&#39;</span>)])</span>
<span id="cb68-2"><a href="introLinearReg.html#cb68-2" tabindex="-1"></a>marketing[<span class="st">&#39;sales_pred&#39;</span>] <span class="ot">=</span> sales_pred</span></code></pre></div>
<p>The <code>predict</code> fucntion predicts sales value for each row based on the model
equation using YouTub costs. This is the equivalent of manually typing out our
equation: <code>sales_pred = 8.439 + 0.048*(advert['youtube'])</code>.</p>
<p>We can visualise our regression model by plotting <code>sales_pred</code> against the
YouTube advertising costs to find the line of best fit:</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="introLinearReg.html#cb69-1" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb69-2"><a href="introLinearReg.html#cb69-2" tabindex="-1"></a></span>
<span id="cb69-3"><a href="introLinearReg.html#cb69-3" tabindex="-1"></a><span class="fu">ggplot</span>(marketing, <span class="fu">aes</span>(<span class="at">x=</span>youtube)) <span class="sc">+</span> </span>
<span id="cb69-4"><a href="introLinearReg.html#cb69-4" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y=</span>sales), <span class="at">colour=</span><span class="st">&quot;black&quot;</span>) <span class="sc">+</span> </span>
<span id="cb69-5"><a href="introLinearReg.html#cb69-5" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y=</span>sales_pred), <span class="at">colour=</span><span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb69-6"><a href="introLinearReg.html#cb69-6" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&#39;YouTube vs Sales&#39;</span>)</span></code></pre></div>
<p><img src="BMDatSci_files/figure-html/fig2-sale-pred-1.png" width="75%" /></p>
<p>In the next step, we will add more features as predictors and see whether it improves our model. Go to the the notebook called <code>02-linearReg-05.Rmd</code>.</p>
</div>
<div id="multiple-regression-with-lm-function" class="section level2 hasAnchor" number="2.5">
<h2><span class="header-section-number">2.5</span> Multiple Regression with <code>lm</code> function<a href="introLinearReg.html#multiple-regression-with-lm-function" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A multiple linear regression is simply a linear regression that involves more
than one predictor variable. It is represented as:
<span class="math display">\[\qquad Y_e = \alpha + \beta_1*X_1  + \beta_2*X_2 + \dots  + \beta_p*X_p\]</span></p>
<p>Each <em>β<sub>i</sub></em> will be estimated using the least sum of squares method.</p>
<p>The data set is<br />
<span class="math display">\[ \begin{array}
       {~~}  Y_1, &amp;  X_1^{(1)},  &amp;  \ldots, &amp;  X_p^{(1)} \\
        Y_2, &amp;  X_1^{(2)},  &amp;  \ldots, &amp;  X_p^{(2)} \\
       \vdots  &amp; \vdots  &amp; \vdots &amp; \vdots \\
      Y_n, &amp;  X_1^{(n)},  &amp;  \ldots, &amp;  X_p^{(n)}
    \end{array}
\]</span>
For each sample <span class="math inline">\(i\)</span>, the predicted value by the model is:<br />
<span class="math inline">\(\qquad Y_{i,e} = \alpha + \beta_1*X_1^{(i)} + \beta_2*X_2^{(i)} + \dots + \beta_p*X_p^{(i)}\)</span></p>
<p>Define the sum of squares
<span class="math display">\[   S(\alpha,\beta_1,\ldots,\beta_p) = \sum_{i=1}^n
\left\{     Y_i -Y_{i,e}\right\}^2  =\sum_{i=1}^n \left\{
    Y_i -\left( \alpha + \beta_1*X_1^{(i)}  + \beta_2*X_2^{(i)} + \dots  + \beta_p*X_p^{(i)}\right)\right\}^2
\]</span>
Least squares estimators: solve
<span class="math display">\[ \frac{\partial  S(\alpha,\beta_1,\ldots,\beta_p)}{\partial \alpha}=0,\quad
\frac{\partial S (\alpha,\beta_1,\ldots,\beta_p)}{\partial \beta_1}=0,\quad \ldots,\quad
\frac{\partial S (\alpha,\beta_1,\ldots,\beta_p)}{\partial \beta_p}=0.
\]</span>
to obtain the <code>least squares estimators</code> of the parameters
<span class="math display">\[ \hat\alpha, \hat\beta_1,\ldots,\hat\beta_p.
\]</span>
Note that be definition,
<span class="math display">\[      SSE = S(\hat\alpha, \hat\beta_1,\ldots,\hat\beta_p).
\]</span>
In other words, the fitted SSE (sum of squares error) is the minimized
value of the sum squares with the estimated values of the parameters.</p>
<p><strong>The more varibles, the smaller the <span class="math inline">\(R^2\)</span></strong></p>
<p>Consider two regression models</p>
<ol style="list-style-type: upper-roman">
<li><p><span class="math inline">\(\quad ~ Y_e = \alpha + \beta_1*X_1\)</span></p></li>
<li><p><span class="math inline">\(\quad \tilde Y_e = \alpha + \beta_1*X_1 + \beta_2*X_2\)</span></p></li>
</ol>
<p>The model (II) has one more input variable <span class="math inline">\(X_2\)</span>.</p>
<p>The <span class="math inline">\(SSE_I\)</span> of Model (I) is the minimum of</p>
<p><span class="math display">\[   S_I(\alpha,\beta_1) = \sum_{i=1}^n \left\{
    Y_i -\left( \alpha + \beta_1*X_1^{(i)} \right)\right\}^2
\]</span>
over all possible values of <span class="math inline">\((\alpha,\beta_1)\)</span>.</p>
<p>The <span class="math inline">\(SSE_{II}\)</span> of Model (II) is the minimum of</p>
<p><span class="math display">\[   S_{II}(\alpha,\beta_1,\beta_2) = \sum_{i=1}^n \left\{
    Y_i -\left( \alpha + \beta_1*X_1^{(i)} +\beta_2*X_2^{(i)}  \right)\right\}^2.
\]</span>
over all possible values of <span class="math inline">\((\alpha,\beta_1,\beta_2)\)</span>.</p>
<p>Because <span class="math inline">\(\quad S_I(\alpha,\beta_1) = S_{II}(\alpha,\beta_1,\beta_2=0 )\)</span>,</p>
<p>we find that <span class="math inline">\(SSE_{II}\le SSE_I\)</span>, so
<span class="math display">\[   R^2_{II} = SST - SSE_{II} \ge SST - SSE_{I} =  R^2_{I}.
\]</span></p>
<p>With this simple dataset of three predictor variables, there can be seven
possible models:</p>
<ol style="list-style-type: decimal">
<li>Sales ~ YouTube</li>
<li>Sales ~ Newspaper</li>
<li>Sales ~ Facebook</li>
<li>Sales ~ YouTube + Facebook</li>
<li>Sales ~ YouTube + Newspaper</li>
<li>Sales ~ Newspaper + Facebook</li>
<li>Sales ~ YouTube + Facebook + Newspaper</li>
</ol>
<p>Generally, if there are p possible predictor variables, there can be
<em>(2<sup>p</sup> - 1)</em> possible models – this can get large very quickly!</p>
<p>Thankfully, there are a few guidelines to filter some of these and then
navigate towards the most efficient one.</p>
<ul>
<li>Keep variables with low p-values and eliminate ones with high p-values</li>
<li>Keep variables that increase the value of <strong>adjusted-<em>R<sup>2</sup></em></strong> – this
penalizes the model for adding insignificant variables and increases when we
add significant variables. It is calculated by:
<span class="math display">\[ R^2_{adj} = 1- (1-R^2) \frac{n-1}{n-p-1}\]</span></li>
</ul>
<p>Based on these guidelines, there are two approaches to select the predictor
variables in the final model:</p>
<ul>
<li><strong>Forward selection</strong>: start with a null model (no predictors), then add
predictors one by one. If the p-value for the variable is small enough and the
value of the adjusted-<em>R<sup>2</sup></em> goes up, the predictor is included in the
model. Otherwise, it is not included.</li>
<li><strong>Backward selection</strong>: starts with a model that has all the possible
predictors and discard some of them. If the p-value of a predictor variable is
large and adjusted-<em>R<sup>2</sup></em> is lower when removed, it is discarded from
the model. Otherwise, it remains a part of the model.</li>
</ul>
<p>Many statistical programs give us an option to select from these approaches
while implementing multiple linear regression.</p>
<p>For now, let’s manually add a few variables and see how it changes the model
parameters and efficacy. First, add the <code>newspaper</code> variable to the model:</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="introLinearReg.html#cb70-1" tabindex="-1"></a><span class="fu">library</span>(datarium)</span>
<span id="cb70-2"><a href="introLinearReg.html#cb70-2" tabindex="-1"></a><span class="fu">data</span>(marketing)</span>
<span id="cb70-3"><a href="introLinearReg.html#cb70-3" tabindex="-1"></a></span>
<span id="cb70-4"><a href="introLinearReg.html#cb70-4" tabindex="-1"></a><span class="fu">head</span>(marketing)</span>
<span id="cb70-5"><a href="introLinearReg.html#cb70-5" tabindex="-1"></a><span class="co">#&gt;   youtube facebook newspaper sales</span></span>
<span id="cb70-6"><a href="introLinearReg.html#cb70-6" tabindex="-1"></a><span class="co">#&gt; 1  276.12    45.36     83.04 26.52</span></span>
<span id="cb70-7"><a href="introLinearReg.html#cb70-7" tabindex="-1"></a><span class="co">#&gt; 2   53.40    47.16     54.12 12.48</span></span>
<span id="cb70-8"><a href="introLinearReg.html#cb70-8" tabindex="-1"></a><span class="co">#&gt; 3   20.64    55.08     83.16 11.16</span></span>
<span id="cb70-9"><a href="introLinearReg.html#cb70-9" tabindex="-1"></a><span class="co">#&gt; 4  181.80    49.56     70.20 22.20</span></span>
<span id="cb70-10"><a href="introLinearReg.html#cb70-10" tabindex="-1"></a><span class="co">#&gt; 5  216.96    12.96     70.08 15.48</span></span>
<span id="cb70-11"><a href="introLinearReg.html#cb70-11" tabindex="-1"></a><span class="co">#&gt; 6   10.44    58.68     90.00  8.64</span></span></code></pre></div>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="introLinearReg.html#cb71-1" tabindex="-1"></a>res_lm2 <span class="ot">=</span> <span class="fu">lm</span>(sales <span class="sc">~</span> youtube <span class="sc">+</span> newspaper, <span class="at">data=</span>marketing)</span>
<span id="cb71-2"><a href="introLinearReg.html#cb71-2" tabindex="-1"></a><span class="fu">summary</span>(res_lm2)</span>
<span id="cb71-3"><a href="introLinearReg.html#cb71-3" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb71-4"><a href="introLinearReg.html#cb71-4" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb71-5"><a href="introLinearReg.html#cb71-5" tabindex="-1"></a><span class="co">#&gt; lm(formula = sales ~ youtube + newspaper, data = marketing)</span></span>
<span id="cb71-6"><a href="introLinearReg.html#cb71-6" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb71-7"><a href="introLinearReg.html#cb71-7" tabindex="-1"></a><span class="co">#&gt; Residuals:</span></span>
<span id="cb71-8"><a href="introLinearReg.html#cb71-8" tabindex="-1"></a><span class="co">#&gt;      Min       1Q   Median       3Q      Max </span></span>
<span id="cb71-9"><a href="introLinearReg.html#cb71-9" tabindex="-1"></a><span class="co">#&gt; -10.3477  -2.0815  -0.1138   2.2711  10.1415 </span></span>
<span id="cb71-10"><a href="introLinearReg.html#cb71-10" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb71-11"><a href="introLinearReg.html#cb71-11" tabindex="-1"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb71-12"><a href="introLinearReg.html#cb71-12" tabindex="-1"></a><span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span id="cb71-13"><a href="introLinearReg.html#cb71-13" tabindex="-1"></a><span class="co">#&gt; (Intercept) 6.929938   0.630405  10.993  &lt; 2e-16 ***</span></span>
<span id="cb71-14"><a href="introLinearReg.html#cb71-14" tabindex="-1"></a><span class="co">#&gt; youtube     0.046901   0.002581  18.173  &lt; 2e-16 ***</span></span>
<span id="cb71-15"><a href="introLinearReg.html#cb71-15" tabindex="-1"></a><span class="co">#&gt; newspaper   0.044219   0.010174   4.346 2.22e-05 ***</span></span>
<span id="cb71-16"><a href="introLinearReg.html#cb71-16" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb71-17"><a href="introLinearReg.html#cb71-17" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb71-18"><a href="introLinearReg.html#cb71-18" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb71-19"><a href="introLinearReg.html#cb71-19" tabindex="-1"></a><span class="co">#&gt; Residual standard error: 3.745 on 197 degrees of freedom</span></span>
<span id="cb71-20"><a href="introLinearReg.html#cb71-20" tabindex="-1"></a><span class="co">#&gt; Multiple R-squared:  0.6458, Adjusted R-squared:  0.6422 </span></span>
<span id="cb71-21"><a href="introLinearReg.html#cb71-21" tabindex="-1"></a><span class="co">#&gt; F-statistic: 179.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16</span></span></code></pre></div>
<p>As you see, the p-values for the coefficients are very small, suggesting that
all the estimates are significant. The equation for this model will be:</p>
<p><span class="math display">\[ \text{Sales} = 6.93+0.046* \text{YouTube} + 0.044 * \text{Newspaper}\]</span></p>
<p>The values of <em>R<sup>2</sup></em> and adjusted <em>R<sup>2</sup></em> are 0.646 and 0.642,
which is just a minor improvement from before (0.612 and 0.610, respectively).</p>
<p>Similarly for RSE (3.745). Only a small decrease in RSE and error…</p>
<p>Let’s take a closer look at the summary above. The Adj-R<sup>2</sup> increases
slightly, but the F-statistic decreases (from 312.1 to 179.6), as does the
associated p-value. This suggests that adding <code>newspaper</code> didn’t improve the
model significantly.</p>
<p>Let’s try adding <code>facebook</code> instead:</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="introLinearReg.html#cb72-1" tabindex="-1"></a><span class="co"># Initialise and fit new model with TV and Radio as predictors</span></span>
<span id="cb72-2"><a href="introLinearReg.html#cb72-2" tabindex="-1"></a><span class="co"># model3 = smf.ols(&#39;Sales ~ TV + Radio&#39;, data=advert).fit()</span></span>
<span id="cb72-3"><a href="introLinearReg.html#cb72-3" tabindex="-1"></a><span class="co"># print(model3.summary())</span></span>
<span id="cb72-4"><a href="introLinearReg.html#cb72-4" tabindex="-1"></a></span>
<span id="cb72-5"><a href="introLinearReg.html#cb72-5" tabindex="-1"></a>res_lm3 <span class="ot">=</span> <span class="fu">lm</span>(sales <span class="sc">~</span> youtube <span class="sc">+</span> facebook, <span class="at">data=</span>marketing)</span>
<span id="cb72-6"><a href="introLinearReg.html#cb72-6" tabindex="-1"></a><span class="fu">summary</span>(res_lm3)</span>
<span id="cb72-7"><a href="introLinearReg.html#cb72-7" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb72-8"><a href="introLinearReg.html#cb72-8" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb72-9"><a href="introLinearReg.html#cb72-9" tabindex="-1"></a><span class="co">#&gt; lm(formula = sales ~ youtube + facebook, data = marketing)</span></span>
<span id="cb72-10"><a href="introLinearReg.html#cb72-10" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb72-11"><a href="introLinearReg.html#cb72-11" tabindex="-1"></a><span class="co">#&gt; Residuals:</span></span>
<span id="cb72-12"><a href="introLinearReg.html#cb72-12" tabindex="-1"></a><span class="co">#&gt;      Min       1Q   Median       3Q      Max </span></span>
<span id="cb72-13"><a href="introLinearReg.html#cb72-13" tabindex="-1"></a><span class="co">#&gt; -10.5572  -1.0502   0.2906   1.4049   3.3994 </span></span>
<span id="cb72-14"><a href="introLinearReg.html#cb72-14" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb72-15"><a href="introLinearReg.html#cb72-15" tabindex="-1"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb72-16"><a href="introLinearReg.html#cb72-16" tabindex="-1"></a><span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span id="cb72-17"><a href="introLinearReg.html#cb72-17" tabindex="-1"></a><span class="co">#&gt; (Intercept)  3.50532    0.35339   9.919   &lt;2e-16 ***</span></span>
<span id="cb72-18"><a href="introLinearReg.html#cb72-18" tabindex="-1"></a><span class="co">#&gt; youtube      0.04575    0.00139  32.909   &lt;2e-16 ***</span></span>
<span id="cb72-19"><a href="introLinearReg.html#cb72-19" tabindex="-1"></a><span class="co">#&gt; facebook     0.18799    0.00804  23.382   &lt;2e-16 ***</span></span>
<span id="cb72-20"><a href="introLinearReg.html#cb72-20" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb72-21"><a href="introLinearReg.html#cb72-21" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb72-22"><a href="introLinearReg.html#cb72-22" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb72-23"><a href="introLinearReg.html#cb72-23" tabindex="-1"></a><span class="co">#&gt; Residual standard error: 2.018 on 197 degrees of freedom</span></span>
<span id="cb72-24"><a href="introLinearReg.html#cb72-24" tabindex="-1"></a><span class="co">#&gt; Multiple R-squared:  0.8972, Adjusted R-squared:  0.8962 </span></span>
<span id="cb72-25"><a href="introLinearReg.html#cb72-25" tabindex="-1"></a><span class="co">#&gt; F-statistic: 859.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16</span></span></code></pre></div>
<p>This gives us the model:</p>
<p><span class="math display">\[ \text{Sales} = 3.51+0.046* \text{YouTube} + 0.188 * \text{Facebook}\]</span></p>
<p>The adjusted <em>R<sup>2</sup></em> value has improved considerably, as did the
RSE and F-statistic, indicating an efficient model.</p>
<p>Thus, we can conclude that <code>facebook</code> is a great addition to the model.<br />
<code>YouTube</code> and <code>facebook</code> advertising costs together are able to predict sales
well. But, can we improve it a bit further by combining all three predictor
variables?</p>
<p><strong>Try it out:</strong> see if you can figure out how to do this on your own!</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="introLinearReg.html#cb73-1" tabindex="-1"></a><span class="co"># Initialise and fit new model with TV, Newspaper, and Radio as predictors</span></span>
<span id="cb73-2"><a href="introLinearReg.html#cb73-2" tabindex="-1"></a></span>
<span id="cb73-3"><a href="introLinearReg.html#cb73-3" tabindex="-1"></a></span>
<span id="cb73-4"><a href="introLinearReg.html#cb73-4" tabindex="-1"></a><span class="co"># Print summary of regression results</span></span>
<span id="cb73-5"><a href="introLinearReg.html#cb73-5" tabindex="-1"></a><span class="co"># Calculate RSE - don&#39;t forget that the number of predictors p is now 3</span></span></code></pre></div>
<p>You should get the equation:</p>
<p><span class="math display">\[ \text{Sales} = 3.53+0.046*\text{YouTube} -0.001*\text{Newspaper} +0.188*\text{Facebook}\]</span></p>
<p>You should also find that:</p>
<ul>
<li>RSE increases slightly,</li>
<li>the coefficient for <code>newspaper</code> is negative, and</li>
<li>the F-statistic decreases considerably from 859.6 to 570.3.</li>
</ul>
<p>All these suggest that the model actually became less efficient on addition of <code>newspaper</code>.</p>
<p>Why?</p>
<p>This step shows clearly that adding one more input variable <code>Newspaper</code> in
Model 3 does not lead to any improvement.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introR.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="introClassifier.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/statbiomed/BMDS-book/tree/main/01-introduction.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["BMDatSci.pdf", "BMDatSci.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
