

## Application on Diabetes

### Load Pima Indians Diabetes Database

This 
[dataset](https://www.rdocumentation.org/packages/mlbench/topics/PimaIndiansDiabetes) 
is originally from the National Institute of Diabetes and Digestive 
and Kidney Diseases. The objective of the dataset is to diagnostically predict 
whether or not a patient has diabetes, based on certain diagnostic measurements 
included in the dataset. Several constraints were placed on the selection of 
these instances from a larger database. In particular, all patients here are 
females at least 21 years old of Pima Indian heritage. 

The datasets consist of several medical predictors (independent variables) and 
one target outcome (dependent variable). Independent variables include the 
number of pregnancies the patient has had, their BMI, insulin level, age, and 
so on.

```{r}
# Install the mlbench library for loading the datasets
if (!requireNamespace("mlbench", quietly = TRUE)) {
  install.packages("mlbench")
}

# Load data
library(mlbench)
data(PimaIndiansDiabetes)

# Check the first few lines
dim(PimaIndiansDiabetes)
head(PimaIndiansDiabetes)
```

Now, let's check two potential features: `glucose` and `age`, colored by the diabetes labels.
```{r fig3-diab-scatter, out.width = '75%'}
library(ggplot2)

ggplot(data=PimaIndiansDiabetes, aes(x=glucose, y=age)) +
  geom_point(aes(color=diabetes))
```

Before we start fitting models, let's split the data into training and test sets in 
a 3:1 ratio. Let's define it manually, though there are functions to do it 
automatically.

```{r}
## split data into training and test sets
set.seed(0)

n_samples = nrow(PimaIndiansDiabetes)
idx_train = sample(n_samples, size = 0.75 * n_samples, replace = FALSE)
df_train = PimaIndiansDiabetes[idx_train, ]
df_test  = PimaIndiansDiabetes[-idx_train, ] # recall the meaning of negative symbol
```



### Fit logistic regression
In logistic regression, the predicted probability of being class 1 is:

$$P(y=1|X, W) = \sigma(w_0, x_1 * w_1 + ... + x_p * w_p)$$

where the $\sigma()$ denotes the logistic function.

In R, the built-in package `stats` already has functions to fit 
[generalised linear model (GLM)](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/glm), 
including logistic regression, a type of GML.

Here, let's start with the entire dataset to fit a logistic regression model.

**Note**, we will specify the model family as `binomial`, as the likelihood we 
are using in logistic regression is a Bernoulli likelihood, a special case of
binomial likelihood when the total trial `n=1`.


```{r}
## Define formula in different ways
# my_formula = as.formula(diabetes ~ glucose + age)
# my_formula = as.formula(paste(colnames(PimaIndiansDiabetes)[1:8], collapse= " + "))
# my_formula = as.formula(diabetes ~ .)

## Fit logistic regression
glm_res <- glm(diabetes ~ ., data=df_train, family = binomial)

## We can use the logLik() function to obtain the log likelihood
logLik(glm_res)
```

We can use `summary()` function to see more details about the model fitting, including accessing the p-values.
```{r}
summary(glm_res)

## Access to the p-value
summary_glm <- summary(glm_res)
print("p-values can be access from the summary function:")
summary_glm$coefficients[, "Pr(>|z|)"]
```

### Assess on test data
Now, we can evaluate the accuracy of the model on the 25% test data.

```{r}
## Train the full model on the training data
glm_train <- glm(diabetes ~ ., data=df_train, family = binomial)

## Predict the probability of being diabeties on test data
# We can also set a threshold, e.g., 0.5 for the predicted label
pred_prob = predict(glm_train, df_test, type = "response")
pred_label = pred_prob >= 0.5

## Observed label
obse_label = df_test$diabetes == 'pos'

## Calculate the accuracy on test data
# think how accuracy is defined
# we can use (TN + TP) / (TN + TP + FN + FP)
# we can also directly compare the proportion of correctness
accuracy = mean(pred_label == obse_label)
print(paste("Accuracy on test set:", accuracy))
```



### Model selection and diagnosis

Similar to the multiple linear regression, selecting the predictive 
features are essential to ensure the prediction performance in test sets. In 
theory, there could 2^{p} combinations of feature usage for $p$-dimensional 
features, making it a challenging task for selecting the best model, especially
when $p$ is large.

Here, we use a strategy of "recursive feature elimination". Namely, we will
include all features first and remove features with relatively large p-value 
(that we fail to reject the null distribution that the feature has a coefficient 
of zero).

Besides using p-value, we will also use the test set that we split from the 
entire dataset, which a general strategy in assessing performance in 
machine learning.

#### Model2: New feature set by removing `triceps`
```{r}
## Train the full model on the training data

glm_mod2 <- glm(diabetes ~ pregnant + glucose + pressure + 
                   insulin + mass + pedigree + age, 
                data=df_train, family = binomial)

logLik(glm_mod2)
summary(glm_mod2)
```


```{r}
## Predict the probability of being diabeties on test data
# We can also set a threshold, e.g., 0.5 for the predicted label
pred_prob2 = predict(glm_mod2, df_test, type = "response")
pred_label2 = pred_prob2 >= 0.5

accuracy2 = mean(pred_label2 == obse_label)
print(paste("Accuracy on test set with model2:", accuracy2))
```


#### Model3: New feature set by removing `triceps` and `insulin`

```{r}
# Train the full model on the training data
glm_mod3 <- glm(diabetes ~ pregnant + glucose + pressure + 
                   mass + pedigree + age, 
                data=df_train, family = binomial)

logLik(glm_mod3)
summary(glm_mod3)
```


```{r}
# Predict the probability of being diabeties on test data
# We can also set a threshold, e.g., 0.5 for the predicted label
pred_prob3 = predict(glm_mod3, df_test, type = "response")
pred_label3 = pred_prob3 >= 0.5

accuracy3 = mean(pred_label3 == obse_label)
print(paste("Accuracy on test set with model3:", accuracy3))
```


